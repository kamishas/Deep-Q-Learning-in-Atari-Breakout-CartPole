{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q gym[atari]\n",
    "!pip install -q autorom[accept-rom-license]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyOpenGL in /home/skamine3/.local/lib/python3.9/site-packages (3.1.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyvirtualdisplay in /home/skamine3/.local/lib/python3.9/site-packages (3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyOpenGL_accelerate in /home/skamine3/.local/lib/python3.9/site-packages (3.1.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install PyOpenGL\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install PyOpenGL_accelerate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gym[atari] in /home/skamine3/.local/lib/python3.9/site-packages (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from gym[atari]) (1.22.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/skamine3/.local/lib/python3.9/site-packages (from gym[atari]) (3.1.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.8.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from gym[atari]) (4.11.3)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in /home/skamine3/.local/lib/python3.9/site-packages (from gym[atari]) (0.0.8)\n",
      "Requirement already satisfied: ale-py~=0.7.5 in /home/skamine3/.local/lib/python3.9/site-packages (from gym[atari]) (0.7.5)\n",
      "Requirement already satisfied: importlib-resources in /home/skamine3/.local/lib/python3.9/site-packages (from ale-py~=0.7.5->gym[atari]) (6.4.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from importlib_metadata>=4.8.0->gym[atari]) (3.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ale-py in /home/skamine3/.local/lib/python3.9/site-packages (0.7.5)\n",
      "Requirement already satisfied: numpy in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ale-py) (1.22.3)\n",
      "Requirement already satisfied: importlib-resources in /home/skamine3/.local/lib/python3.9/site-packages (from ale-py) (6.4.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from ale-py) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from importlib-metadata>=4.10.0->ale-py) (3.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[atari]\n",
    "!pip install ale-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gym==0.25.2 in /home/skamine3/.local/lib/python3.9/site-packages (0.25.2)\n",
      "Requirement already satisfied: pyvirtualdisplay in /home/skamine3/.local/lib/python3.9/site-packages (3.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from gym==0.25.2) (1.22.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/skamine3/.local/lib/python3.9/site-packages (from gym==0.25.2) (3.1.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.8.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from gym==0.25.2) (4.11.3)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in /home/skamine3/.local/lib/python3.9/site-packages (from gym==0.25.2) (0.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from importlib_metadata>=4.8.0->gym==0.25.2) (3.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "We trust you have received the usual lecture from the local System\n",
      "Administrator. It usually boils down to these three things:\n",
      "\n",
      "    #1) Respect the privacy of others.\n",
      "    #2) Think before you type.\n",
      "    #3) With great power comes great responsibility.\n",
      "\n",
      "[sudo] password for skamine3: \n"
     ]
    }
   ],
   "source": [
    "!pip3 install gym==0.25.2 pyvirtualdisplay\n",
    "!sudo apt-get install -y xvfb python-opengl ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (61.0.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Using cached setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: setuptools\n",
      "Successfully installed setuptools-75.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ez_setup\n",
      "  Downloading ez_setup-0.9.tar.gz (6.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[40 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-pip-egg-info-d9r06y64/ez_setup.egg-info\n",
      "  \u001b[31m   \u001b[0m writing /tmp/pip-pip-egg-info-d9r06y64/ez_setup.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to /tmp/pip-pip-egg-info-d9r06y64/ez_setup.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to /tmp/pip-pip-egg-info-d9r06y64/ez_setup.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m writing manifest file '/tmp/pip-pip-egg-info-d9r06y64/ez_setup.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest file '/tmp/pip-pip-egg-info-d9r06y64/ez_setup.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-n44kat7q/ez-setup_9fd55b33712547edadaa84f01187d694/setup.py\", line 18, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(name='ez_setup',\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/__init__.py\", line 117, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 183, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/_distutils/core.py\", line 199, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 954, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/dist.py\", line 995, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/_distutils/dist.py\", line 973, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/command/egg_info.py\", line 313, in run\n",
      "  \u001b[31m   \u001b[0m     self.find_sources()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/command/egg_info.py\", line 321, in find_sources\n",
      "  \u001b[31m   \u001b[0m     mm.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/command/egg_info.py\", line 549, in run\n",
      "  \u001b[31m   \u001b[0m     self.prune_file_list()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/command/sdist.py\", line 162, in prune_file_list\n",
      "  \u001b[31m   \u001b[0m     super().prune_file_list()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/_distutils/command/sdist.py\", line 380, in prune_file_list\n",
      "  \u001b[31m   \u001b[0m     base_dir = self.distribution.get_fullname()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/_core_metadata.py\", line 267, in get_fullname\n",
      "  \u001b[31m   \u001b[0m     return _distribution_fullname(self.get_name(), self.get_version())\n",
      "  \u001b[31m   \u001b[0m   File \"/home/skamine3/.local/lib/python3.9/site-packages/setuptools/_core_metadata.py\", line 285, in _distribution_fullname\n",
      "  \u001b[31m   \u001b[0m     canonicalize_version(version, strip_trailing_zero=False),\n",
      "  \u001b[31m   \u001b[0m TypeError: canonicalize_version() got an unexpected keyword argument 'strip_trailing_zero'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade setuptools --user\n",
    "!pip3 install ez_setup\n",
    "#!pip3 install gym[atari]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gym==0.25.2 in /home/skamine3/.local/lib/python3.9/site-packages (0.25.2)\n",
      "Requirement already satisfied: pyvirtualdisplay in /home/skamine3/.local/lib/python3.9/site-packages (3.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from gym==0.25.2) (1.22.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/skamine3/.local/lib/python3.9/site-packages (from gym==0.25.2) (3.1.0)\n",
      "Requirement already satisfied: importlib_metadata>=4.8.0 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from gym==0.25.2) (4.11.3)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in /home/skamine3/.local/lib/python3.9/site-packages (from gym==0.25.2) (0.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages (from importlib_metadata>=4.8.0->gym==0.25.2) (3.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "We trust you have received the usual lecture from the local System\n",
      "Administrator. It usually boils down to these three things:\n",
      "\n",
      "    #1) Respect the privacy of others.\n",
      "    #2) Think before you type.\n",
      "    #3) With great power comes great responsibility.\n",
      "\n",
      "[sudo] password for skamine3: "
     ]
    }
   ],
   "source": [
    "!pip3 install gym==0.25.2 pyvirtualdisplay\n",
    "!sudo apt-get install -y xvfb python-opengl ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import gym\n",
    "import torch\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from utils import find_max_lives, check_live, get_frame, get_init_state\n",
    "from model import DQN\n",
    "from config import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info keys: dict_keys(['lives', 'episode_frame_number', 'frame_number'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n",
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('ALE/Breakout-v5')\n",
    "state = env.reset()\n",
    "_, _, _, info = env.step(0)  # Take a no-op action\n",
    "print(\"Info keys:\", info.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_live(life, cur_life):\n",
    "    return life > cur_life\n",
    "\n",
    "def find_max_lives(env):\n",
    "    env.reset()\n",
    "    _, _, _, info = env.step(0)\n",
    "    return info.get('lives', 0)  # Use 'lives' key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_lives = find_max_lives(env)\n",
    "state_size = env.observation_space.shape\n",
    "action_size = 3 #fire, left, and right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_dqn = False # set to True if using double DQN agent\n",
    "\n",
    "if double_dqn:\n",
    "    from agent_double import Agent\n",
    "else:\n",
    "    from agent import Agent\n",
    "\n",
    "agent = Agent(action_size)\n",
    "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
    "frame = 0\n",
    "memory_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0   score: 0.0   memory length: 123   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 0.0\n",
      "episode: 1   score: 0.0   memory length: 247   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 0.0\n",
      "episode: 2   score: 1.0   memory length: 418   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 0.3333333333333333\n",
      "episode: 3   score: 4.0   memory length: 696   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 4   score: 1.0   memory length: 866   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 5   score: 0.0   memory length: 990   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.0\n",
      "episode: 6   score: 1.0   memory length: 1142   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.0\n",
      "episode: 7   score: 1.0   memory length: 1313   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.0\n",
      "episode: 8   score: 1.0   memory length: 1483   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.0\n",
      "episode: 9   score: 3.0   memory length: 1750   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 10   score: 1.0   memory length: 1902   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.1818181818181819\n",
      "episode: 11   score: 1.0   memory length: 2072   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.1666666666666667\n",
      "episode: 12   score: 4.0   memory length: 2348   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.3846153846153846\n",
      "episode: 13   score: 0.0   memory length: 2472   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2857142857142858\n",
      "episode: 14   score: 0.0   memory length: 2595   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 15   score: 4.0   memory length: 2910   epsilon: 1.0    steps: 315    lr: 0.0001     evaluation reward: 1.375\n",
      "episode: 16   score: 0.0   memory length: 3033   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2941176470588236\n",
      "episode: 17   score: 2.0   memory length: 3234   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.3333333333333333\n",
      "episode: 18   score: 1.0   memory length: 3386   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.3157894736842106\n",
      "episode: 19   score: 0.0   memory length: 3510   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 20   score: 1.0   memory length: 3680   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.2380952380952381\n",
      "episode: 21   score: 0.0   memory length: 3803   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1818181818181819\n",
      "episode: 22   score: 3.0   memory length: 4032   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.2608695652173914\n",
      "episode: 23   score: 2.0   memory length: 4230   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.2916666666666667\n",
      "episode: 24   score: 2.0   memory length: 4429   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 25   score: 0.0   memory length: 4553   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2692307692307692\n",
      "episode: 26   score: 0.0   memory length: 4677   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2222222222222223\n",
      "episode: 27   score: 2.0   memory length: 4876   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 28   score: 0.0   memory length: 4999   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.206896551724138\n",
      "episode: 29   score: 0.0   memory length: 5123   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.1666666666666667\n",
      "episode: 30   score: 0.0   memory length: 5247   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.1290322580645162\n",
      "episode: 31   score: 2.0   memory length: 5446   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.15625\n",
      "episode: 32   score: 2.0   memory length: 5645   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.1818181818181819\n",
      "episode: 33   score: 0.0   memory length: 5768   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.1470588235294117\n",
      "episode: 34   score: 2.0   memory length: 5966   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.1714285714285715\n",
      "episode: 35   score: 0.0   memory length: 6090   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.1388888888888888\n",
      "episode: 36   score: 2.0   memory length: 6290   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.162162162162162\n",
      "episode: 37   score: 4.0   memory length: 6581   epsilon: 1.0    steps: 291    lr: 0.0001     evaluation reward: 1.236842105263158\n",
      "episode: 38   score: 2.0   memory length: 6798   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.2564102564102564\n",
      "episode: 39   score: 2.0   memory length: 6997   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.275\n",
      "episode: 40   score: 2.0   memory length: 7216   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.2926829268292683\n",
      "episode: 41   score: 1.0   memory length: 7368   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.2857142857142858\n",
      "episode: 42   score: 0.0   memory length: 7492   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.255813953488372\n",
      "episode: 43   score: 0.0   memory length: 7616   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2272727272727273\n",
      "episode: 44   score: 0.0   memory length: 7740   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 45   score: 3.0   memory length: 8013   epsilon: 1.0    steps: 273    lr: 0.0001     evaluation reward: 1.2391304347826086\n",
      "episode: 46   score: 1.0   memory length: 8165   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.2340425531914894\n",
      "episode: 47   score: 0.0   memory length: 8289   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2083333333333333\n",
      "episode: 48   score: 0.0   memory length: 8413   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.183673469387755\n",
      "episode: 49   score: 2.0   memory length: 8631   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.2\n",
      "episode: 50   score: 3.0   memory length: 8896   epsilon: 1.0    steps: 265    lr: 0.0001     evaluation reward: 1.2352941176470589\n",
      "episode: 51   score: 2.0   memory length: 9094   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.25\n",
      "episode: 52   score: 1.0   memory length: 9266   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.2452830188679245\n",
      "episode: 53   score: 3.0   memory length: 9495   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.2777777777777777\n",
      "episode: 54   score: 2.0   memory length: 9695   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.290909090909091\n",
      "episode: 55   score: 0.0   memory length: 9818   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2678571428571428\n",
      "episode: 56   score: 2.0   memory length: 10019   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.280701754385965\n",
      "episode: 57   score: 0.0   memory length: 10143   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2586206896551724\n",
      "episode: 58   score: 3.0   memory length: 10389   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.2881355932203389\n",
      "episode: 59   score: 0.0   memory length: 10513   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2666666666666666\n",
      "episode: 60   score: 0.0   memory length: 10637   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2459016393442623\n",
      "episode: 61   score: 2.0   memory length: 10818   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.2580645161290323\n",
      "episode: 62   score: 2.0   memory length: 11037   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.2698412698412698\n",
      "episode: 63   score: 3.0   memory length: 11304   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.296875\n",
      "episode: 64   score: 2.0   memory length: 11505   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.3076923076923077\n",
      "episode: 65   score: 1.0   memory length: 11675   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.303030303030303\n",
      "episode: 66   score: 1.0   memory length: 11827   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.2985074626865671\n",
      "episode: 67   score: 0.0   memory length: 11951   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2794117647058822\n",
      "episode: 68   score: 2.0   memory length: 12153   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.289855072463768\n",
      "episode: 69   score: 1.0   memory length: 12305   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.2857142857142858\n",
      "episode: 70   score: 1.0   memory length: 12475   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.2816901408450705\n",
      "episode: 71   score: 3.0   memory length: 12720   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.3055555555555556\n",
      "episode: 72   score: 1.0   memory length: 12871   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.3013698630136987\n",
      "episode: 73   score: 2.0   memory length: 13070   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.3108108108108107\n",
      "episode: 74   score: 0.0   memory length: 13193   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.2933333333333332\n",
      "episode: 75   score: 0.0   memory length: 13317   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.2763157894736843\n",
      "episode: 76   score: 1.0   memory length: 13487   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.2727272727272727\n",
      "episode: 77   score: 1.0   memory length: 13638   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.2692307692307692\n",
      "episode: 78   score: 4.0   memory length: 13918   epsilon: 1.0    steps: 280    lr: 0.0001     evaluation reward: 1.3037974683544304\n",
      "episode: 79   score: 1.0   memory length: 14089   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 80   score: 3.0   memory length: 14356   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.3209876543209877\n",
      "episode: 81   score: 2.0   memory length: 14558   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.329268292682927\n",
      "episode: 82   score: 1.0   memory length: 14729   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.3253012048192772\n",
      "episode: 83   score: 1.0   memory length: 14898   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.3214285714285714\n",
      "episode: 84   score: 3.0   memory length: 15125   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.3411764705882352\n",
      "episode: 85   score: 2.0   memory length: 15323   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.3488372093023255\n",
      "episode: 86   score: 1.0   memory length: 15475   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.3448275862068966\n",
      "episode: 87   score: 0.0   memory length: 15599   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.3295454545454546\n",
      "episode: 88   score: 3.0   memory length: 15844   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.348314606741573\n",
      "episode: 89   score: 3.0   memory length: 16074   epsilon: 1.0    steps: 230    lr: 0.0001     evaluation reward: 1.3666666666666667\n",
      "episode: 90   score: 0.0   memory length: 16198   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.3516483516483517\n",
      "episode: 91   score: 3.0   memory length: 16464   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.3695652173913044\n",
      "episode: 92   score: 0.0   memory length: 16588   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.3548387096774193\n",
      "episode: 93   score: 1.0   memory length: 16758   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.351063829787234\n",
      "episode: 94   score: 1.0   memory length: 16927   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.3473684210526315\n",
      "episode: 95   score: 2.0   memory length: 17126   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.3541666666666667\n",
      "episode: 96   score: 3.0   memory length: 17373   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.3711340206185567\n",
      "episode: 97   score: 5.0   memory length: 17699   epsilon: 1.0    steps: 326    lr: 0.0001     evaluation reward: 1.4081632653061225\n",
      "episode: 98   score: 1.0   memory length: 17869   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.404040404040404\n",
      "episode: 99   score: 2.0   memory length: 18050   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 100   score: 0.0   memory length: 18174   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 101   score: 2.0   memory length: 18372   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 102   score: 0.0   memory length: 18496   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 103   score: 2.0   memory length: 18714   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 104   score: 0.0   memory length: 18837   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 105   score: 3.0   memory length: 19085   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 106   score: 3.0   memory length: 19349   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 107   score: 1.0   memory length: 19522   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 108   score: 6.0   memory length: 19873   epsilon: 1.0    steps: 351    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 109   score: 0.0   memory length: 19997   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 110   score: 1.0   memory length: 20149   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 111   score: 3.0   memory length: 20394   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 112   score: 3.0   memory length: 20620   epsilon: 1.0    steps: 226    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 113   score: 4.0   memory length: 20880   epsilon: 1.0    steps: 260    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 114   score: 0.0   memory length: 21003   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 115   score: 1.0   memory length: 21172   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 116   score: 1.0   memory length: 21324   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 117   score: 2.0   memory length: 21522   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 118   score: 4.0   memory length: 21800   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 119   score: 0.0   memory length: 21923   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 120   score: 0.0   memory length: 22047   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 121   score: 2.0   memory length: 22245   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 122   score: 2.0   memory length: 22464   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 123   score: 0.0   memory length: 22587   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 124   score: 0.0   memory length: 22711   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 125   score: 2.0   memory length: 22933   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 126   score: 2.0   memory length: 23131   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 127   score: 1.0   memory length: 23282   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 128   score: 1.0   memory length: 23452   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 129   score: 4.0   memory length: 23749   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 130   score: 2.0   memory length: 23966   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 131   score: 0.0   memory length: 24090   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 132   score: 2.0   memory length: 24307   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 133   score: 2.0   memory length: 24506   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 134   score: 3.0   memory length: 24757   epsilon: 1.0    steps: 251    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 135   score: 0.0   memory length: 24880   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 136   score: 1.0   memory length: 25050   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 137   score: 2.0   memory length: 25249   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 138   score: 4.0   memory length: 25529   epsilon: 1.0    steps: 280    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 139   score: 0.0   memory length: 25653   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 140   score: 3.0   memory length: 25884   epsilon: 1.0    steps: 231    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 141   score: 4.0   memory length: 26145   epsilon: 1.0    steps: 261    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 142   score: 1.0   memory length: 26315   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 143   score: 1.0   memory length: 26487   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 144   score: 1.0   memory length: 26656   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 145   score: 0.0   memory length: 26779   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 146   score: 3.0   memory length: 27006   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 147   score: 3.0   memory length: 27254   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 148   score: 2.0   memory length: 27453   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 149   score: 1.0   memory length: 27622   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 150   score: 2.0   memory length: 27821   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 151   score: 3.0   memory length: 28048   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 152   score: 1.0   memory length: 28219   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 153   score: 2.0   memory length: 28438   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 154   score: 1.0   memory length: 28608   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 155   score: 0.0   memory length: 28732   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 156   score: 3.0   memory length: 29001   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 157   score: 3.0   memory length: 29248   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 158   score: 3.0   memory length: 29497   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 159   score: 1.0   memory length: 29666   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 160   score: 2.0   memory length: 29865   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 161   score: 0.0   memory length: 29989   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 162   score: 0.0   memory length: 30113   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 163   score: 0.0   memory length: 30236   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 164   score: 1.0   memory length: 30406   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 165   score: 3.0   memory length: 30672   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 166   score: 0.0   memory length: 30796   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 167   score: 0.0   memory length: 30920   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 168   score: 3.0   memory length: 31166   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 169   score: 3.0   memory length: 31436   epsilon: 1.0    steps: 270    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 170   score: 1.0   memory length: 31608   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 171   score: 2.0   memory length: 31811   epsilon: 1.0    steps: 203    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 172   score: 4.0   memory length: 32079   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 173   score: 1.0   memory length: 32248   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 174   score: 0.0   memory length: 32371   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 175   score: 1.0   memory length: 32541   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 176   score: 1.0   memory length: 32710   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 177   score: 0.0   memory length: 32833   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 178   score: 2.0   memory length: 33014   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 179   score: 2.0   memory length: 33231   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 180   score: 2.0   memory length: 33447   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 181   score: 5.0   memory length: 33771   epsilon: 1.0    steps: 324    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 182   score: 2.0   memory length: 33970   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 183   score: 2.0   memory length: 34169   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 184   score: 1.0   memory length: 34322   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 185   score: 1.0   memory length: 34473   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 186   score: 3.0   memory length: 34720   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 187   score: 1.0   memory length: 34890   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 188   score: 2.0   memory length: 35110   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 189   score: 0.0   memory length: 35233   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 190   score: 0.0   memory length: 35356   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 191   score: 1.0   memory length: 35508   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 192   score: 4.0   memory length: 35788   epsilon: 1.0    steps: 280    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 193   score: 0.0   memory length: 35912   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 194   score: 2.0   memory length: 36129   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 195   score: 1.0   memory length: 36281   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 196   score: 1.0   memory length: 36433   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 197   score: 0.0   memory length: 36557   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 198   score: 3.0   memory length: 36784   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 199   score: 2.0   memory length: 36968   epsilon: 1.0    steps: 184    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 200   score: 4.0   memory length: 37247   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 201   score: 0.0   memory length: 37371   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 202   score: 4.0   memory length: 37667   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 203   score: 1.0   memory length: 37836   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 204   score: 0.0   memory length: 37960   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 205   score: 2.0   memory length: 38160   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 206   score: 2.0   memory length: 38358   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 207   score: 2.0   memory length: 38540   epsilon: 1.0    steps: 182    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 208   score: 1.0   memory length: 38709   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 209   score: 0.0   memory length: 38833   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 210   score: 2.0   memory length: 39052   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 211   score: 3.0   memory length: 39299   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 212   score: 3.0   memory length: 39526   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 213   score: 2.0   memory length: 39725   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 214   score: 1.0   memory length: 39876   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 215   score: 1.0   memory length: 40045   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 216   score: 0.0   memory length: 40169   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 217   score: 1.0   memory length: 40339   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 218   score: 3.0   memory length: 40550   epsilon: 1.0    steps: 211    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 219   score: 1.0   memory length: 40703   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 220   score: 0.0   memory length: 40827   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 221   score: 0.0   memory length: 40951   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 222   score: 3.0   memory length: 41199   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 223   score: 2.0   memory length: 41397   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 224   score: 0.0   memory length: 41520   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 225   score: 2.0   memory length: 41742   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 226   score: 1.0   memory length: 41893   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 227   score: 1.0   memory length: 42065   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 228   score: 5.0   memory length: 42413   epsilon: 1.0    steps: 348    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 229   score: 1.0   memory length: 42583   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 230   score: 1.0   memory length: 42735   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 231   score: 2.0   memory length: 42956   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 232   score: 1.0   memory length: 43126   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 233   score: 0.0   memory length: 43250   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 234   score: 0.0   memory length: 43374   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 235   score: 0.0   memory length: 43498   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 236   score: 0.0   memory length: 43622   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 237   score: 0.0   memory length: 43746   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 238   score: 0.0   memory length: 43870   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 239   score: 0.0   memory length: 43993   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 240   score: 3.0   memory length: 44238   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 241   score: 2.0   memory length: 44421   epsilon: 1.0    steps: 183    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 242   score: 2.0   memory length: 44623   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 243   score: 3.0   memory length: 44871   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 244   score: 3.0   memory length: 45135   epsilon: 1.0    steps: 264    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 245   score: 1.0   memory length: 45305   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 246   score: 3.0   memory length: 45553   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 247   score: 3.0   memory length: 45798   epsilon: 1.0    steps: 245    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 248   score: 3.0   memory length: 46009   epsilon: 1.0    steps: 211    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 249   score: 3.0   memory length: 46255   epsilon: 1.0    steps: 246    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 250   score: 2.0   memory length: 46453   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 251   score: 0.0   memory length: 46577   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 252   score: 0.0   memory length: 46701   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 253   score: 2.0   memory length: 46923   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 254   score: 2.0   memory length: 47125   epsilon: 1.0    steps: 202    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 255   score: 4.0   memory length: 47446   epsilon: 1.0    steps: 321    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 256   score: 0.0   memory length: 47570   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 257   score: 4.0   memory length: 47866   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 258   score: 0.0   memory length: 47990   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 259   score: 4.0   memory length: 48287   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 260   score: 2.0   memory length: 48488   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 261   score: 2.0   memory length: 48687   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 262   score: 4.0   memory length: 48983   epsilon: 1.0    steps: 296    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 263   score: 1.0   memory length: 49153   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 264   score: 1.0   memory length: 49305   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 265   score: 4.0   memory length: 49581   epsilon: 1.0    steps: 276    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 266   score: 2.0   memory length: 49780   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 267   score: 1.0   memory length: 49932   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 268   score: 3.0   memory length: 50201   epsilon: 1.0    steps: 269    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 269   score: 3.0   memory length: 50430   epsilon: 1.0    steps: 229    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 270   score: 3.0   memory length: 50644   epsilon: 1.0    steps: 214    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 271   score: 2.0   memory length: 50844   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 272   score: 0.0   memory length: 50968   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 273   score: 0.0   memory length: 51092   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 274   score: 1.0   memory length: 51244   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 275   score: 0.0   memory length: 51367   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 276   score: 0.0   memory length: 51490   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 277   score: 2.0   memory length: 51708   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 278   score: 1.0   memory length: 51878   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 279   score: 0.0   memory length: 52002   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 280   score: 2.0   memory length: 52201   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 281   score: 1.0   memory length: 52372   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 282   score: 0.0   memory length: 52496   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 283   score: 2.0   memory length: 52718   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 284   score: 4.0   memory length: 52995   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 285   score: 2.0   memory length: 53194   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 286   score: 8.0   memory length: 53632   epsilon: 1.0    steps: 438    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 287   score: 2.0   memory length: 53851   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 288   score: 0.0   memory length: 53974   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 289   score: 2.0   memory length: 54173   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 290   score: 4.0   memory length: 54455   epsilon: 1.0    steps: 282    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 291   score: 2.0   memory length: 54674   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 292   score: 0.0   memory length: 54798   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 293   score: 1.0   memory length: 54950   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 294   score: 1.0   memory length: 55102   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 295   score: 2.0   memory length: 55301   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 296   score: 4.0   memory length: 55579   epsilon: 1.0    steps: 278    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 297   score: 0.0   memory length: 55703   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 298   score: 0.0   memory length: 55826   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 299   score: 1.0   memory length: 55978   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 300   score: 2.0   memory length: 56181   epsilon: 1.0    steps: 203    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 301   score: 2.0   memory length: 56380   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 302   score: 0.0   memory length: 56504   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 303   score: 0.0   memory length: 56628   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 304   score: 0.0   memory length: 56751   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 305   score: 2.0   memory length: 56970   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 306   score: 1.0   memory length: 57122   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 307   score: 3.0   memory length: 57349   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 308   score: 3.0   memory length: 57596   epsilon: 1.0    steps: 247    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 309   score: 5.0   memory length: 57919   epsilon: 1.0    steps: 323    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 310   score: 1.0   memory length: 58070   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 311   score: 2.0   memory length: 58268   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 312   score: 2.0   memory length: 58468   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 313   score: 1.0   memory length: 58619   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 314   score: 2.0   memory length: 58838   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 315   score: 0.0   memory length: 58962   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 316   score: 1.0   memory length: 59113   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 317   score: 0.0   memory length: 59236   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 318   score: 0.0   memory length: 59360   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 319   score: 2.0   memory length: 59559   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 320   score: 0.0   memory length: 59682   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 321   score: 3.0   memory length: 59910   epsilon: 1.0    steps: 228    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 322   score: 0.0   memory length: 60034   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 323   score: 0.0   memory length: 60158   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 324   score: 1.0   memory length: 60309   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 325   score: 1.0   memory length: 60482   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 326   score: 1.0   memory length: 60655   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 327   score: 0.0   memory length: 60779   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 328   score: 4.0   memory length: 61094   epsilon: 1.0    steps: 315    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 329   score: 4.0   memory length: 61373   epsilon: 1.0    steps: 279    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 330   score: 2.0   memory length: 61572   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 331   score: 3.0   memory length: 61799   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 332   score: 0.0   memory length: 61922   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 333   score: 1.0   memory length: 62074   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 334   score: 1.0   memory length: 62244   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 335   score: 3.0   memory length: 62511   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 336   score: 0.0   memory length: 62634   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 337   score: 2.0   memory length: 62853   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 338   score: 2.0   memory length: 63052   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 339   score: 2.0   memory length: 63250   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 340   score: 1.0   memory length: 63401   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 341   score: 1.0   memory length: 63553   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 342   score: 1.0   memory length: 63705   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 343   score: 1.0   memory length: 63857   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 344   score: 1.0   memory length: 64030   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 345   score: 2.0   memory length: 64229   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 346   score: 0.0   memory length: 64352   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 347   score: 0.0   memory length: 64475   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 348   score: 1.0   memory length: 64627   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 349   score: 1.0   memory length: 64779   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 350   score: 0.0   memory length: 64903   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 351   score: 1.0   memory length: 65054   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 352   score: 0.0   memory length: 65178   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 353   score: 0.0   memory length: 65302   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 354   score: 4.0   memory length: 65597   epsilon: 1.0    steps: 295    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 355   score: 2.0   memory length: 65796   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 356   score: 2.0   memory length: 65995   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 357   score: 1.0   memory length: 66165   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 358   score: 2.0   memory length: 66382   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 359   score: 0.0   memory length: 66506   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 360   score: 2.0   memory length: 66724   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 361   score: 2.0   memory length: 66943   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 362   score: 0.0   memory length: 67066   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 363   score: 2.0   memory length: 67285   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 364   score: 0.0   memory length: 67409   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 365   score: 2.0   memory length: 67627   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 366   score: 2.0   memory length: 67847   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 367   score: 0.0   memory length: 67970   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 368   score: 1.0   memory length: 68139   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 369   score: 2.0   memory length: 68358   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 370   score: 1.0   memory length: 68531   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 371   score: 3.0   memory length: 68798   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 372   score: 3.0   memory length: 69030   epsilon: 1.0    steps: 232    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 373   score: 3.0   memory length: 69257   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 374   score: 6.0   memory length: 69615   epsilon: 1.0    steps: 358    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 375   score: 2.0   memory length: 69814   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 376   score: 2.0   memory length: 70014   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 377   score: 2.0   memory length: 70213   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 378   score: 2.0   memory length: 70411   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 379   score: 2.0   memory length: 70630   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 380   score: 0.0   memory length: 70754   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 381   score: 3.0   memory length: 71003   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 382   score: 2.0   memory length: 71201   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 383   score: 0.0   memory length: 71324   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 384   score: 1.0   memory length: 71493   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 385   score: 2.0   memory length: 71692   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 386   score: 0.0   memory length: 71816   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 387   score: 0.0   memory length: 71940   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 388   score: 1.0   memory length: 72110   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 389   score: 4.0   memory length: 72387   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 390   score: 2.0   memory length: 72604   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 391   score: 1.0   memory length: 72774   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 392   score: 1.0   memory length: 72943   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 393   score: 2.0   memory length: 73141   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 394   score: 2.0   memory length: 73340   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 395   score: 0.0   memory length: 73463   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 396   score: 1.0   memory length: 73614   epsilon: 1.0    steps: 151    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 397   score: 4.0   memory length: 73911   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 398   score: 1.0   memory length: 74084   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 399   score: 0.0   memory length: 74208   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 400   score: 3.0   memory length: 74478   epsilon: 1.0    steps: 270    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 401   score: 0.0   memory length: 74602   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 402   score: 1.0   memory length: 74775   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 403   score: 1.0   memory length: 74945   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 404   score: 2.0   memory length: 75164   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 405   score: 2.0   memory length: 75363   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 406   score: 2.0   memory length: 75561   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 407   score: 1.0   memory length: 75713   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 408   score: 0.0   memory length: 75837   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 409   score: 3.0   memory length: 76068   epsilon: 1.0    steps: 231    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 410   score: 3.0   memory length: 76317   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 411   score: 2.0   memory length: 76518   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 412   score: 0.0   memory length: 76642   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 413   score: 3.0   memory length: 76892   epsilon: 1.0    steps: 250    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 414   score: 0.0   memory length: 77015   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 415   score: 2.0   memory length: 77232   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 416   score: 0.0   memory length: 77356   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 417   score: 2.0   memory length: 77574   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 418   score: 5.0   memory length: 77901   epsilon: 1.0    steps: 327    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 419   score: 1.0   memory length: 78053   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 420   score: 2.0   memory length: 78252   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 421   score: 1.0   memory length: 78404   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 422   score: 1.0   memory length: 78556   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 423   score: 2.0   memory length: 78773   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 424   score: 2.0   memory length: 78972   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 425   score: 1.0   memory length: 79124   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 426   score: 0.0   memory length: 79248   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 427   score: 0.0   memory length: 79372   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 428   score: 3.0   memory length: 79623   epsilon: 1.0    steps: 251    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 429   score: 1.0   memory length: 79775   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 430   score: 2.0   memory length: 79973   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 431   score: 3.0   memory length: 80221   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 432   score: 1.0   memory length: 80393   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 433   score: 1.0   memory length: 80565   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 434   score: 1.0   memory length: 80734   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 435   score: 0.0   memory length: 80858   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 436   score: 1.0   memory length: 81027   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 437   score: 0.0   memory length: 81151   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 438   score: 1.0   memory length: 81322   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 439   score: 1.0   memory length: 81474   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 440   score: 0.0   memory length: 81598   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 441   score: 2.0   memory length: 81778   epsilon: 1.0    steps: 180    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 442   score: 0.0   memory length: 81901   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 443   score: 2.0   memory length: 82099   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 444   score: 0.0   memory length: 82222   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 445   score: 2.0   memory length: 82421   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 446   score: 1.0   memory length: 82591   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 447   score: 1.0   memory length: 82745   epsilon: 1.0    steps: 154    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 448   score: 2.0   memory length: 82963   epsilon: 1.0    steps: 218    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 449   score: 0.0   memory length: 83087   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 450   score: 3.0   memory length: 83353   epsilon: 1.0    steps: 266    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 451   score: 3.0   memory length: 83568   epsilon: 1.0    steps: 215    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 452   score: 1.0   memory length: 83721   epsilon: 1.0    steps: 153    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 453   score: 2.0   memory length: 83940   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 454   score: 1.0   memory length: 84111   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 455   score: 0.0   memory length: 84235   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 456   score: 1.0   memory length: 84408   epsilon: 1.0    steps: 173    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 457   score: 1.0   memory length: 84578   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 458   score: 2.0   memory length: 84777   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 459   score: 4.0   memory length: 85074   epsilon: 1.0    steps: 297    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 460   score: 3.0   memory length: 85301   epsilon: 1.0    steps: 227    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 461   score: 1.0   memory length: 85453   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 462   score: 1.0   memory length: 85623   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 463   score: 1.0   memory length: 85795   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 464   score: 2.0   memory length: 86011   epsilon: 1.0    steps: 216    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 465   score: 1.0   memory length: 86180   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 466   score: 2.0   memory length: 86378   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 467   score: 4.0   memory length: 86655   epsilon: 1.0    steps: 277    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 468   score: 3.0   memory length: 86926   epsilon: 1.0    steps: 271    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 469   score: 1.0   memory length: 87096   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 470   score: 3.0   memory length: 87345   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 471   score: 2.0   memory length: 87545   epsilon: 1.0    steps: 200    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 472   score: 2.0   memory length: 87743   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 473   score: 2.0   memory length: 87924   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 474   score: 3.0   memory length: 88191   epsilon: 1.0    steps: 267    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 475   score: 1.0   memory length: 88362   epsilon: 1.0    steps: 171    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 476   score: 2.0   memory length: 88581   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 477   score: 0.0   memory length: 88705   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 478   score: 0.0   memory length: 88829   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 479   score: 5.0   memory length: 89156   epsilon: 1.0    steps: 327    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 480   score: 2.0   memory length: 89354   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 481   score: 3.0   memory length: 89602   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 482   score: 3.0   memory length: 89814   epsilon: 1.0    steps: 212    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 483   score: 0.0   memory length: 89938   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 484   score: 1.0   memory length: 90108   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 485   score: 2.0   memory length: 90306   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 486   score: 2.0   memory length: 90505   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 487   score: 0.0   memory length: 90628   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 488   score: 3.0   memory length: 90877   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 489   score: 0.0   memory length: 91001   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 490   score: 2.0   memory length: 91199   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 491   score: 2.0   memory length: 91420   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 492   score: 2.0   memory length: 91641   epsilon: 1.0    steps: 221    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 493   score: 2.0   memory length: 91863   epsilon: 1.0    steps: 222    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 494   score: 5.0   memory length: 92211   epsilon: 1.0    steps: 348    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 495   score: 1.0   memory length: 92363   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 496   score: 1.0   memory length: 92533   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 497   score: 2.0   memory length: 92752   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 498   score: 0.0   memory length: 92876   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 499   score: 2.0   memory length: 93096   epsilon: 1.0    steps: 220    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 500   score: 0.0   memory length: 93219   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 501   score: 0.0   memory length: 93343   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 502   score: 3.0   memory length: 93611   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 503   score: 2.0   memory length: 93809   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 504   score: 2.0   memory length: 94008   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 505   score: 0.0   memory length: 94132   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 506   score: 1.0   memory length: 94284   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 507   score: 3.0   memory length: 94533   epsilon: 1.0    steps: 249    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 508   score: 2.0   memory length: 94731   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 509   score: 0.0   memory length: 94855   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 510   score: 3.0   memory length: 95103   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 511   score: 4.0   memory length: 95423   epsilon: 1.0    steps: 320    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 512   score: 2.0   memory length: 95621   epsilon: 1.0    steps: 198    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 513   score: 2.0   memory length: 95820   epsilon: 1.0    steps: 199    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 514   score: 0.0   memory length: 95943   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 515   score: 3.0   memory length: 96211   epsilon: 1.0    steps: 268    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 516   score: 2.0   memory length: 96430   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 517   score: 0.0   memory length: 96553   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 518   score: 1.0   memory length: 96722   epsilon: 1.0    steps: 169    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 519   score: 1.0   memory length: 96894   epsilon: 1.0    steps: 172    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 520   score: 0.0   memory length: 97018   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 521   score: 2.0   memory length: 97235   epsilon: 1.0    steps: 217    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 522   score: 0.0   memory length: 97359   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 523   score: 3.0   memory length: 97607   epsilon: 1.0    steps: 248    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 524   score: 0.0   memory length: 97731   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 525   score: 1.0   memory length: 97901   epsilon: 1.0    steps: 170    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 526   score: 0.0   memory length: 98025   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 527   score: 4.0   memory length: 98283   epsilon: 1.0    steps: 258    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 528   score: 0.0   memory length: 98407   epsilon: 1.0    steps: 124    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 529   score: 2.0   memory length: 98626   epsilon: 1.0    steps: 219    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 530   score: 4.0   memory length: 98925   epsilon: 1.0    steps: 299    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 531   score: 2.0   memory length: 99106   epsilon: 1.0    steps: 181    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 532   score: 1.0   memory length: 99258   epsilon: 1.0    steps: 152    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 533   score: 0.0   memory length: 99381   epsilon: 1.0    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 534   score: 2.0   memory length: 99582   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 535   score: 2.0   memory length: 99783   epsilon: 1.0    steps: 201    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 536   score: 3.0   memory length: 100030   epsilon: 0.9999386200000013    steps: 247    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 537   score: 2.0   memory length: 100229   epsilon: 0.9995446000000099    steps: 199    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 538   score: 1.0   memory length: 100381   epsilon: 0.9992436400000164    steps: 152    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 539   score: 0.0   memory length: 100505   epsilon: 0.9989981200000217    steps: 124    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 540   score: 0.0   memory length: 100628   epsilon: 0.998754580000027    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 541   score: 2.0   memory length: 100845   epsilon: 0.9983249200000364    steps: 217    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 542   score: 0.0   memory length: 100968   epsilon: 0.9980813800000417    steps: 123    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 543   score: 0.0   memory length: 101092   epsilon: 0.997835860000047    steps: 124    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 544   score: 0.0   memory length: 101216   epsilon: 0.9975903400000523    steps: 124    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 545   score: 3.0   memory length: 101461   epsilon: 0.9971052400000628    steps: 245    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 546   score: 3.0   memory length: 101708   epsilon: 0.9966161800000735    steps: 247    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 547   score: 1.0   memory length: 101880   epsilon: 0.9962756200000809    steps: 172    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 548   score: 2.0   memory length: 102079   epsilon: 0.9958816000000894    steps: 199    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 549   score: 2.0   memory length: 102281   epsilon: 0.9954816400000981    steps: 202    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 550   score: 0.0   memory length: 102405   epsilon: 0.9952361200001034    steps: 124    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 551   score: 1.0   memory length: 102556   epsilon: 0.9949371400001099    steps: 151    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 552   score: 1.0   memory length: 102726   epsilon: 0.9946005400001172    steps: 170    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 553   score: 2.0   memory length: 102946   epsilon: 0.9941649400001267    steps: 220    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 554   score: 3.0   memory length: 103213   epsilon: 0.9936362800001382    steps: 267    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 555   score: 5.0   memory length: 103555   epsilon: 0.9929591200001529    steps: 342    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 556   score: 0.0   memory length: 103678   epsilon: 0.9927155800001581    steps: 123    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 557   score: 2.0   memory length: 103897   epsilon: 0.9922819600001676    steps: 219    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 558   score: 2.0   memory length: 104079   epsilon: 0.9919216000001754    steps: 182    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 559   score: 2.0   memory length: 104260   epsilon: 0.9915632200001832    steps: 181    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 560   score: 1.0   memory length: 104412   epsilon: 0.9912622600001897    steps: 152    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 561   score: 0.0   memory length: 104536   epsilon: 0.991016740000195    steps: 124    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 562   score: 0.0   memory length: 104660   epsilon: 0.9907712200002003    steps: 124    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 563   score: 1.0   memory length: 104832   epsilon: 0.9904306600002077    steps: 172    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 564   score: 4.0   memory length: 105132   epsilon: 0.9898366600002206    steps: 300    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 565   score: 2.0   memory length: 105315   epsilon: 0.9894743200002285    steps: 183    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 566   score: 0.0   memory length: 105439   epsilon: 0.9892288000002338    steps: 124    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 567   score: 4.0   memory length: 105735   epsilon: 0.9886427200002466    steps: 296    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 568   score: 2.0   memory length: 105954   epsilon: 0.988209100000256    steps: 219    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 569   score: 0.0   memory length: 106077   epsilon: 0.9879655600002613    steps: 123    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 570   score: 0.0   memory length: 106201   epsilon: 0.9877200400002666    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 571   score: 1.0   memory length: 106352   epsilon: 0.9874210600002731    steps: 151    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 572   score: 1.0   memory length: 106505   epsilon: 0.9871181200002797    steps: 153    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 573   score: 1.0   memory length: 106678   epsilon: 0.9867755800002871    steps: 173    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 574   score: 1.0   memory length: 106830   epsilon: 0.9864746200002936    steps: 152    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 575   score: 0.0   memory length: 106954   epsilon: 0.986229100000299    steps: 124    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 576   score: 0.0   memory length: 107078   epsilon: 0.9859835800003043    steps: 124    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 577   score: 2.0   memory length: 107298   epsilon: 0.9855479800003137    steps: 220    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 578   score: 0.0   memory length: 107422   epsilon: 0.9853024600003191    steps: 124    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 579   score: 3.0   memory length: 107671   epsilon: 0.9848094400003298    steps: 249    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 580   score: 1.0   memory length: 107841   epsilon: 0.9844728400003371    steps: 170    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 581   score: 3.0   memory length: 108087   epsilon: 0.9839857600003477    steps: 246    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 582   score: 1.0   memory length: 108258   epsilon: 0.983647180000355    steps: 171    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 583   score: 4.0   memory length: 108515   epsilon: 0.983138320000366    steps: 257    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 584   score: 1.0   memory length: 108685   epsilon: 0.9828017200003734    steps: 170    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 585   score: 1.0   memory length: 108854   epsilon: 0.9824671000003806    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 586   score: 1.0   memory length: 109027   epsilon: 0.9821245600003881    steps: 173    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 587   score: 3.0   memory length: 109276   epsilon: 0.9816315400003988    steps: 249    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 588   score: 0.0   memory length: 109400   epsilon: 0.9813860200004041    steps: 124    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 589   score: 2.0   memory length: 109599   epsilon: 0.9809920000004126    steps: 199    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 590   score: 1.0   memory length: 109769   epsilon: 0.98065540000042    steps: 170    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 591   score: 2.0   memory length: 109967   epsilon: 0.9802633600004285    steps: 198    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 592   score: 1.0   memory length: 110137   epsilon: 0.9799267600004358    steps: 170    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 593   score: 4.0   memory length: 110453   epsilon: 0.9793010800004494    steps: 316    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 594   score: 1.0   memory length: 110605   epsilon: 0.9790001200004559    steps: 152    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 595   score: 2.0   memory length: 110825   epsilon: 0.9785645200004653    steps: 220    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 596   score: 2.0   memory length: 111024   epsilon: 0.9781705000004739    steps: 199    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 597   score: 5.0   memory length: 111374   epsilon: 0.9774775000004889    steps: 350    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 598   score: 3.0   memory length: 111603   epsilon: 0.9770240800004988    steps: 229    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 599   score: 0.0   memory length: 111727   epsilon: 0.9767785600005041    steps: 124    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 600   score: 5.0   memory length: 112055   epsilon: 0.9761291200005182    steps: 328    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 601   score: 0.0   memory length: 112178   epsilon: 0.9758855800005235    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 602   score: 1.0   memory length: 112330   epsilon: 0.97558462000053    steps: 152    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 603   score: 1.0   memory length: 112483   epsilon: 0.9752816800005366    steps: 153    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 604   score: 3.0   memory length: 112727   epsilon: 0.9747985600005471    steps: 244    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 605   score: 2.0   memory length: 112946   epsilon: 0.9743649400005565    steps: 219    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 606   score: 0.0   memory length: 113070   epsilon: 0.9741194200005618    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 607   score: 2.0   memory length: 113271   epsilon: 0.9737214400005705    steps: 201    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 608   score: 3.0   memory length: 113502   epsilon: 0.9732640600005804    steps: 231    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 609   score: 0.0   memory length: 113626   epsilon: 0.9730185400005857    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 610   score: 2.0   memory length: 113824   epsilon: 0.9726265000005943    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 611   score: 0.0   memory length: 113948   epsilon: 0.9723809800005996    steps: 124    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 612   score: 1.0   memory length: 114119   epsilon: 0.9720424000006069    steps: 171    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 613   score: 3.0   memory length: 114386   epsilon: 0.9715137400006184    steps: 267    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 614   score: 3.0   memory length: 114635   epsilon: 0.9710207200006291    steps: 249    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 615   score: 0.0   memory length: 114758   epsilon: 0.9707771800006344    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 616   score: 1.0   memory length: 114910   epsilon: 0.9704762200006409    steps: 152    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 617   score: 4.0   memory length: 115185   epsilon: 0.9699317200006528    steps: 275    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 618   score: 0.0   memory length: 115308   epsilon: 0.969688180000658    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 619   score: 1.0   memory length: 115480   epsilon: 0.9693476200006654    steps: 172    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 620   score: 0.0   memory length: 115604   epsilon: 0.9691021000006708    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 621   score: 1.0   memory length: 115776   epsilon: 0.9687615400006782    steps: 172    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 622   score: 2.0   memory length: 115975   epsilon: 0.9683675200006867    steps: 199    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 623   score: 1.0   memory length: 116144   epsilon: 0.968032900000694    steps: 169    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 624   score: 5.0   memory length: 116487   epsilon: 0.9673537600007087    steps: 343    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 625   score: 3.0   memory length: 116698   epsilon: 0.9669359800007178    steps: 211    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 626   score: 2.0   memory length: 116916   epsilon: 0.9665043400007272    steps: 218    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 627   score: 2.0   memory length: 117135   epsilon: 0.9660707200007366    steps: 219    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 628   score: 3.0   memory length: 117362   epsilon: 0.9656212600007463    steps: 227    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 629   score: 1.0   memory length: 117533   epsilon: 0.9652826800007537    steps: 171    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 630   score: 2.0   memory length: 117749   epsilon: 0.964855000000763    steps: 216    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 631   score: 0.0   memory length: 117873   epsilon: 0.9646094800007683    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 632   score: 4.0   memory length: 118167   epsilon: 0.9640273600007809    steps: 294    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 633   score: 0.0   memory length: 118291   epsilon: 0.9637818400007863    steps: 124    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 634   score: 3.0   memory length: 118557   epsilon: 0.9632551600007977    steps: 266    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 635   score: 2.0   memory length: 118756   epsilon: 0.9628611400008062    steps: 199    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 636   score: 2.0   memory length: 118973   epsilon: 0.9624314800008156    steps: 217    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 637   score: 2.0   memory length: 119191   epsilon: 0.961999840000825    steps: 218    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 638   score: 0.0   memory length: 119315   epsilon: 0.9617543200008303    steps: 124    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 639   score: 0.0   memory length: 119438   epsilon: 0.9615107800008356    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 640   score: 1.0   memory length: 119590   epsilon: 0.9612098200008421    steps: 152    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 641   score: 1.0   memory length: 119742   epsilon: 0.9609088600008486    steps: 152    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 642   score: 2.0   memory length: 119940   epsilon: 0.9605168200008571    steps: 198    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 643   score: 2.0   memory length: 120138   epsilon: 0.9601247800008657    steps: 198    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 644   score: 0.0   memory length: 120261   epsilon: 0.9598812400008709    steps: 123    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 645   score: 0.0   memory length: 120385   epsilon: 0.9596357200008763    steps: 124    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 646   score: 2.0   memory length: 120583   epsilon: 0.9592436800008848    steps: 198    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 647   score: 1.0   memory length: 120735   epsilon: 0.9589427200008913    steps: 152    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 648   score: 0.0   memory length: 120858   epsilon: 0.9586991800008966    steps: 123    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 649   score: 1.0   memory length: 121029   epsilon: 0.958360600000904    steps: 171    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 650   score: 3.0   memory length: 121294   epsilon: 0.9578359000009153    steps: 265    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 651   score: 0.0   memory length: 121418   epsilon: 0.9575903800009207    steps: 124    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 652   score: 3.0   memory length: 121649   epsilon: 0.9571330000009306    steps: 231    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 653   score: 1.0   memory length: 121820   epsilon: 0.956794420000938    steps: 171    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 654   score: 2.0   memory length: 122043   epsilon: 0.9563528800009475    steps: 223    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 655   score: 0.0   memory length: 122166   epsilon: 0.9561093400009528    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 656   score: 1.0   memory length: 122319   epsilon: 0.9558064000009594    steps: 153    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 657   score: 0.0   memory length: 122443   epsilon: 0.9555608800009647    steps: 124    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 658   score: 2.0   memory length: 122644   epsilon: 0.9551629000009734    steps: 201    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 659   score: 1.0   memory length: 122796   epsilon: 0.9548619400009799    steps: 152    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 660   score: 0.0   memory length: 122920   epsilon: 0.9546164200009852    steps: 124    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 661   score: 3.0   memory length: 123166   epsilon: 0.9541293400009958    steps: 246    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 662   score: 2.0   memory length: 123364   epsilon: 0.9537373000010043    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 663   score: 0.0   memory length: 123487   epsilon: 0.9534937600010096    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 664   score: 0.0   memory length: 123611   epsilon: 0.9532482400010149    steps: 124    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 665   score: 7.0   memory length: 124021   epsilon: 0.9524364400010326    steps: 410    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 666   score: 2.0   memory length: 124222   epsilon: 0.9520384600010412    steps: 201    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 667   score: 2.0   memory length: 124421   epsilon: 0.9516444400010498    steps: 199    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 668   score: 1.0   memory length: 124595   epsilon: 0.9512999200010572    steps: 174    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 669   score: 2.0   memory length: 124816   epsilon: 0.9508623400010667    steps: 221    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 670   score: 1.0   memory length: 124967   epsilon: 0.9505633600010732    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 671   score: 0.0   memory length: 125090   epsilon: 0.9503198200010785    steps: 123    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 672   score: 1.0   memory length: 125260   epsilon: 0.9499832200010858    steps: 170    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 673   score: 2.0   memory length: 125459   epsilon: 0.9495892000010944    steps: 199    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 674   score: 1.0   memory length: 125630   epsilon: 0.9492506200011017    steps: 171    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 675   score: 2.0   memory length: 125815   epsilon: 0.9488843200011097    steps: 185    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 676   score: 2.0   memory length: 126032   epsilon: 0.948454660001119    steps: 217    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 677   score: 0.0   memory length: 126156   epsilon: 0.9482091400011243    steps: 124    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 678   score: 1.0   memory length: 126326   epsilon: 0.9478725400011316    steps: 170    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 679   score: 3.0   memory length: 126575   epsilon: 0.9473795200011423    steps: 249    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 680   score: 0.0   memory length: 126698   epsilon: 0.9471359800011476    steps: 123    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 681   score: 1.0   memory length: 126849   epsilon: 0.9468370000011541    steps: 151    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 682   score: 2.0   memory length: 127048   epsilon: 0.9464429800011627    steps: 199    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 683   score: 0.0   memory length: 127171   epsilon: 0.946199440001168    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 684   score: 1.0   memory length: 127341   epsilon: 0.9458628400011753    steps: 170    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 685   score: 4.0   memory length: 127639   epsilon: 0.9452728000011881    steps: 298    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 686   score: 4.0   memory length: 127957   epsilon: 0.9446431600012017    steps: 318    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 687   score: 2.0   memory length: 128156   epsilon: 0.9442491400012103    steps: 199    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 688   score: 3.0   memory length: 128385   epsilon: 0.9437957200012201    steps: 229    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 689   score: 1.0   memory length: 128555   epsilon: 0.9434591200012274    steps: 170    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 690   score: 3.0   memory length: 128787   epsilon: 0.9429997600012374    steps: 232    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 691   score: 1.0   memory length: 128939   epsilon: 0.942698800001244    steps: 152    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 692   score: 1.0   memory length: 129112   epsilon: 0.9423562600012514    steps: 173    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 693   score: 0.0   memory length: 129236   epsilon: 0.9421107400012567    steps: 124    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 694   score: 2.0   memory length: 129435   epsilon: 0.9417167200012653    steps: 199    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 695   score: 2.0   memory length: 129652   epsilon: 0.9412870600012746    steps: 217    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 696   score: 1.0   memory length: 129805   epsilon: 0.9409841200012812    steps: 153    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 697   score: 0.0   memory length: 129929   epsilon: 0.9407386000012865    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 698   score: 0.0   memory length: 130053   epsilon: 0.9404930800012918    steps: 124    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 699   score: 1.0   memory length: 130204   epsilon: 0.9401941000012983    steps: 151    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 700   score: 2.0   memory length: 130403   epsilon: 0.9398000800013069    steps: 199    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 701   score: 3.0   memory length: 130655   epsilon: 0.9393011200013177    steps: 252    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 702   score: 1.0   memory length: 130825   epsilon: 0.938964520001325    steps: 170    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 703   score: 0.0   memory length: 130949   epsilon: 0.9387190000013304    steps: 124    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 704   score: 3.0   memory length: 131196   epsilon: 0.938229940001341    steps: 247    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 705   score: 1.0   memory length: 131348   epsilon: 0.9379289800013475    steps: 152    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 706   score: 4.0   memory length: 131644   epsilon: 0.9373429000013602    steps: 296    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 707   score: 3.0   memory length: 131911   epsilon: 0.9368142400013717    steps: 267    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 708   score: 2.0   memory length: 132110   epsilon: 0.9364202200013803    steps: 199    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 709   score: 0.0   memory length: 132234   epsilon: 0.9361747000013856    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 710   score: 7.0   memory length: 132658   epsilon: 0.9353351800014038    steps: 424    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 711   score: 0.0   memory length: 132782   epsilon: 0.9350896600014091    steps: 124    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 712   score: 0.0   memory length: 132906   epsilon: 0.9348441400014145    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 713   score: 3.0   memory length: 133150   epsilon: 0.934361020001425    steps: 244    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 714   score: 0.0   memory length: 133274   epsilon: 0.9341155000014303    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 715   score: 1.0   memory length: 133444   epsilon: 0.9337789000014376    steps: 170    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 716   score: 1.0   memory length: 133616   epsilon: 0.933438340001445    steps: 172    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 717   score: 2.0   memory length: 133797   epsilon: 0.9330799600014528    steps: 181    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 718   score: 1.0   memory length: 133968   epsilon: 0.9327413800014601    steps: 171    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 719   score: 0.0   memory length: 134092   epsilon: 0.9324958600014654    steps: 124    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 720   score: 2.0   memory length: 134312   epsilon: 0.9320602600014749    steps: 220    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 721   score: 4.0   memory length: 134585   epsilon: 0.9315197200014866    steps: 273    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 722   score: 1.0   memory length: 134737   epsilon: 0.9312187600014932    steps: 152    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 723   score: 2.0   memory length: 134957   epsilon: 0.9307831600015026    steps: 220    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 724   score: 1.0   memory length: 135109   epsilon: 0.9304822000015092    steps: 152    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 725   score: 0.0   memory length: 135232   epsilon: 0.9302386600015145    steps: 123    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 726   score: 2.0   memory length: 135432   epsilon: 0.929842660001523    steps: 200    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 727   score: 0.0   memory length: 135556   epsilon: 0.9295971400015284    steps: 124    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 728   score: 0.0   memory length: 135680   epsilon: 0.9293516200015337    steps: 124    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 729   score: 1.0   memory length: 135832   epsilon: 0.9290506600015402    steps: 152    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 730   score: 2.0   memory length: 136033   epsilon: 0.9286526800015489    steps: 201    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 731   score: 3.0   memory length: 136259   epsilon: 0.9282052000015586    steps: 226    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 732   score: 3.0   memory length: 136507   epsilon: 0.9277141600015693    steps: 248    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 733   score: 3.0   memory length: 136754   epsilon: 0.9272251000015799    steps: 247    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 734   score: 0.0   memory length: 136878   epsilon: 0.9269795800015852    steps: 124    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 735   score: 2.0   memory length: 137094   epsilon: 0.9265519000015945    steps: 216    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 736   score: 2.0   memory length: 137293   epsilon: 0.926157880001603    steps: 199    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 737   score: 3.0   memory length: 137505   epsilon: 0.9257381200016122    steps: 212    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 738   score: 0.0   memory length: 137629   epsilon: 0.9254926000016175    steps: 124    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 739   score: 2.0   memory length: 137827   epsilon: 0.925100560001626    steps: 198    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 740   score: 0.0   memory length: 137951   epsilon: 0.9248550400016313    steps: 124    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 741   score: 1.0   memory length: 138121   epsilon: 0.9245184400016386    steps: 170    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 742   score: 1.0   memory length: 138273   epsilon: 0.9242174800016452    steps: 152    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 743   score: 0.0   memory length: 138397   epsilon: 0.9239719600016505    steps: 124    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 744   score: 3.0   memory length: 138645   epsilon: 0.9234809200016612    steps: 248    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 745   score: 1.0   memory length: 138814   epsilon: 0.9231463000016684    steps: 169    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 746   score: 4.0   memory length: 139110   epsilon: 0.9225602200016811    steps: 296    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 747   score: 2.0   memory length: 139310   epsilon: 0.9221642200016897    steps: 200    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 748   score: 2.0   memory length: 139508   epsilon: 0.9217721800016982    steps: 198    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 749   score: 2.0   memory length: 139727   epsilon: 0.9213385600017077    steps: 219    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 750   score: 1.0   memory length: 139898   epsilon: 0.920999980001715    steps: 171    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 751   score: 0.0   memory length: 140021   epsilon: 0.9207564400017203    steps: 123    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 752   score: 2.0   memory length: 140238   epsilon: 0.9203267800017296    steps: 217    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 753   score: 1.0   memory length: 140409   epsilon: 0.919988200001737    steps: 171    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 754   score: 1.0   memory length: 140582   epsilon: 0.9196456600017444    steps: 173    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 755   score: 1.0   memory length: 140735   epsilon: 0.919342720001751    steps: 153    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 756   score: 2.0   memory length: 140933   epsilon: 0.9189506800017595    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 757   score: 1.0   memory length: 141104   epsilon: 0.9186121000017669    steps: 171    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 758   score: 0.0   memory length: 141228   epsilon: 0.9183665800017722    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 759   score: 0.0   memory length: 141351   epsilon: 0.9181230400017775    steps: 123    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 760   score: 2.0   memory length: 141570   epsilon: 0.9176894200017869    steps: 219    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 761   score: 2.0   memory length: 141787   epsilon: 0.9172597600017962    steps: 217    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 762   score: 2.0   memory length: 141986   epsilon: 0.9168657400018048    steps: 199    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 763   score: 0.0   memory length: 142110   epsilon: 0.9166202200018101    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 764   score: 1.0   memory length: 142262   epsilon: 0.9163192600018166    steps: 152    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 765   score: 2.0   memory length: 142460   epsilon: 0.9159272200018251    steps: 198    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 766   score: 1.0   memory length: 142612   epsilon: 0.9156262600018317    steps: 152    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 767   score: 0.0   memory length: 142736   epsilon: 0.915380740001837    steps: 124    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 768   score: 0.0   memory length: 142860   epsilon: 0.9151352200018423    steps: 124    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 769   score: 0.0   memory length: 142983   epsilon: 0.9148916800018476    steps: 123    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 770   score: 4.0   memory length: 143296   epsilon: 0.9142719400018611    steps: 313    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 771   score: 4.0   memory length: 143594   epsilon: 0.9136819000018739    steps: 298    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 772   score: 0.0   memory length: 143717   epsilon: 0.9134383600018792    steps: 123    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 773   score: 3.0   memory length: 143946   epsilon: 0.912984940001889    steps: 229    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 774   score: 1.0   memory length: 144098   epsilon: 0.9126839800018955    steps: 152    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 775   score: 0.0   memory length: 144222   epsilon: 0.9124384600019009    steps: 124    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 776   score: 2.0   memory length: 144421   epsilon: 0.9120444400019094    steps: 199    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 777   score: 0.0   memory length: 144544   epsilon: 0.9118009000019147    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 778   score: 3.0   memory length: 144793   epsilon: 0.9113078800019254    steps: 249    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 779   score: 1.0   memory length: 144963   epsilon: 0.9109712800019327    steps: 170    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 780   score: 0.0   memory length: 145087   epsilon: 0.9107257600019381    steps: 124    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 781   score: 2.0   memory length: 145286   epsilon: 0.9103317400019466    steps: 199    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 782   score: 1.0   memory length: 145456   epsilon: 0.9099951400019539    steps: 170    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 783   score: 1.0   memory length: 145608   epsilon: 0.9096941800019605    steps: 152    lr: 0.0001     evaluation reward: 1.5\n",
      "episode: 784   score: 0.0   memory length: 145732   epsilon: 0.9094486600019658    steps: 124    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 785   score: 0.0   memory length: 145856   epsilon: 0.9092031400019711    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 786   score: 3.0   memory length: 146104   epsilon: 0.9087121000019818    steps: 248    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 787   score: 4.0   memory length: 146402   epsilon: 0.9081220600019946    steps: 298    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 788   score: 1.0   memory length: 146573   epsilon: 0.9077834800020019    steps: 171    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 789   score: 2.0   memory length: 146790   epsilon: 0.9073538200020113    steps: 217    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 790   score: 2.0   memory length: 146989   epsilon: 0.9069598000020198    steps: 199    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 791   score: 1.0   memory length: 147158   epsilon: 0.9066251800020271    steps: 169    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 792   score: 0.0   memory length: 147282   epsilon: 0.9063796600020324    steps: 124    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 793   score: 0.0   memory length: 147405   epsilon: 0.9061361200020377    steps: 123    lr: 0.0001     evaluation reward: 1.43\n",
      "episode: 794   score: 1.0   memory length: 147556   epsilon: 0.9058371400020442    steps: 151    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 795   score: 1.0   memory length: 147708   epsilon: 0.9055361800020507    steps: 152    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 796   score: 4.0   memory length: 148004   epsilon: 0.9049501000020634    steps: 296    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 797   score: 0.0   memory length: 148128   epsilon: 0.9047045800020688    steps: 124    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 798   score: 1.0   memory length: 148298   epsilon: 0.9043679800020761    steps: 170    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 799   score: 3.0   memory length: 148525   epsilon: 0.9039185200020858    steps: 227    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 800   score: 1.0   memory length: 148695   epsilon: 0.9035819200020931    steps: 170    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 801   score: 1.0   memory length: 148864   epsilon: 0.9032473000021004    steps: 169    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 802   score: 1.0   memory length: 149015   epsilon: 0.9029483200021069    steps: 151    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 803   score: 0.0   memory length: 149139   epsilon: 0.9027028000021122    steps: 124    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 804   score: 3.0   memory length: 149366   epsilon: 0.902253340002122    steps: 227    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 805   score: 1.0   memory length: 149538   epsilon: 0.9019127800021294    steps: 172    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 806   score: 1.0   memory length: 149708   epsilon: 0.9015761800021367    steps: 170    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 807   score: 3.0   memory length: 149956   epsilon: 0.9010851400021473    steps: 248    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 808   score: 2.0   memory length: 150179   epsilon: 0.9006436000021569    steps: 223    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 809   score: 0.0   memory length: 150303   epsilon: 0.9003980800021623    steps: 124    lr: 0.0001     evaluation reward: 1.41\n",
      "episode: 810   score: 1.0   memory length: 150473   epsilon: 0.9000614800021696    steps: 170    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 811   score: 2.0   memory length: 150672   epsilon: 0.8996674600021781    steps: 199    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 812   score: 1.0   memory length: 150842   epsilon: 0.8993308600021854    steps: 170    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 813   score: 1.0   memory length: 151012   epsilon: 0.8989942600021927    steps: 170    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 814   score: 0.0   memory length: 151136   epsilon: 0.8987487400021981    steps: 124    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 815   score: 1.0   memory length: 151308   epsilon: 0.8984081800022055    steps: 172    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 816   score: 2.0   memory length: 151506   epsilon: 0.898016140002214    steps: 198    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 817   score: 0.0   memory length: 151629   epsilon: 0.8977726000022193    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 818   score: 4.0   memory length: 151889   epsilon: 0.8972578000022304    steps: 260    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 819   score: 0.0   memory length: 152013   epsilon: 0.8970122800022358    steps: 124    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 820   score: 4.0   memory length: 152305   epsilon: 0.8964341200022483    steps: 292    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 821   score: 1.0   memory length: 152474   epsilon: 0.8960995000022556    steps: 169    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 822   score: 0.0   memory length: 152597   epsilon: 0.8958559600022609    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 823   score: 2.0   memory length: 152815   epsilon: 0.8954243200022702    steps: 218    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 824   score: 0.0   memory length: 152939   epsilon: 0.8951788000022756    steps: 124    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 825   score: 7.0   memory length: 153360   epsilon: 0.8943452200022937    steps: 421    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 826   score: 4.0   memory length: 153672   epsilon: 0.8937274600023071    steps: 312    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 827   score: 1.0   memory length: 153824   epsilon: 0.8934265000023136    steps: 152    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 828   score: 0.0   memory length: 153948   epsilon: 0.8931809800023189    steps: 124    lr: 0.0001     evaluation reward: 1.45\n",
      "episode: 829   score: 0.0   memory length: 154072   epsilon: 0.8929354600023243    steps: 124    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 830   score: 2.0   memory length: 154275   epsilon: 0.892533520002333    steps: 203    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 831   score: 1.0   memory length: 154426   epsilon: 0.8922345400023395    steps: 151    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 832   score: 0.0   memory length: 154550   epsilon: 0.8919890200023448    steps: 124    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 833   score: 2.0   memory length: 154769   epsilon: 0.8915554000023542    steps: 219    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 834   score: 0.0   memory length: 154893   epsilon: 0.8913098800023596    steps: 124    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 835   score: 2.0   memory length: 155092   epsilon: 0.8909158600023681    steps: 199    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 836   score: 0.0   memory length: 155215   epsilon: 0.8906723200023734    steps: 123    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 837   score: 0.0   memory length: 155339   epsilon: 0.8904268000023787    steps: 124    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 838   score: 1.0   memory length: 155509   epsilon: 0.890090200002386    steps: 170    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 839   score: 0.0   memory length: 155633   epsilon: 0.8898446800023914    steps: 124    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 840   score: 1.0   memory length: 155802   epsilon: 0.8895100600023986    steps: 169    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 841   score: 0.0   memory length: 155925   epsilon: 0.8892665200024039    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 842   score: 0.0   memory length: 156049   epsilon: 0.8890210000024092    steps: 124    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 843   score: 1.0   memory length: 156219   epsilon: 0.8886844000024166    steps: 170    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 844   score: 2.0   memory length: 156441   epsilon: 0.8882448400024261    steps: 222    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 845   score: 3.0   memory length: 156668   epsilon: 0.8877953800024359    steps: 227    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 846   score: 1.0   memory length: 156837   epsilon: 0.8874607600024431    steps: 169    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 847   score: 3.0   memory length: 157064   epsilon: 0.8870113000024529    steps: 227    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 848   score: 2.0   memory length: 157282   epsilon: 0.8865796600024622    steps: 218    lr: 0.0001     evaluation reward: 1.31\n",
      "episode: 849   score: 4.0   memory length: 157575   epsilon: 0.8859995200024748    steps: 293    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 850   score: 4.0   memory length: 157853   epsilon: 0.8854490800024868    steps: 278    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 851   score: 0.0   memory length: 157977   epsilon: 0.8852035600024921    steps: 124    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 852   score: 0.0   memory length: 158101   epsilon: 0.8849580400024974    steps: 124    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 853   score: 0.0   memory length: 158225   epsilon: 0.8847125200025028    steps: 124    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 854   score: 2.0   memory length: 158444   epsilon: 0.8842789000025122    steps: 219    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 855   score: 3.0   memory length: 158671   epsilon: 0.883829440002522    steps: 227    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 856   score: 0.0   memory length: 158795   epsilon: 0.8835839200025273    steps: 124    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 857   score: 2.0   memory length: 159015   epsilon: 0.8831483200025367    steps: 220    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 858   score: 2.0   memory length: 159233   epsilon: 0.8827166800025461    steps: 218    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 859   score: 0.0   memory length: 159357   epsilon: 0.8824711600025514    steps: 124    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 860   score: 0.0   memory length: 159480   epsilon: 0.8822276200025567    steps: 123    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 861   score: 0.0   memory length: 159604   epsilon: 0.881982100002562    steps: 124    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 862   score: 1.0   memory length: 159774   epsilon: 0.8816455000025694    steps: 170    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 863   score: 2.0   memory length: 159993   epsilon: 0.8812118800025788    steps: 219    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 864   score: 2.0   memory length: 160192   epsilon: 0.8808178600025873    steps: 199    lr: 0.0001     evaluation reward: 1.35\n",
      "episode: 865   score: 0.0   memory length: 160316   epsilon: 0.8805723400025927    steps: 124    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 866   score: 1.0   memory length: 160469   epsilon: 0.8802694000025992    steps: 153    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 867   score: 3.0   memory length: 160734   epsilon: 0.8797447000026106    steps: 265    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 868   score: 1.0   memory length: 160905   epsilon: 0.879406120002618    steps: 171    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 869   score: 1.0   memory length: 161077   epsilon: 0.8790655600026254    steps: 172    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 870   score: 0.0   memory length: 161200   epsilon: 0.8788220200026307    steps: 123    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 871   score: 3.0   memory length: 161448   epsilon: 0.8783309800026413    steps: 248    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 872   score: 3.0   memory length: 161696   epsilon: 0.877839940002652    steps: 248    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 873   score: 1.0   memory length: 161865   epsilon: 0.8775053200026592    steps: 169    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 874   score: 0.0   memory length: 161989   epsilon: 0.8772598000026646    steps: 124    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 875   score: 3.0   memory length: 162237   epsilon: 0.8767687600026752    steps: 248    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 876   score: 2.0   memory length: 162455   epsilon: 0.8763371200026846    steps: 218    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 877   score: 1.0   memory length: 162607   epsilon: 0.8760361600026911    steps: 152    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 878   score: 0.0   memory length: 162731   epsilon: 0.8757906400026965    steps: 124    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 879   score: 1.0   memory length: 162900   epsilon: 0.8754560200027037    steps: 169    lr: 0.0001     evaluation reward: 1.34\n",
      "episode: 880   score: 3.0   memory length: 163168   epsilon: 0.8749253800027152    steps: 268    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 881   score: 2.0   memory length: 163366   epsilon: 0.8745333400027238    steps: 198    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 882   score: 0.0   memory length: 163490   epsilon: 0.8742878200027291    steps: 124    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 883   score: 1.0   memory length: 163660   epsilon: 0.8739512200027364    steps: 170    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 884   score: 0.0   memory length: 163784   epsilon: 0.8737057000027417    steps: 124    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 885   score: 2.0   memory length: 163982   epsilon: 0.8733136600027502    steps: 198    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 886   score: 2.0   memory length: 164199   epsilon: 0.8728840000027596    steps: 217    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 887   score: 0.0   memory length: 164322   epsilon: 0.8726404600027649    steps: 123    lr: 0.0001     evaluation reward: 1.33\n",
      "episode: 888   score: 0.0   memory length: 164445   epsilon: 0.8723969200027701    steps: 123    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 889   score: 2.0   memory length: 164643   epsilon: 0.8720048800027786    steps: 198    lr: 0.0001     evaluation reward: 1.32\n",
      "episode: 890   score: 0.0   memory length: 164766   epsilon: 0.8717613400027839    steps: 123    lr: 0.0001     evaluation reward: 1.3\n",
      "episode: 891   score: 7.0   memory length: 165128   epsilon: 0.8710445800027995    steps: 362    lr: 0.0001     evaluation reward: 1.36\n",
      "episode: 892   score: 2.0   memory length: 165326   epsilon: 0.870652540002808    steps: 198    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 893   score: 0.0   memory length: 165449   epsilon: 0.8704090000028133    steps: 123    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 894   score: 1.0   memory length: 165619   epsilon: 0.8700724000028206    steps: 170    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 895   score: 1.0   memory length: 165790   epsilon: 0.869733820002828    steps: 171    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 896   score: 3.0   memory length: 166036   epsilon: 0.8692467400028385    steps: 246    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 897   score: 0.0   memory length: 166160   epsilon: 0.8690012200028439    steps: 124    lr: 0.0001     evaluation reward: 1.37\n",
      "episode: 898   score: 4.0   memory length: 166458   epsilon: 0.8684111800028567    steps: 298    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 899   score: 1.0   memory length: 166629   epsilon: 0.868072600002864    steps: 171    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 900   score: 2.0   memory length: 166828   epsilon: 0.8676785800028726    steps: 199    lr: 0.0001     evaluation reward: 1.39\n",
      "episode: 901   score: 0.0   memory length: 166952   epsilon: 0.8674330600028779    steps: 124    lr: 0.0001     evaluation reward: 1.38\n",
      "episode: 902   score: 3.0   memory length: 167184   epsilon: 0.8669737000028879    steps: 232    lr: 0.0001     evaluation reward: 1.4\n",
      "episode: 903   score: 2.0   memory length: 167383   epsilon: 0.8665796800028964    steps: 199    lr: 0.0001     evaluation reward: 1.42\n",
      "episode: 904   score: 5.0   memory length: 167709   epsilon: 0.8659342000029104    steps: 326    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 905   score: 1.0   memory length: 167860   epsilon: 0.8656352200029169    steps: 151    lr: 0.0001     evaluation reward: 1.44\n",
      "episode: 906   score: 3.0   memory length: 168107   epsilon: 0.8651461600029275    steps: 247    lr: 0.0001     evaluation reward: 1.46\n",
      "episode: 907   score: 8.0   memory length: 168476   epsilon: 0.8644155400029434    steps: 369    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 908   score: 0.0   memory length: 168599   epsilon: 0.8641720000029487    steps: 123    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 909   score: 2.0   memory length: 168798   epsilon: 0.8637779800029572    steps: 199    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 910   score: 1.0   memory length: 168950   epsilon: 0.8634770200029638    steps: 152    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 911   score: 2.0   memory length: 169149   epsilon: 0.8630830000029723    steps: 199    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 912   score: 3.0   memory length: 169420   epsilon: 0.862546420002984    steps: 271    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 913   score: 4.0   memory length: 169698   epsilon: 0.8619959800029959    steps: 278    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 914   score: 1.0   memory length: 169868   epsilon: 0.8616593800030032    steps: 170    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 915   score: 0.0   memory length: 169992   epsilon: 0.8614138600030086    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 916   score: 4.0   memory length: 170309   epsilon: 0.8607862000030222    steps: 317    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 917   score: 1.0   memory length: 170460   epsilon: 0.8604872200030287    steps: 151    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 918   score: 0.0   memory length: 170584   epsilon: 0.860241700003034    steps: 124    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 919   score: 3.0   memory length: 170831   epsilon: 0.8597526400030446    steps: 247    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 920   score: 0.0   memory length: 170954   epsilon: 0.8595091000030499    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 921   score: 3.0   memory length: 171199   epsilon: 0.8590240000030605    steps: 245    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 922   score: 0.0   memory length: 171323   epsilon: 0.8587784800030658    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 923   score: 3.0   memory length: 171550   epsilon: 0.8583290200030755    steps: 227    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 924   score: 0.0   memory length: 171674   epsilon: 0.8580835000030809    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 925   score: 1.0   memory length: 171846   epsilon: 0.8577429400030883    steps: 172    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 926   score: 2.0   memory length: 172064   epsilon: 0.8573113000030976    steps: 218    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 927   score: 1.0   memory length: 172233   epsilon: 0.8569766800031049    steps: 169    lr: 0.0001     evaluation reward: 1.49\n",
      "episode: 928   score: 3.0   memory length: 172505   epsilon: 0.8564381200031166    steps: 272    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 929   score: 2.0   memory length: 172704   epsilon: 0.8560441000031251    steps: 199    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 930   score: 2.0   memory length: 172905   epsilon: 0.8556461200031338    steps: 201    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 931   score: 3.0   memory length: 173152   epsilon: 0.8551570600031444    steps: 247    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 932   score: 3.0   memory length: 173399   epsilon: 0.854668000003155    steps: 247    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 933   score: 3.0   memory length: 173626   epsilon: 0.8542185400031648    steps: 227    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 934   score: 0.0   memory length: 173750   epsilon: 0.8539730200031701    steps: 124    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 935   score: 1.0   memory length: 173923   epsilon: 0.8536304800031775    steps: 173    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 936   score: 3.0   memory length: 174137   epsilon: 0.8532067600031867    steps: 214    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 937   score: 1.0   memory length: 174289   epsilon: 0.8529058000031933    steps: 152    lr: 0.0001     evaluation reward: 1.63\n",
      "episode: 938   score: 2.0   memory length: 174489   epsilon: 0.8525098000032019    steps: 200    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 939   score: 4.0   memory length: 174807   epsilon: 0.8518801600032155    steps: 318    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 940   score: 2.0   memory length: 175028   epsilon: 0.851442580003225    steps: 221    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 941   score: 0.0   memory length: 175151   epsilon: 0.8511990400032303    steps: 123    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 942   score: 3.0   memory length: 175360   epsilon: 0.8507852200032393    steps: 209    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 943   score: 2.0   memory length: 175542   epsilon: 0.8504248600032471    steps: 182    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 944   score: 0.0   memory length: 175666   epsilon: 0.8501793400032525    steps: 124    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 945   score: 3.0   memory length: 175939   epsilon: 0.8496388000032642    steps: 273    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 946   score: 7.0   memory length: 176222   epsilon: 0.8490784600032764    steps: 283    lr: 0.0001     evaluation reward: 1.77\n",
      "episode: 947   score: 1.0   memory length: 176375   epsilon: 0.8487755200032829    steps: 153    lr: 0.0001     evaluation reward: 1.75\n",
      "episode: 948   score: 3.0   memory length: 176622   epsilon: 0.8482864600032936    steps: 247    lr: 0.0001     evaluation reward: 1.76\n",
      "episode: 949   score: 2.0   memory length: 176824   epsilon: 0.8478865000033022    steps: 202    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 950   score: 0.0   memory length: 176947   epsilon: 0.8476429600033075    steps: 123    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 951   score: 0.0   memory length: 177071   epsilon: 0.8473974400033129    steps: 124    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 952   score: 1.0   memory length: 177242   epsilon: 0.8470588600033202    steps: 171    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 953   score: 0.0   memory length: 177366   epsilon: 0.8468133400033255    steps: 124    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 954   score: 2.0   memory length: 177584   epsilon: 0.8463817000033349    steps: 218    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 955   score: 2.0   memory length: 177783   epsilon: 0.8459876800033435    steps: 199    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 956   score: 1.0   memory length: 177934   epsilon: 0.84568870000335    steps: 151    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 957   score: 0.0   memory length: 178058   epsilon: 0.8454431800033553    steps: 124    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 958   score: 2.0   memory length: 178257   epsilon: 0.8450491600033638    steps: 199    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 959   score: 1.0   memory length: 178427   epsilon: 0.8447125600033711    steps: 170    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 960   score: 2.0   memory length: 178627   epsilon: 0.8443165600033797    steps: 200    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 961   score: 1.0   memory length: 178797   epsilon: 0.843979960003387    steps: 170    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 962   score: 2.0   memory length: 178996   epsilon: 0.8435859400033956    steps: 199    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 963   score: 0.0   memory length: 179120   epsilon: 0.8433404200034009    steps: 124    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 964   score: 0.0   memory length: 179244   epsilon: 0.8430949000034063    steps: 124    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 965   score: 0.0   memory length: 179367   epsilon: 0.8428513600034115    steps: 123    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 966   score: 1.0   memory length: 179538   epsilon: 0.8425127800034189    steps: 171    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 967   score: 0.0   memory length: 179662   epsilon: 0.8422672600034242    steps: 124    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 968   score: 0.0   memory length: 179786   epsilon: 0.8420217400034296    steps: 124    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 969   score: 2.0   memory length: 180007   epsilon: 0.841584160003439    steps: 221    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 970   score: 5.0   memory length: 180327   epsilon: 0.8409505600034528    steps: 320    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 971   score: 1.0   memory length: 180479   epsilon: 0.8406496000034593    steps: 152    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 972   score: 2.0   memory length: 180660   epsilon: 0.8402912200034671    steps: 181    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 973   score: 1.0   memory length: 180830   epsilon: 0.8399546200034744    steps: 170    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 974   score: 3.0   memory length: 181078   epsilon: 0.8394635800034851    steps: 248    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 975   score: 3.0   memory length: 181328   epsilon: 0.8389685800034958    steps: 250    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 976   score: 2.0   memory length: 181527   epsilon: 0.8385745600035044    steps: 199    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 977   score: 1.0   memory length: 181697   epsilon: 0.8382379600035117    steps: 170    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 978   score: 2.0   memory length: 181915   epsilon: 0.8378063200035211    steps: 218    lr: 0.0001     evaluation reward: 1.74\n",
      "episode: 979   score: 0.0   memory length: 182039   epsilon: 0.8375608000035264    steps: 124    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 980   score: 2.0   memory length: 182255   epsilon: 0.8371331200035357    steps: 216    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 981   score: 2.0   memory length: 182456   epsilon: 0.8367351400035443    steps: 201    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 982   score: 0.0   memory length: 182580   epsilon: 0.8364896200035496    steps: 124    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 983   score: 0.0   memory length: 182703   epsilon: 0.8362460800035549    steps: 123    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 984   score: 2.0   memory length: 182902   epsilon: 0.8358520600035635    steps: 199    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 985   score: 2.0   memory length: 183119   epsilon: 0.8354224000035728    steps: 217    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 986   score: 0.0   memory length: 183243   epsilon: 0.8351768800035781    steps: 124    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 987   score: 0.0   memory length: 183366   epsilon: 0.8349333400035834    steps: 123    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 988   score: 2.0   memory length: 183585   epsilon: 0.8344997200035928    steps: 219    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 989   score: 0.0   memory length: 183709   epsilon: 0.8342542000035982    steps: 124    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 990   score: 2.0   memory length: 183928   epsilon: 0.8338205800036076    steps: 219    lr: 0.0001     evaluation reward: 1.73\n",
      "episode: 991   score: 0.0   memory length: 184052   epsilon: 0.8335750600036129    steps: 124    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 992   score: 2.0   memory length: 184251   epsilon: 0.8331810400036215    steps: 199    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 993   score: 3.0   memory length: 184499   epsilon: 0.8326900000036321    steps: 248    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 994   score: 2.0   memory length: 184717   epsilon: 0.8322583600036415    steps: 218    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 995   score: 2.0   memory length: 184916   epsilon: 0.8318643400036501    steps: 199    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 996   score: 1.0   memory length: 185088   epsilon: 0.8315237800036575    steps: 172    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 997   score: 3.0   memory length: 185336   epsilon: 0.8310327400036681    steps: 248    lr: 0.0001     evaluation reward: 1.72\n",
      "episode: 998   score: 2.0   memory length: 185535   epsilon: 0.8306387200036767    steps: 199    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 999   score: 2.0   memory length: 185734   epsilon: 0.8302447000036852    steps: 199    lr: 0.0001     evaluation reward: 1.71\n",
      "episode: 1000   score: 0.0   memory length: 185858   epsilon: 0.8299991800036906    steps: 124    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 1001   score: 1.0   memory length: 186028   epsilon: 0.8296625800036979    steps: 170    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 1002   score: 2.0   memory length: 186226   epsilon: 0.8292705400037064    steps: 198    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 1003   score: 3.0   memory length: 186454   epsilon: 0.8288191000037162    steps: 228    lr: 0.0001     evaluation reward: 1.7\n",
      "episode: 1004   score: 2.0   memory length: 186652   epsilon: 0.8284270600037247    steps: 198    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1005   score: 0.0   memory length: 186775   epsilon: 0.82818352000373    steps: 123    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 1006   score: 3.0   memory length: 187043   epsilon: 0.8276528800037415    steps: 268    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 1007   score: 1.0   memory length: 187195   epsilon: 0.827351920003748    steps: 152    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1008   score: 2.0   memory length: 187393   epsilon: 0.8269598800037565    steps: 198    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 1009   score: 0.0   memory length: 187517   epsilon: 0.8267143600037619    steps: 124    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1010   score: 1.0   memory length: 187687   epsilon: 0.8263777600037692    steps: 170    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1011   score: 2.0   memory length: 187886   epsilon: 0.8259837400037777    steps: 199    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1012   score: 2.0   memory length: 188084   epsilon: 0.8255917000037862    steps: 198    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 1013   score: 2.0   memory length: 188303   epsilon: 0.8251580800037956    steps: 219    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 1014   score: 2.0   memory length: 188501   epsilon: 0.8247660400038042    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1015   score: 2.0   memory length: 188720   epsilon: 0.8243324200038136    steps: 219    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1016   score: 2.0   memory length: 188942   epsilon: 0.8238928600038231    steps: 222    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1017   score: 0.0   memory length: 189066   epsilon: 0.8236473400038284    steps: 124    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 1018   score: 2.0   memory length: 189248   epsilon: 0.8232869800038363    steps: 182    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 1019   score: 4.0   memory length: 189525   epsilon: 0.8227385200038482    steps: 277    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1020   score: 0.0   memory length: 189649   epsilon: 0.8224930000038535    steps: 124    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1021   score: 1.0   memory length: 189819   epsilon: 0.8221564000038608    steps: 170    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1022   score: 2.0   memory length: 190018   epsilon: 0.8217623800038694    steps: 199    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1023   score: 2.0   memory length: 190237   epsilon: 0.8213287600038788    steps: 219    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 1024   score: 2.0   memory length: 190455   epsilon: 0.8208971200038881    steps: 218    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1025   score: 2.0   memory length: 190653   epsilon: 0.8205050800038967    steps: 198    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 1026   score: 1.0   memory length: 190825   epsilon: 0.820164520003904    steps: 172    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1027   score: 2.0   memory length: 191024   epsilon: 0.8197705000039126    steps: 199    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 1028   score: 2.0   memory length: 191243   epsilon: 0.819336880003922    steps: 219    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1029   score: 0.0   memory length: 191367   epsilon: 0.8190913600039273    steps: 124    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 1030   score: 2.0   memory length: 191567   epsilon: 0.818695360003936    steps: 200    lr: 0.0001     evaluation reward: 1.58\n",
      "episode: 1031   score: 2.0   memory length: 191765   epsilon: 0.8183033200039445    steps: 198    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1032   score: 3.0   memory length: 192012   epsilon: 0.8178142600039551    steps: 247    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1033   score: 0.0   memory length: 192135   epsilon: 0.8175707200039604    steps: 123    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 1034   score: 6.0   memory length: 192509   epsilon: 0.8168302000039764    steps: 374    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1035   score: 1.0   memory length: 192662   epsilon: 0.816527260003983    steps: 153    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1036   score: 3.0   memory length: 192891   epsilon: 0.8160738400039929    steps: 229    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1037   score: 2.0   memory length: 193112   epsilon: 0.8156362600040024    steps: 221    lr: 0.0001     evaluation reward: 1.61\n",
      "episode: 1038   score: 3.0   memory length: 193382   epsilon: 0.815101660004014    steps: 270    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 1039   score: 1.0   memory length: 193551   epsilon: 0.8147670400040212    steps: 169    lr: 0.0001     evaluation reward: 1.59\n",
      "episode: 1040   score: 0.0   memory length: 193675   epsilon: 0.8145215200040266    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1041   score: 0.0   memory length: 193799   epsilon: 0.8142760000040319    steps: 124    lr: 0.0001     evaluation reward: 1.57\n",
      "episode: 1042   score: 0.0   memory length: 193923   epsilon: 0.8140304800040372    steps: 124    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 1043   score: 2.0   memory length: 194122   epsilon: 0.8136364600040458    steps: 199    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 1044   score: 2.0   memory length: 194343   epsilon: 0.8131988800040553    steps: 221    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 1045   score: 1.0   memory length: 194495   epsilon: 0.8128979200040618    steps: 152    lr: 0.0001     evaluation reward: 1.54\n",
      "episode: 1046   score: 1.0   memory length: 194665   epsilon: 0.8125613200040691    steps: 170    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 1047   score: 1.0   memory length: 194835   epsilon: 0.8122247200040764    steps: 170    lr: 0.0001     evaluation reward: 1.48\n",
      "episode: 1048   score: 2.0   memory length: 195052   epsilon: 0.8117950600040857    steps: 217    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 1049   score: 2.0   memory length: 195251   epsilon: 0.8114010400040943    steps: 199    lr: 0.0001     evaluation reward: 1.47\n",
      "episode: 1050   score: 4.0   memory length: 195548   epsilon: 0.8108129800041071    steps: 297    lr: 0.0001     evaluation reward: 1.51\n",
      "episode: 1051   score: 1.0   memory length: 195719   epsilon: 0.8104744000041144    steps: 171    lr: 0.0001     evaluation reward: 1.52\n",
      "episode: 1052   score: 2.0   memory length: 195918   epsilon: 0.810080380004123    steps: 199    lr: 0.0001     evaluation reward: 1.53\n",
      "episode: 1053   score: 2.0   memory length: 196116   epsilon: 0.8096883400041315    steps: 198    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 1054   score: 2.0   memory length: 196335   epsilon: 0.8092547200041409    steps: 219    lr: 0.0001     evaluation reward: 1.55\n",
      "episode: 1055   score: 3.0   memory length: 196582   epsilon: 0.8087656600041515    steps: 247    lr: 0.0001     evaluation reward: 1.56\n",
      "episode: 1056   score: 5.0   memory length: 196908   epsilon: 0.8081201800041655    steps: 326    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1057   score: 0.0   memory length: 197032   epsilon: 0.8078746600041709    steps: 124    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1058   score: 2.0   memory length: 197232   epsilon: 0.8074786600041794    steps: 200    lr: 0.0001     evaluation reward: 1.6\n",
      "episode: 1059   score: 3.0   memory length: 197483   epsilon: 0.8069816800041902    steps: 251    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 1060   score: 2.0   memory length: 197702   epsilon: 0.8065480600041997    steps: 219    lr: 0.0001     evaluation reward: 1.62\n",
      "episode: 1061   score: 3.0   memory length: 197968   epsilon: 0.8060213800042111    steps: 266    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 1062   score: 2.0   memory length: 198190   epsilon: 0.8055818200042206    steps: 222    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 1063   score: 0.0   memory length: 198314   epsilon: 0.805336300004226    steps: 124    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 1064   score: 2.0   memory length: 198515   epsilon: 0.8049383200042346    steps: 201    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 1065   score: 0.0   memory length: 198639   epsilon: 0.8046928000042399    steps: 124    lr: 0.0001     evaluation reward: 1.66\n",
      "episode: 1066   score: 2.0   memory length: 198838   epsilon: 0.8042987800042485    steps: 199    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1067   score: 0.0   memory length: 198962   epsilon: 0.8040532600042538    steps: 124    lr: 0.0001     evaluation reward: 1.67\n",
      "episode: 1068   score: 2.0   memory length: 199180   epsilon: 0.8036216200042632    steps: 218    lr: 0.0001     evaluation reward: 1.69\n",
      "episode: 1069   score: 1.0   memory length: 199349   epsilon: 0.8032870000042704    steps: 169    lr: 0.0001     evaluation reward: 1.68\n",
      "episode: 1070   score: 2.0   memory length: 199570   epsilon: 0.80284942000428    steps: 221    lr: 0.0001     evaluation reward: 1.65\n",
      "episode: 1071   score: 0.0   memory length: 199694   epsilon: 0.8026039000042853    steps: 124    lr: 0.0001     evaluation reward: 1.64\n",
      "episode: 1072   score: 9.0   memory length: 200084   epsilon: 0.801831700004302    steps: 390    lr: 4e-05     evaluation reward: 1.71\n",
      "episode: 1073   score: 5.0   memory length: 200409   epsilon: 0.801188200004316    steps: 325    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 1074   score: 3.0   memory length: 200674   epsilon: 0.8006635000043274    steps: 265    lr: 4e-05     evaluation reward: 1.75\n",
      "episode: 1075   score: 0.0   memory length: 200798   epsilon: 0.8004179800043327    steps: 124    lr: 4e-05     evaluation reward: 1.72\n",
      "episode: 1076   score: 3.0   memory length: 201044   epsilon: 0.7999309000043433    steps: 246    lr: 4e-05     evaluation reward: 1.73\n",
      "episode: 1077   score: 2.0   memory length: 201263   epsilon: 0.7994972800043527    steps: 219    lr: 4e-05     evaluation reward: 1.74\n",
      "episode: 1078   score: 4.0   memory length: 201537   epsilon: 0.7989547600043645    steps: 274    lr: 4e-05     evaluation reward: 1.76\n",
      "episode: 1079   score: 2.0   memory length: 201735   epsilon: 0.798562720004373    steps: 198    lr: 4e-05     evaluation reward: 1.78\n",
      "episode: 1080   score: 3.0   memory length: 201984   epsilon: 0.7980697000043837    steps: 249    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1081   score: 2.0   memory length: 202183   epsilon: 0.7976756800043923    steps: 199    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1082   score: 0.0   memory length: 202307   epsilon: 0.7974301600043976    steps: 124    lr: 4e-05     evaluation reward: 1.79\n",
      "episode: 1083   score: 2.0   memory length: 202506   epsilon: 0.7970361400044061    steps: 199    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 1084   score: 2.0   memory length: 202723   epsilon: 0.7966064800044155    steps: 217    lr: 4e-05     evaluation reward: 1.81\n",
      "episode: 1085   score: 3.0   memory length: 202986   epsilon: 0.7960857400044268    steps: 263    lr: 4e-05     evaluation reward: 1.82\n",
      "episode: 1086   score: 2.0   memory length: 203185   epsilon: 0.7956917200044353    steps: 199    lr: 4e-05     evaluation reward: 1.84\n",
      "episode: 1087   score: 1.0   memory length: 203355   epsilon: 0.7953551200044426    steps: 170    lr: 4e-05     evaluation reward: 1.85\n",
      "episode: 1088   score: 0.0   memory length: 203478   epsilon: 0.7951115800044479    steps: 123    lr: 4e-05     evaluation reward: 1.83\n",
      "episode: 1089   score: 4.0   memory length: 203775   epsilon: 0.7945235200044607    steps: 297    lr: 4e-05     evaluation reward: 1.87\n",
      "episode: 1090   score: 3.0   memory length: 204002   epsilon: 0.7940740600044705    steps: 227    lr: 4e-05     evaluation reward: 1.88\n",
      "episode: 1091   score: 3.0   memory length: 204270   epsilon: 0.793543420004482    steps: 268    lr: 4e-05     evaluation reward: 1.91\n",
      "episode: 1092   score: 2.0   memory length: 204468   epsilon: 0.7931513800044905    steps: 198    lr: 4e-05     evaluation reward: 1.91\n",
      "episode: 1093   score: 3.0   memory length: 204736   epsilon: 0.792620740004502    steps: 268    lr: 4e-05     evaluation reward: 1.91\n",
      "episode: 1094   score: 2.0   memory length: 204953   epsilon: 0.7921910800045113    steps: 217    lr: 4e-05     evaluation reward: 1.91\n",
      "episode: 1095   score: 0.0   memory length: 205077   epsilon: 0.7919455600045167    steps: 124    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 1096   score: 1.0   memory length: 205248   epsilon: 0.791606980004524    steps: 171    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 1097   score: 3.0   memory length: 205515   epsilon: 0.7910783200045355    steps: 267    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 1098   score: 2.0   memory length: 205714   epsilon: 0.790684300004544    steps: 199    lr: 4e-05     evaluation reward: 1.89\n",
      "episode: 1099   score: 0.0   memory length: 205838   epsilon: 0.7904387800045494    steps: 124    lr: 4e-05     evaluation reward: 1.87\n",
      "episode: 1100   score: 3.0   memory length: 206110   epsilon: 0.7899002200045611    steps: 272    lr: 4e-05     evaluation reward: 1.9\n",
      "episode: 1101   score: 5.0   memory length: 206440   epsilon: 0.7892468200045752    steps: 330    lr: 4e-05     evaluation reward: 1.94\n",
      "episode: 1102   score: 2.0   memory length: 206639   epsilon: 0.7888528000045838    steps: 199    lr: 4e-05     evaluation reward: 1.94\n",
      "episode: 1103   score: 3.0   memory length: 206886   epsilon: 0.7883637400045944    steps: 247    lr: 4e-05     evaluation reward: 1.94\n",
      "episode: 1104   score: 1.0   memory length: 207056   epsilon: 0.7880271400046017    steps: 170    lr: 4e-05     evaluation reward: 1.93\n",
      "episode: 1105   score: 4.0   memory length: 207334   epsilon: 0.7874767000046137    steps: 278    lr: 4e-05     evaluation reward: 1.97\n",
      "episode: 1106   score: 2.0   memory length: 207533   epsilon: 0.7870826800046222    steps: 199    lr: 4e-05     evaluation reward: 1.96\n",
      "episode: 1107   score: 2.0   memory length: 207751   epsilon: 0.7866510400046316    steps: 218    lr: 4e-05     evaluation reward: 1.97\n",
      "episode: 1108   score: 2.0   memory length: 207952   epsilon: 0.7862530600046402    steps: 201    lr: 4e-05     evaluation reward: 1.97\n",
      "episode: 1109   score: 1.0   memory length: 208103   epsilon: 0.7859540800046467    steps: 151    lr: 4e-05     evaluation reward: 1.98\n",
      "episode: 1110   score: 3.0   memory length: 208330   epsilon: 0.7855046200046565    steps: 227    lr: 4e-05     evaluation reward: 2.0\n",
      "episode: 1111   score: 3.0   memory length: 208557   epsilon: 0.7850551600046662    steps: 227    lr: 4e-05     evaluation reward: 2.01\n",
      "episode: 1112   score: 2.0   memory length: 208755   epsilon: 0.7846631200046748    steps: 198    lr: 4e-05     evaluation reward: 2.01\n",
      "episode: 1113   score: 2.0   memory length: 208954   epsilon: 0.7842691000046833    steps: 199    lr: 4e-05     evaluation reward: 2.01\n",
      "episode: 1114   score: 2.0   memory length: 209174   epsilon: 0.7838335000046928    steps: 220    lr: 4e-05     evaluation reward: 2.01\n",
      "episode: 1115   score: 2.0   memory length: 209372   epsilon: 0.7834414600047013    steps: 198    lr: 4e-05     evaluation reward: 2.01\n",
      "episode: 1116   score: 2.0   memory length: 209591   epsilon: 0.7830078400047107    steps: 219    lr: 4e-05     evaluation reward: 2.01\n",
      "episode: 1117   score: 5.0   memory length: 209956   epsilon: 0.7822851400047264    steps: 365    lr: 4e-05     evaluation reward: 2.06\n",
      "episode: 1118   score: 4.0   memory length: 210253   epsilon: 0.7816970800047391    steps: 297    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 1119   score: 3.0   memory length: 210479   epsilon: 0.7812496000047489    steps: 226    lr: 4e-05     evaluation reward: 2.07\n",
      "episode: 1120   score: 2.0   memory length: 210678   epsilon: 0.7808555800047574    steps: 199    lr: 4e-05     evaluation reward: 2.09\n",
      "episode: 1121   score: 2.0   memory length: 210877   epsilon: 0.780461560004766    steps: 199    lr: 4e-05     evaluation reward: 2.1\n",
      "episode: 1122   score: 2.0   memory length: 211076   epsilon: 0.7800675400047745    steps: 199    lr: 4e-05     evaluation reward: 2.1\n",
      "episode: 1123   score: 0.0   memory length: 211200   epsilon: 0.7798220200047798    steps: 124    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 1124   score: 2.0   memory length: 211398   epsilon: 0.7794299800047884    steps: 198    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 1125   score: 0.0   memory length: 211522   epsilon: 0.7791844600047937    steps: 124    lr: 4e-05     evaluation reward: 2.06\n",
      "episode: 1126   score: 3.0   memory length: 211795   epsilon: 0.7786439200048054    steps: 273    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 1127   score: 0.0   memory length: 211919   epsilon: 0.7783984000048108    steps: 124    lr: 4e-05     evaluation reward: 2.06\n",
      "episode: 1128   score: 3.0   memory length: 212166   epsilon: 0.7779093400048214    steps: 247    lr: 4e-05     evaluation reward: 2.07\n",
      "episode: 1129   score: 1.0   memory length: 212335   epsilon: 0.7775747200048286    steps: 169    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 1130   score: 2.0   memory length: 212534   epsilon: 0.7771807000048372    steps: 199    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 1131   score: 2.0   memory length: 212753   epsilon: 0.7767470800048466    steps: 219    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 1132   score: 2.0   memory length: 212972   epsilon: 0.776313460004856    steps: 219    lr: 4e-05     evaluation reward: 2.07\n",
      "episode: 1133   score: 3.0   memory length: 213219   epsilon: 0.7758244000048666    steps: 247    lr: 4e-05     evaluation reward: 2.1\n",
      "episode: 1134   score: 5.0   memory length: 213544   epsilon: 0.7751809000048806    steps: 325    lr: 4e-05     evaluation reward: 2.09\n",
      "episode: 1135   score: 2.0   memory length: 213763   epsilon: 0.77474728000489    steps: 219    lr: 4e-05     evaluation reward: 2.1\n",
      "episode: 1136   score: 2.0   memory length: 213982   epsilon: 0.7743136600048994    steps: 219    lr: 4e-05     evaluation reward: 2.09\n",
      "episode: 1137   score: 0.0   memory length: 214105   epsilon: 0.7740701200049047    steps: 123    lr: 4e-05     evaluation reward: 2.07\n",
      "episode: 1138   score: 2.0   memory length: 214304   epsilon: 0.7736761000049133    steps: 199    lr: 4e-05     evaluation reward: 2.06\n",
      "episode: 1139   score: 3.0   memory length: 214573   epsilon: 0.7731434800049248    steps: 269    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 1140   score: 0.0   memory length: 214696   epsilon: 0.7728999400049301    steps: 123    lr: 4e-05     evaluation reward: 2.08\n",
      "episode: 1141   score: 3.0   memory length: 214942   epsilon: 0.7724128600049407    steps: 246    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 1142   score: 0.0   memory length: 215066   epsilon: 0.772167340004946    steps: 124    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 1143   score: 2.0   memory length: 215264   epsilon: 0.7717753000049545    steps: 198    lr: 4e-05     evaluation reward: 2.11\n",
      "episode: 1144   score: 0.0   memory length: 215388   epsilon: 0.7715297800049599    steps: 124    lr: 4e-05     evaluation reward: 2.09\n",
      "episode: 1145   score: 4.0   memory length: 215687   epsilon: 0.7709377600049727    steps: 299    lr: 4e-05     evaluation reward: 2.12\n",
      "episode: 1146   score: 4.0   memory length: 215982   epsilon: 0.7703536600049854    steps: 295    lr: 4e-05     evaluation reward: 2.15\n",
      "episode: 1147   score: 2.0   memory length: 216200   epsilon: 0.7699220200049948    steps: 218    lr: 4e-05     evaluation reward: 2.16\n",
      "episode: 1148   score: 4.0   memory length: 216476   epsilon: 0.7693755400050066    steps: 276    lr: 4e-05     evaluation reward: 2.18\n",
      "episode: 1149   score: 0.0   memory length: 216600   epsilon: 0.769130020005012    steps: 124    lr: 4e-05     evaluation reward: 2.16\n",
      "episode: 1150   score: 3.0   memory length: 216827   epsilon: 0.7686805600050217    steps: 227    lr: 4e-05     evaluation reward: 2.15\n",
      "episode: 1151   score: 0.0   memory length: 216951   epsilon: 0.768435040005027    steps: 124    lr: 4e-05     evaluation reward: 2.14\n",
      "episode: 1152   score: 4.0   memory length: 217268   epsilon: 0.7678073800050407    steps: 317    lr: 4e-05     evaluation reward: 2.16\n",
      "episode: 1153   score: 2.0   memory length: 217467   epsilon: 0.7674133600050492    steps: 199    lr: 4e-05     evaluation reward: 2.16\n",
      "episode: 1154   score: 4.0   memory length: 217761   epsilon: 0.7668312400050619    steps: 294    lr: 4e-05     evaluation reward: 2.18\n",
      "episode: 1155   score: 1.0   memory length: 217932   epsilon: 0.7664926600050692    steps: 171    lr: 4e-05     evaluation reward: 2.16\n",
      "episode: 1156   score: 4.0   memory length: 218223   epsilon: 0.7659164800050817    steps: 291    lr: 4e-05     evaluation reward: 2.15\n",
      "episode: 1157   score: 3.0   memory length: 218493   epsilon: 0.7653818800050933    steps: 270    lr: 4e-05     evaluation reward: 2.18\n",
      "episode: 1158   score: 0.0   memory length: 218616   epsilon: 0.7651383400050986    steps: 123    lr: 4e-05     evaluation reward: 2.16\n",
      "episode: 1159   score: 2.0   memory length: 218835   epsilon: 0.764704720005108    steps: 219    lr: 4e-05     evaluation reward: 2.15\n",
      "episode: 1160   score: 4.0   memory length: 219132   epsilon: 0.7641166600051208    steps: 297    lr: 4e-05     evaluation reward: 2.17\n",
      "episode: 1161   score: 1.0   memory length: 219285   epsilon: 0.7638137200051274    steps: 153    lr: 4e-05     evaluation reward: 2.15\n",
      "episode: 1162   score: 0.0   memory length: 219409   epsilon: 0.7635682000051327    steps: 124    lr: 4e-05     evaluation reward: 2.13\n",
      "episode: 1163   score: 5.0   memory length: 219710   epsilon: 0.7629722200051456    steps: 301    lr: 4e-05     evaluation reward: 2.18\n",
      "episode: 1164   score: 0.0   memory length: 219834   epsilon: 0.762726700005151    steps: 124    lr: 4e-05     evaluation reward: 2.16\n",
      "episode: 1165   score: 4.0   memory length: 220092   epsilon: 0.7622158600051621    steps: 258    lr: 4e-05     evaluation reward: 2.2\n",
      "episode: 1166   score: 2.0   memory length: 220291   epsilon: 0.7618218400051706    steps: 199    lr: 4e-05     evaluation reward: 2.2\n",
      "episode: 1167   score: 5.0   memory length: 220636   epsilon: 0.7611387400051854    steps: 345    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 1168   score: 1.0   memory length: 220806   epsilon: 0.7608021400051928    steps: 170    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1169   score: 2.0   memory length: 221023   epsilon: 0.7603724800052021    steps: 217    lr: 4e-05     evaluation reward: 2.25\n",
      "episode: 1170   score: 4.0   memory length: 221299   epsilon: 0.7598260000052139    steps: 276    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1171   score: 2.0   memory length: 221498   epsilon: 0.7594319800052225    steps: 199    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1172   score: 3.0   memory length: 221765   epsilon: 0.758903320005234    steps: 267    lr: 4e-05     evaluation reward: 2.23\n",
      "episode: 1173   score: 4.0   memory length: 222046   epsilon: 0.758346940005246    steps: 281    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1174   score: 2.0   memory length: 222245   epsilon: 0.7579529200052546    steps: 199    lr: 4e-05     evaluation reward: 2.21\n",
      "episode: 1175   score: 3.0   memory length: 222494   epsilon: 0.7574599000052653    steps: 249    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1176   score: 0.0   memory length: 222618   epsilon: 0.7572143800052706    steps: 124    lr: 4e-05     evaluation reward: 2.21\n",
      "episode: 1177   score: 1.0   memory length: 222769   epsilon: 0.7569154000052771    steps: 151    lr: 4e-05     evaluation reward: 2.2\n",
      "episode: 1178   score: 2.0   memory length: 222950   epsilon: 0.7565570200052849    steps: 181    lr: 4e-05     evaluation reward: 2.18\n",
      "episode: 1179   score: 4.0   memory length: 223230   epsilon: 0.7560026200052969    steps: 280    lr: 4e-05     evaluation reward: 2.2\n",
      "episode: 1180   score: 3.0   memory length: 223477   epsilon: 0.7555135600053076    steps: 247    lr: 4e-05     evaluation reward: 2.2\n",
      "episode: 1181   score: 2.0   memory length: 223676   epsilon: 0.7551195400053161    steps: 199    lr: 4e-05     evaluation reward: 2.2\n",
      "episode: 1182   score: 2.0   memory length: 223875   epsilon: 0.7547255200053247    steps: 199    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1183   score: 2.0   memory length: 224074   epsilon: 0.7543315000053332    steps: 199    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1184   score: 2.0   memory length: 224273   epsilon: 0.7539374800053418    steps: 199    lr: 4e-05     evaluation reward: 2.22\n",
      "episode: 1185   score: 5.0   memory length: 224642   epsilon: 0.7532068600053576    steps: 369    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1186   score: 2.0   memory length: 224841   epsilon: 0.7528128400053662    steps: 199    lr: 4e-05     evaluation reward: 2.24\n",
      "episode: 1187   score: 4.0   memory length: 225117   epsilon: 0.752266360005378    steps: 276    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1188   score: 5.0   memory length: 225404   epsilon: 0.7516981000053904    steps: 287    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1189   score: 2.0   memory length: 225602   epsilon: 0.7513060600053989    steps: 198    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1190   score: 2.0   memory length: 225824   epsilon: 0.7508665000054084    steps: 222    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1191   score: 2.0   memory length: 226023   epsilon: 0.750472480005417    steps: 199    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1192   score: 0.0   memory length: 226147   epsilon: 0.7502269600054223    steps: 124    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1193   score: 3.0   memory length: 226394   epsilon: 0.749737900005433    steps: 247    lr: 4e-05     evaluation reward: 2.26\n",
      "episode: 1194   score: 3.0   memory length: 226663   epsilon: 0.7492052800054445    steps: 269    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1195   score: 0.0   memory length: 226787   epsilon: 0.7489597600054498    steps: 124    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1196   score: 3.0   memory length: 227036   epsilon: 0.7484667400054605    steps: 249    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1197   score: 3.0   memory length: 227303   epsilon: 0.747938080005472    steps: 267    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1198   score: 3.0   memory length: 227548   epsilon: 0.7474529800054825    steps: 245    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1199   score: 4.0   memory length: 227826   epsilon: 0.7469025400054945    steps: 278    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1200   score: 2.0   memory length: 228025   epsilon: 0.746508520005503    steps: 199    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1201   score: 2.0   memory length: 228223   epsilon: 0.7461164800055116    steps: 198    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1202   score: 2.0   memory length: 228441   epsilon: 0.7456848400055209    steps: 218    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1203   score: 2.0   memory length: 228640   epsilon: 0.7452908200055295    steps: 199    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1204   score: 4.0   memory length: 228919   epsilon: 0.7447384000055415    steps: 279    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1205   score: 1.0   memory length: 229091   epsilon: 0.7443978400055489    steps: 172    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1206   score: 5.0   memory length: 229417   epsilon: 0.7437523600055629    steps: 326    lr: 4e-05     evaluation reward: 2.32\n",
      "episode: 1207   score: 0.0   memory length: 229541   epsilon: 0.7435068400055682    steps: 124    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1208   score: 0.0   memory length: 229665   epsilon: 0.7432613200055735    steps: 124    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1209   score: 2.0   memory length: 229886   epsilon: 0.742823740005583    steps: 221    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1210   score: 1.0   memory length: 230038   epsilon: 0.7425227800055896    steps: 152    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1211   score: 3.0   memory length: 230304   epsilon: 0.741996100005601    steps: 266    lr: 4e-05     evaluation reward: 2.27\n",
      "episode: 1212   score: 3.0   memory length: 230553   epsilon: 0.7415030800056117    steps: 249    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1213   score: 2.0   memory length: 230770   epsilon: 0.741073420005621    steps: 217    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1214   score: 2.0   memory length: 230968   epsilon: 0.7406813800056296    steps: 198    lr: 4e-05     evaluation reward: 2.28\n",
      "episode: 1215   score: 3.0   memory length: 231215   epsilon: 0.7401923200056402    steps: 247    lr: 4e-05     evaluation reward: 2.29\n",
      "episode: 1216   score: 3.0   memory length: 231487   epsilon: 0.7396537600056519    steps: 272    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1217   score: 5.0   memory length: 231805   epsilon: 0.7390241200056655    steps: 318    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1218   score: 4.0   memory length: 232082   epsilon: 0.7384756600056774    steps: 277    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1219   score: 3.0   memory length: 232309   epsilon: 0.7380262000056872    steps: 227    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1220   score: 2.0   memory length: 232508   epsilon: 0.7376321800056957    steps: 199    lr: 4e-05     evaluation reward: 2.3\n",
      "episode: 1221   score: 3.0   memory length: 232776   epsilon: 0.7371015400057073    steps: 268    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1222   score: 2.0   memory length: 232975   epsilon: 0.7367075200057158    steps: 199    lr: 4e-05     evaluation reward: 2.31\n",
      "episode: 1223   score: 2.0   memory length: 233174   epsilon: 0.7363135000057244    steps: 199    lr: 4e-05     evaluation reward: 2.33\n",
      "episode: 1224   score: 3.0   memory length: 233419   epsilon: 0.7358284000057349    steps: 245    lr: 4e-05     evaluation reward: 2.34\n",
      "episode: 1225   score: 2.0   memory length: 233618   epsilon: 0.7354343800057435    steps: 199    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1226   score: 3.0   memory length: 233845   epsilon: 0.7349849200057532    steps: 227    lr: 4e-05     evaluation reward: 2.36\n",
      "episode: 1227   score: 4.0   memory length: 234120   epsilon: 0.734440420005765    steps: 275    lr: 4e-05     evaluation reward: 2.4\n",
      "episode: 1228   score: 4.0   memory length: 234438   epsilon: 0.7338107800057787    steps: 318    lr: 4e-05     evaluation reward: 2.41\n",
      "episode: 1229   score: 3.0   memory length: 234686   epsilon: 0.7333197400057894    steps: 248    lr: 4e-05     evaluation reward: 2.43\n",
      "episode: 1230   score: 0.0   memory length: 234809   epsilon: 0.7330762000057947    steps: 123    lr: 4e-05     evaluation reward: 2.41\n",
      "episode: 1231   score: 4.0   memory length: 235086   epsilon: 0.7325277400058066    steps: 277    lr: 4e-05     evaluation reward: 2.43\n",
      "episode: 1232   score: 2.0   memory length: 235284   epsilon: 0.7321357000058151    steps: 198    lr: 4e-05     evaluation reward: 2.43\n",
      "episode: 1233   score: 5.0   memory length: 235627   epsilon: 0.7314565600058298    steps: 343    lr: 4e-05     evaluation reward: 2.45\n",
      "episode: 1234   score: 2.0   memory length: 235826   epsilon: 0.7310625400058384    steps: 199    lr: 4e-05     evaluation reward: 2.42\n",
      "episode: 1235   score: 7.0   memory length: 236247   epsilon: 0.7302289600058565    steps: 421    lr: 4e-05     evaluation reward: 2.47\n",
      "episode: 1236   score: 3.0   memory length: 236474   epsilon: 0.7297795000058662    steps: 227    lr: 4e-05     evaluation reward: 2.48\n",
      "episode: 1237   score: 4.0   memory length: 236772   epsilon: 0.729189460005879    steps: 298    lr: 4e-05     evaluation reward: 2.52\n",
      "episode: 1238   score: 1.0   memory length: 236941   epsilon: 0.7288548400058863    steps: 169    lr: 4e-05     evaluation reward: 2.51\n",
      "episode: 1239   score: 4.0   memory length: 237217   epsilon: 0.7283083600058982    steps: 276    lr: 4e-05     evaluation reward: 2.52\n",
      "episode: 1240   score: 3.0   memory length: 237465   epsilon: 0.7278173200059088    steps: 248    lr: 4e-05     evaluation reward: 2.55\n",
      "episode: 1241   score: 3.0   memory length: 237693   epsilon: 0.7273658800059186    steps: 228    lr: 4e-05     evaluation reward: 2.55\n",
      "episode: 1242   score: 2.0   memory length: 237912   epsilon: 0.726932260005928    steps: 219    lr: 4e-05     evaluation reward: 2.57\n",
      "episode: 1243   score: 3.0   memory length: 238159   epsilon: 0.7264432000059386    steps: 247    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1244   score: 1.0   memory length: 238329   epsilon: 0.726106600005946    steps: 170    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1245   score: 0.0   memory length: 238453   epsilon: 0.7258610800059513    steps: 124    lr: 4e-05     evaluation reward: 2.55\n",
      "episode: 1246   score: 1.0   memory length: 238623   epsilon: 0.7255244800059586    steps: 170    lr: 4e-05     evaluation reward: 2.52\n",
      "episode: 1247   score: 0.0   memory length: 238746   epsilon: 0.7252809400059639    steps: 123    lr: 4e-05     evaluation reward: 2.5\n",
      "episode: 1248   score: 6.0   memory length: 239140   epsilon: 0.7245008200059808    steps: 394    lr: 4e-05     evaluation reward: 2.52\n",
      "episode: 1249   score: 4.0   memory length: 239436   epsilon: 0.7239147400059935    steps: 296    lr: 4e-05     evaluation reward: 2.56\n",
      "episode: 1250   score: 1.0   memory length: 239588   epsilon: 0.7236137800060001    steps: 152    lr: 4e-05     evaluation reward: 2.54\n",
      "episode: 1251   score: 2.0   memory length: 239808   epsilon: 0.7231781800060095    steps: 220    lr: 4e-05     evaluation reward: 2.56\n",
      "episode: 1252   score: 2.0   memory length: 240007   epsilon: 0.7227841600060181    steps: 199    lr: 4e-05     evaluation reward: 2.54\n",
      "episode: 1253   score: 2.0   memory length: 240225   epsilon: 0.7223525200060275    steps: 218    lr: 4e-05     evaluation reward: 2.54\n",
      "episode: 1254   score: 4.0   memory length: 240522   epsilon: 0.7217644600060402    steps: 297    lr: 4e-05     evaluation reward: 2.54\n",
      "episode: 1255   score: 4.0   memory length: 240822   epsilon: 0.7211704600060531    steps: 300    lr: 4e-05     evaluation reward: 2.57\n",
      "episode: 1256   score: 3.0   memory length: 241069   epsilon: 0.7206814000060637    steps: 247    lr: 4e-05     evaluation reward: 2.56\n",
      "episode: 1257   score: 7.0   memory length: 241456   epsilon: 0.7199151400060804    steps: 387    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1258   score: 4.0   memory length: 241753   epsilon: 0.7193270800060931    steps: 297    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1259   score: 2.0   memory length: 241971   epsilon: 0.7188954400061025    steps: 218    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1260   score: 0.0   memory length: 242095   epsilon: 0.7186499200061078    steps: 124    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1261   score: 2.0   memory length: 242297   epsilon: 0.7182499600061165    steps: 202    lr: 4e-05     evaluation reward: 2.61\n",
      "episode: 1262   score: 3.0   memory length: 242528   epsilon: 0.7177925800061264    steps: 231    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1263   score: 3.0   memory length: 242776   epsilon: 0.7173015400061371    steps: 248    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1264   score: 2.0   memory length: 242995   epsilon: 0.7168679200061465    steps: 219    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1265   score: 3.0   memory length: 243222   epsilon: 0.7164184600061563    steps: 227    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1266   score: 2.0   memory length: 243439   epsilon: 0.7159888000061656    steps: 217    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1267   score: 2.0   memory length: 243638   epsilon: 0.7155947800061742    steps: 199    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1268   score: 2.0   memory length: 243859   epsilon: 0.7151572000061837    steps: 221    lr: 4e-05     evaluation reward: 2.61\n",
      "episode: 1269   score: 2.0   memory length: 244058   epsilon: 0.7147631800061922    steps: 199    lr: 4e-05     evaluation reward: 2.61\n",
      "episode: 1270   score: 3.0   memory length: 244305   epsilon: 0.7142741200062028    steps: 247    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1271   score: 2.0   memory length: 244524   epsilon: 0.7138405000062122    steps: 219    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1272   score: 3.0   memory length: 244774   epsilon: 0.713345500006223    steps: 250    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1273   score: 3.0   memory length: 245000   epsilon: 0.7128980200062327    steps: 226    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1274   score: 3.0   memory length: 245247   epsilon: 0.7124089600062433    steps: 247    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1275   score: 2.0   memory length: 245448   epsilon: 0.712010980006252    steps: 201    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1276   score: 3.0   memory length: 245675   epsilon: 0.7115615200062617    steps: 227    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1277   score: 2.0   memory length: 245874   epsilon: 0.7111675000062703    steps: 199    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1278   score: 6.0   memory length: 246253   epsilon: 0.7104170800062866    steps: 379    lr: 4e-05     evaluation reward: 2.67\n",
      "episode: 1279   score: 4.0   memory length: 246569   epsilon: 0.7097914000063001    steps: 316    lr: 4e-05     evaluation reward: 2.67\n",
      "episode: 1280   score: 2.0   memory length: 246768   epsilon: 0.7093973800063087    steps: 199    lr: 4e-05     evaluation reward: 2.66\n",
      "episode: 1281   score: 3.0   memory length: 247016   epsilon: 0.7089063400063194    steps: 248    lr: 4e-05     evaluation reward: 2.67\n",
      "episode: 1282   score: 0.0   memory length: 247140   epsilon: 0.7086608200063247    steps: 124    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1283   score: 0.0   memory length: 247263   epsilon: 0.70841728000633    steps: 123    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1284   score: 2.0   memory length: 247462   epsilon: 0.7080232600063385    steps: 199    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1285   score: 3.0   memory length: 247710   epsilon: 0.7075322200063492    steps: 248    lr: 4e-05     evaluation reward: 2.61\n",
      "episode: 1286   score: 0.0   memory length: 247834   epsilon: 0.7072867000063545    steps: 124    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1287   score: 3.0   memory length: 248105   epsilon: 0.7067501200063662    steps: 271    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1288   score: 2.0   memory length: 248327   epsilon: 0.7063105600063757    steps: 222    lr: 4e-05     evaluation reward: 2.55\n",
      "episode: 1289   score: 5.0   memory length: 248674   epsilon: 0.7056235000063906    steps: 347    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1290   score: 2.0   memory length: 248873   epsilon: 0.7052294800063992    steps: 199    lr: 4e-05     evaluation reward: 2.58\n",
      "episode: 1291   score: 3.0   memory length: 249100   epsilon: 0.7047800200064089    steps: 227    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1292   score: 0.0   memory length: 249223   epsilon: 0.7045364800064142    steps: 123    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1293   score: 3.0   memory length: 249493   epsilon: 0.7040018800064258    steps: 270    lr: 4e-05     evaluation reward: 2.59\n",
      "episode: 1294   score: 4.0   memory length: 249811   epsilon: 0.7033722400064395    steps: 318    lr: 4e-05     evaluation reward: 2.6\n",
      "episode: 1295   score: 3.0   memory length: 250057   epsilon: 0.7028851600064501    steps: 246    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1296   score: 4.0   memory length: 250333   epsilon: 0.7023386800064619    steps: 276    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1297   score: 2.0   memory length: 250531   epsilon: 0.7019466400064704    steps: 198    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1298   score: 3.0   memory length: 250781   epsilon: 0.7014516400064812    steps: 250    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1299   score: 3.0   memory length: 251011   epsilon: 0.7009962400064911    steps: 230    lr: 4e-05     evaluation reward: 2.62\n",
      "episode: 1300   score: 3.0   memory length: 251238   epsilon: 0.7005467800065008    steps: 227    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1301   score: 2.0   memory length: 251438   epsilon: 0.7001507800065094    steps: 200    lr: 4e-05     evaluation reward: 2.63\n",
      "episode: 1302   score: 3.0   memory length: 251666   epsilon: 0.6996993400065192    steps: 228    lr: 4e-05     evaluation reward: 2.64\n",
      "episode: 1303   score: 4.0   memory length: 251967   epsilon: 0.6991033600065322    steps: 301    lr: 4e-05     evaluation reward: 2.66\n",
      "episode: 1304   score: 3.0   memory length: 252212   epsilon: 0.6986182600065427    steps: 245    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1305   score: 2.0   memory length: 252431   epsilon: 0.6981846400065521    steps: 219    lr: 4e-05     evaluation reward: 2.66\n",
      "episode: 1306   score: 4.0   memory length: 252730   epsilon: 0.697592620006565    steps: 299    lr: 4e-05     evaluation reward: 2.65\n",
      "episode: 1307   score: 3.0   memory length: 252956   epsilon: 0.6971451400065747    steps: 226    lr: 4e-05     evaluation reward: 2.68\n",
      "episode: 1308   score: 6.0   memory length: 253322   epsilon: 0.6964204600065904    steps: 366    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1309   score: 2.0   memory length: 253520   epsilon: 0.6960284200065989    steps: 198    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1310   score: 2.0   memory length: 253718   epsilon: 0.6956363800066074    steps: 198    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1311   score: 2.0   memory length: 253936   epsilon: 0.6952047400066168    steps: 218    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1312   score: 3.0   memory length: 254183   epsilon: 0.6947156800066274    steps: 247    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1313   score: 4.0   memory length: 254477   epsilon: 0.6941335600066401    steps: 294    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1314   score: 2.0   memory length: 254696   epsilon: 0.6936999400066495    steps: 219    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1315   score: 2.0   memory length: 254895   epsilon: 0.693305920006658    steps: 199    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1316   score: 4.0   memory length: 255215   epsilon: 0.6926723200066718    steps: 320    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1317   score: 3.0   memory length: 255442   epsilon: 0.6922228600066815    steps: 227    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1318   score: 1.0   memory length: 255594   epsilon: 0.6919219000066881    steps: 152    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1319   score: 0.0   memory length: 255718   epsilon: 0.6916763800066934    steps: 124    lr: 4e-05     evaluation reward: 2.68\n",
      "episode: 1320   score: 3.0   memory length: 255965   epsilon: 0.691187320006704    steps: 247    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1321   score: 3.0   memory length: 256195   epsilon: 0.6907319200067139    steps: 230    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1322   score: 6.0   memory length: 256532   epsilon: 0.6900646600067284    steps: 337    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1323   score: 2.0   memory length: 256731   epsilon: 0.689670640006737    steps: 199    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1324   score: 4.0   memory length: 256992   epsilon: 0.6891538600067482    steps: 261    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1325   score: 3.0   memory length: 257240   epsilon: 0.6886628200067588    steps: 248    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1326   score: 3.0   memory length: 257488   epsilon: 0.6881717800067695    steps: 248    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1327   score: 2.0   memory length: 257687   epsilon: 0.687777760006778    steps: 199    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1328   score: 2.0   memory length: 257885   epsilon: 0.6873857200067865    steps: 198    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1329   score: 2.0   memory length: 258086   epsilon: 0.6869877400067952    steps: 201    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1330   score: 4.0   memory length: 258361   epsilon: 0.686443240006807    steps: 275    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1331   score: 4.0   memory length: 258658   epsilon: 0.6858551800068198    steps: 297    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1332   score: 4.0   memory length: 258928   epsilon: 0.6853205800068314    steps: 270    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1333   score: 3.0   memory length: 259157   epsilon: 0.6848671600068412    steps: 229    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1334   score: 4.0   memory length: 259455   epsilon: 0.684277120006854    steps: 298    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1335   score: 3.0   memory length: 259682   epsilon: 0.6838276600068638    steps: 227    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1336   score: 4.0   memory length: 259960   epsilon: 0.6832772200068757    steps: 278    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1337   score: 1.0   memory length: 260113   epsilon: 0.6829742800068823    steps: 153    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1338   score: 3.0   memory length: 260361   epsilon: 0.682483240006893    steps: 248    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1339   score: 0.0   memory length: 260485   epsilon: 0.6822377200068983    steps: 124    lr: 4e-05     evaluation reward: 2.68\n",
      "episode: 1340   score: 4.0   memory length: 260785   epsilon: 0.6816437200069112    steps: 300    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1341   score: 3.0   memory length: 261033   epsilon: 0.6811526800069219    steps: 248    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1342   score: 3.0   memory length: 261281   epsilon: 0.6806616400069325    steps: 248    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1343   score: 4.0   memory length: 261551   epsilon: 0.6801270400069441    steps: 270    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1344   score: 2.0   memory length: 261750   epsilon: 0.6797330200069527    steps: 199    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1345   score: 2.0   memory length: 261932   epsilon: 0.6793726600069605    steps: 182    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1346   score: 4.0   memory length: 262229   epsilon: 0.6787846000069733    steps: 297    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1347   score: 4.0   memory length: 262525   epsilon: 0.678198520006986    steps: 296    lr: 4e-05     evaluation reward: 2.81\n",
      "episode: 1348   score: 2.0   memory length: 262726   epsilon: 0.6778005400069946    steps: 201    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1349   score: 2.0   memory length: 262943   epsilon: 0.677370880007004    steps: 217    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1350   score: 2.0   memory length: 263142   epsilon: 0.6769768600070125    steps: 199    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1351   score: 3.0   memory length: 263389   epsilon: 0.6764878000070231    steps: 247    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1352   score: 4.0   memory length: 263667   epsilon: 0.6759373600070351    steps: 278    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1353   score: 2.0   memory length: 263886   epsilon: 0.6755037400070445    steps: 219    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1354   score: 7.0   memory length: 264185   epsilon: 0.6749117200070573    steps: 299    lr: 4e-05     evaluation reward: 2.82\n",
      "episode: 1355   score: 1.0   memory length: 264338   epsilon: 0.6746087800070639    steps: 153    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1356   score: 3.0   memory length: 264585   epsilon: 0.6741197200070745    steps: 247    lr: 4e-05     evaluation reward: 2.79\n",
      "episode: 1357   score: 1.0   memory length: 264737   epsilon: 0.6738187600070811    steps: 152    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1358   score: 2.0   memory length: 264935   epsilon: 0.6734267200070896    steps: 198    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1359   score: 5.0   memory length: 265234   epsilon: 0.6728347000071024    steps: 299    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1360   score: 1.0   memory length: 265386   epsilon: 0.672533740007109    steps: 152    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1361   score: 2.0   memory length: 265585   epsilon: 0.6721397200071175    steps: 199    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1362   score: 1.0   memory length: 265737   epsilon: 0.6718387600071241    steps: 152    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1363   score: 2.0   memory length: 265936   epsilon: 0.6714447400071326    steps: 199    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1364   score: 3.0   memory length: 266163   epsilon: 0.6709952800071424    steps: 227    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1365   score: 1.0   memory length: 266315   epsilon: 0.6706943200071489    steps: 152    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1366   score: 2.0   memory length: 266534   epsilon: 0.6702607000071583    steps: 219    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1367   score: 3.0   memory length: 266782   epsilon: 0.669769660007169    steps: 248    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1368   score: 3.0   memory length: 267030   epsilon: 0.6692786200071796    steps: 248    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1369   score: 4.0   memory length: 267283   epsilon: 0.6687776800071905    steps: 253    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1370   score: 3.0   memory length: 267513   epsilon: 0.6683222800072004    steps: 230    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1371   score: 3.0   memory length: 267724   epsilon: 0.6679045000072095    steps: 211    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1372   score: 2.0   memory length: 267922   epsilon: 0.667512460007218    steps: 198    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1373   score: 4.0   memory length: 268221   epsilon: 0.6669204400072308    steps: 299    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1374   score: 3.0   memory length: 268448   epsilon: 0.6664709800072406    steps: 227    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1375   score: 2.0   memory length: 268648   epsilon: 0.6660749800072492    steps: 200    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1376   score: 3.0   memory length: 268875   epsilon: 0.6656255200072589    steps: 227    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1377   score: 3.0   memory length: 269123   epsilon: 0.6651344800072696    steps: 248    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1378   score: 4.0   memory length: 269422   epsilon: 0.6645424600072825    steps: 299    lr: 4e-05     evaluation reward: 2.75\n",
      "episode: 1379   score: 3.0   memory length: 269693   epsilon: 0.6640058800072941    steps: 271    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1380   score: 0.0   memory length: 269817   epsilon: 0.6637603600072994    steps: 124    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1381   score: 0.0   memory length: 269940   epsilon: 0.6635168200073047    steps: 123    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1382   score: 1.0   memory length: 270092   epsilon: 0.6632158600073113    steps: 152    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1383   score: 0.0   memory length: 270216   epsilon: 0.6629703400073166    steps: 124    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1384   score: 1.0   memory length: 270385   epsilon: 0.6626357200073238    steps: 169    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1385   score: 4.0   memory length: 270683   epsilon: 0.6620456800073367    steps: 298    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1386   score: 2.0   memory length: 270866   epsilon: 0.6616833400073445    steps: 183    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1387   score: 2.0   memory length: 271049   epsilon: 0.6613210000073524    steps: 183    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1388   score: 2.0   memory length: 271248   epsilon: 0.6609269800073609    steps: 199    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1389   score: 3.0   memory length: 271480   epsilon: 0.6604676200073709    steps: 232    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1390   score: 4.0   memory length: 271757   epsilon: 0.6599191600073828    steps: 277    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1391   score: 4.0   memory length: 272051   epsilon: 0.6593370400073955    steps: 294    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1392   score: 4.0   memory length: 272311   epsilon: 0.6588222400074066    steps: 260    lr: 4e-05     evaluation reward: 2.76\n",
      "episode: 1393   score: 4.0   memory length: 272574   epsilon: 0.6583015000074179    steps: 263    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1394   score: 4.0   memory length: 272849   epsilon: 0.6577570000074298    steps: 275    lr: 4e-05     evaluation reward: 2.77\n",
      "episode: 1395   score: 0.0   memory length: 272973   epsilon: 0.6575114800074351    steps: 124    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1396   score: 4.0   memory length: 273250   epsilon: 0.656963020007447    steps: 277    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1397   score: 1.0   memory length: 273402   epsilon: 0.6566620600074535    steps: 152    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1398   score: 2.0   memory length: 273601   epsilon: 0.6562680400074621    steps: 199    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1399   score: 3.0   memory length: 273869   epsilon: 0.6557374000074736    steps: 268    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1400   score: 3.0   memory length: 274135   epsilon: 0.655210720007485    steps: 266    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1401   score: 0.0   memory length: 274258   epsilon: 0.6549671800074903    steps: 123    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1402   score: 4.0   memory length: 274534   epsilon: 0.6544207000075022    steps: 276    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1403   score: 2.0   memory length: 274716   epsilon: 0.65406034000751    steps: 182    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1404   score: 7.0   memory length: 275140   epsilon: 0.6532208200075282    steps: 424    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1405   score: 3.0   memory length: 275369   epsilon: 0.6527674000075381    steps: 229    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1406   score: 3.0   memory length: 275599   epsilon: 0.652312000007548    steps: 230    lr: 4e-05     evaluation reward: 2.73\n",
      "episode: 1407   score: 4.0   memory length: 275877   epsilon: 0.6517615600075599    steps: 278    lr: 4e-05     evaluation reward: 2.74\n",
      "episode: 1408   score: 1.0   memory length: 276029   epsilon: 0.6514606000075664    steps: 152    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1409   score: 2.0   memory length: 276227   epsilon: 0.651068560007575    steps: 198    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1410   score: 2.0   memory length: 276426   epsilon: 0.6506745400075835    steps: 199    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1411   score: 5.0   memory length: 276755   epsilon: 0.6500231200075977    steps: 329    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1412   score: 3.0   memory length: 276967   epsilon: 0.6496033600076068    steps: 212    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1413   score: 2.0   memory length: 277167   epsilon: 0.6492073600076154    steps: 200    lr: 4e-05     evaluation reward: 2.7\n",
      "episode: 1414   score: 1.0   memory length: 277337   epsilon: 0.6488707600076227    steps: 170    lr: 4e-05     evaluation reward: 2.69\n",
      "episode: 1415   score: 5.0   memory length: 277643   epsilon: 0.6482648800076358    steps: 306    lr: 4e-05     evaluation reward: 2.72\n",
      "episode: 1416   score: 3.0   memory length: 277870   epsilon: 0.6478154200076456    steps: 227    lr: 4e-05     evaluation reward: 2.71\n",
      "episode: 1417   score: 17.0   memory length: 278597   epsilon: 0.6463759600076768    steps: 727    lr: 4e-05     evaluation reward: 2.85\n",
      "episode: 1418   score: 4.0   memory length: 278855   epsilon: 0.6458651200076879    steps: 258    lr: 4e-05     evaluation reward: 2.88\n",
      "episode: 1419   score: 2.0   memory length: 279074   epsilon: 0.6454315000076973    steps: 219    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1420   score: 3.0   memory length: 279305   epsilon: 0.6449741200077073    steps: 231    lr: 4e-05     evaluation reward: 2.9\n",
      "episode: 1421   score: 6.0   memory length: 279716   epsilon: 0.6441603400077249    steps: 411    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1422   score: 4.0   memory length: 279977   epsilon: 0.6436435600077361    steps: 261    lr: 4e-05     evaluation reward: 2.91\n",
      "episode: 1423   score: 4.0   memory length: 280261   epsilon: 0.6430812400077484    steps: 284    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1424   score: 6.0   memory length: 280640   epsilon: 0.6423308200077646    steps: 379    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1425   score: 3.0   memory length: 280885   epsilon: 0.6418457200077752    steps: 245    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1426   score: 3.0   memory length: 281111   epsilon: 0.6413982400077849    steps: 226    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1427   score: 2.0   memory length: 281310   epsilon: 0.6410042200077934    steps: 199    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1428   score: 6.0   memory length: 281684   epsilon: 0.6402637000078095    steps: 374    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1429   score: 2.0   memory length: 281883   epsilon: 0.6398696800078181    steps: 199    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1430   score: 1.0   memory length: 282053   epsilon: 0.6395330800078254    steps: 170    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1431   score: 3.0   memory length: 282282   epsilon: 0.6390796600078352    steps: 229    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1432   score: 2.0   memory length: 282481   epsilon: 0.6386856400078438    steps: 199    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1433   score: 3.0   memory length: 282711   epsilon: 0.6382302400078537    steps: 230    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1434   score: 4.0   memory length: 282975   epsilon: 0.637707520007865    steps: 264    lr: 4e-05     evaluation reward: 2.93\n",
      "episode: 1435   score: 5.0   memory length: 283298   epsilon: 0.6370679800078789    steps: 323    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1436   score: 5.0   memory length: 283622   epsilon: 0.6364264600078928    steps: 324    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1437   score: 2.0   memory length: 283804   epsilon: 0.6360661000079006    steps: 182    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1438   score: 3.0   memory length: 284036   epsilon: 0.6356067400079106    steps: 232    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1439   score: 2.0   memory length: 284235   epsilon: 0.6352127200079192    steps: 199    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1440   score: 4.0   memory length: 284513   epsilon: 0.6346622800079311    steps: 278    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1441   score: 4.0   memory length: 284768   epsilon: 0.6341573800079421    steps: 255    lr: 4e-05     evaluation reward: 3.0\n",
      "episode: 1442   score: 2.0   memory length: 284987   epsilon: 0.6337237600079515    steps: 219    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1443   score: 3.0   memory length: 285215   epsilon: 0.6332723200079613    steps: 228    lr: 4e-05     evaluation reward: 2.98\n",
      "episode: 1444   score: 2.0   memory length: 285434   epsilon: 0.6328387000079707    steps: 219    lr: 4e-05     evaluation reward: 2.98\n",
      "episode: 1445   score: 2.0   memory length: 285634   epsilon: 0.6324427000079793    steps: 200    lr: 4e-05     evaluation reward: 2.98\n",
      "episode: 1446   score: 2.0   memory length: 285833   epsilon: 0.6320486800079879    steps: 199    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1447   score: 3.0   memory length: 286062   epsilon: 0.6315952600079977    steps: 229    lr: 4e-05     evaluation reward: 2.95\n",
      "episode: 1448   score: 3.0   memory length: 286289   epsilon: 0.6311458000080075    steps: 227    lr: 4e-05     evaluation reward: 2.96\n",
      "episode: 1449   score: 3.0   memory length: 286503   epsilon: 0.6307220800080167    steps: 214    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1450   score: 4.0   memory length: 286783   epsilon: 0.6301676800080287    steps: 280    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1451   score: 3.0   memory length: 287030   epsilon: 0.6296786200080393    steps: 247    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1452   score: 4.0   memory length: 287288   epsilon: 0.6291677800080504    steps: 258    lr: 4e-05     evaluation reward: 2.99\n",
      "episode: 1453   score: 3.0   memory length: 287535   epsilon: 0.628678720008061    steps: 247    lr: 4e-05     evaluation reward: 3.0\n",
      "episode: 1454   score: 4.0   memory length: 287814   epsilon: 0.628126300008073    steps: 279    lr: 4e-05     evaluation reward: 2.97\n",
      "episode: 1455   score: 4.0   memory length: 288076   epsilon: 0.6276075400080843    steps: 262    lr: 4e-05     evaluation reward: 3.0\n",
      "episode: 1456   score: 7.0   memory length: 288456   epsilon: 0.6268551400081006    steps: 380    lr: 4e-05     evaluation reward: 3.04\n",
      "episode: 1457   score: 3.0   memory length: 288701   epsilon: 0.6263700400081111    steps: 245    lr: 4e-05     evaluation reward: 3.06\n",
      "episode: 1458   score: 5.0   memory length: 289046   epsilon: 0.625686940008126    steps: 345    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1459   score: 5.0   memory length: 289375   epsilon: 0.6250355200081401    steps: 329    lr: 4e-05     evaluation reward: 3.09\n",
      "episode: 1460   score: 2.0   memory length: 289573   epsilon: 0.6246434800081486    steps: 198    lr: 4e-05     evaluation reward: 3.1\n",
      "episode: 1461   score: 3.0   memory length: 289799   epsilon: 0.6241960000081583    steps: 226    lr: 4e-05     evaluation reward: 3.11\n",
      "episode: 1462   score: 4.0   memory length: 290044   epsilon: 0.6237109000081689    steps: 245    lr: 4e-05     evaluation reward: 3.14\n",
      "episode: 1463   score: 0.0   memory length: 290167   epsilon: 0.6234673600081742    steps: 123    lr: 4e-05     evaluation reward: 3.12\n",
      "episode: 1464   score: 3.0   memory length: 290417   epsilon: 0.6229723600081849    steps: 250    lr: 4e-05     evaluation reward: 3.12\n",
      "episode: 1465   score: 3.0   memory length: 290685   epsilon: 0.6224417200081964    steps: 268    lr: 4e-05     evaluation reward: 3.14\n",
      "episode: 1466   score: 3.0   memory length: 290930   epsilon: 0.621956620008207    steps: 245    lr: 4e-05     evaluation reward: 3.15\n",
      "episode: 1467   score: 4.0   memory length: 291190   epsilon: 0.6214418200082181    steps: 260    lr: 4e-05     evaluation reward: 3.16\n",
      "episode: 1468   score: 3.0   memory length: 291435   epsilon: 0.6209567200082287    steps: 245    lr: 4e-05     evaluation reward: 3.16\n",
      "episode: 1469   score: 2.0   memory length: 291633   epsilon: 0.6205646800082372    steps: 198    lr: 4e-05     evaluation reward: 3.14\n",
      "episode: 1470   score: 6.0   memory length: 292027   epsilon: 0.6197845600082541    steps: 394    lr: 4e-05     evaluation reward: 3.17\n",
      "episode: 1471   score: 5.0   memory length: 292354   epsilon: 0.6191371000082682    steps: 327    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1472   score: 3.0   memory length: 292602   epsilon: 0.6186460600082788    steps: 248    lr: 4e-05     evaluation reward: 3.2\n",
      "episode: 1473   score: 0.0   memory length: 292726   epsilon: 0.6184005400082841    steps: 124    lr: 4e-05     evaluation reward: 3.16\n",
      "episode: 1474   score: 2.0   memory length: 292925   epsilon: 0.6180065200082927    steps: 199    lr: 4e-05     evaluation reward: 3.15\n",
      "episode: 1475   score: 5.0   memory length: 293274   epsilon: 0.6173155000083077    steps: 349    lr: 4e-05     evaluation reward: 3.18\n",
      "episode: 1476   score: 4.0   memory length: 293574   epsilon: 0.6167215000083206    steps: 300    lr: 4e-05     evaluation reward: 3.19\n",
      "episode: 1477   score: 5.0   memory length: 293879   epsilon: 0.6161176000083337    steps: 305    lr: 4e-05     evaluation reward: 3.21\n",
      "episode: 1478   score: 7.0   memory length: 294200   epsilon: 0.6154820200083475    steps: 321    lr: 4e-05     evaluation reward: 3.24\n",
      "episode: 1479   score: 3.0   memory length: 294427   epsilon: 0.6150325600083573    steps: 227    lr: 4e-05     evaluation reward: 3.24\n",
      "episode: 1480   score: 2.0   memory length: 294626   epsilon: 0.6146385400083658    steps: 199    lr: 4e-05     evaluation reward: 3.26\n",
      "episode: 1481   score: 0.0   memory length: 294750   epsilon: 0.6143930200083711    steps: 124    lr: 4e-05     evaluation reward: 3.26\n",
      "episode: 1482   score: 5.0   memory length: 295080   epsilon: 0.6137396200083853    steps: 330    lr: 4e-05     evaluation reward: 3.3\n",
      "episode: 1483   score: 3.0   memory length: 295307   epsilon: 0.6132901600083951    steps: 227    lr: 4e-05     evaluation reward: 3.33\n",
      "episode: 1484   score: 3.0   memory length: 295517   epsilon: 0.6128743600084041    steps: 210    lr: 4e-05     evaluation reward: 3.35\n",
      "episode: 1485   score: 2.0   memory length: 295737   epsilon: 0.6124387600084136    steps: 220    lr: 4e-05     evaluation reward: 3.33\n",
      "episode: 1486   score: 2.0   memory length: 295938   epsilon: 0.6120407800084222    steps: 201    lr: 4e-05     evaluation reward: 3.33\n",
      "episode: 1487   score: 3.0   memory length: 296168   epsilon: 0.6115853800084321    steps: 230    lr: 4e-05     evaluation reward: 3.34\n",
      "episode: 1488   score: 1.0   memory length: 296320   epsilon: 0.6112844200084386    steps: 152    lr: 4e-05     evaluation reward: 3.33\n",
      "episode: 1489   score: 3.0   memory length: 296533   epsilon: 0.6108626800084478    steps: 213    lr: 4e-05     evaluation reward: 3.33\n",
      "episode: 1490   score: 3.0   memory length: 296761   epsilon: 0.6104112400084576    steps: 228    lr: 4e-05     evaluation reward: 3.32\n",
      "episode: 1491   score: 3.0   memory length: 296990   epsilon: 0.6099578200084674    steps: 229    lr: 4e-05     evaluation reward: 3.31\n",
      "episode: 1492   score: 2.0   memory length: 297188   epsilon: 0.6095657800084759    steps: 198    lr: 4e-05     evaluation reward: 3.29\n",
      "episode: 1493   score: 5.0   memory length: 297516   epsilon: 0.60891634000849    steps: 328    lr: 4e-05     evaluation reward: 3.3\n",
      "episode: 1494   score: 4.0   memory length: 297793   epsilon: 0.608367880008502    steps: 277    lr: 4e-05     evaluation reward: 3.3\n",
      "episode: 1495   score: 3.0   memory length: 298026   epsilon: 0.607906540008512    steps: 233    lr: 4e-05     evaluation reward: 3.33\n",
      "episode: 1496   score: 3.0   memory length: 298273   epsilon: 0.6074174800085226    steps: 247    lr: 4e-05     evaluation reward: 3.32\n",
      "episode: 1497   score: 4.0   memory length: 298516   epsilon: 0.606936340008533    steps: 243    lr: 4e-05     evaluation reward: 3.35\n",
      "episode: 1498   score: 5.0   memory length: 298842   epsilon: 0.606290860008547    steps: 326    lr: 4e-05     evaluation reward: 3.38\n",
      "episode: 1499   score: 6.0   memory length: 299198   epsilon: 0.6055859800085623    steps: 356    lr: 4e-05     evaluation reward: 3.41\n",
      "episode: 1500   score: 2.0   memory length: 299419   epsilon: 0.6051484000085718    steps: 221    lr: 4e-05     evaluation reward: 3.4\n",
      "episode: 1501   score: 4.0   memory length: 299662   epsilon: 0.6046672600085823    steps: 243    lr: 4e-05     evaluation reward: 3.44\n",
      "episode: 1502   score: 12.0   memory length: 300139   epsilon: 0.6037228000086028    steps: 477    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n",
      "episode: 1503   score: 7.0   memory length: 300490   epsilon: 0.6030278200086179    steps: 351    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1504   score: 5.0   memory length: 300783   epsilon: 0.6024476800086305    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1505   score: 3.0   memory length: 301012   epsilon: 0.6019942600086403    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1506   score: 2.0   memory length: 301231   epsilon: 0.6015606400086497    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 3.54\n",
      "episode: 1507   score: 5.0   memory length: 301559   epsilon: 0.6009112000086638    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1508   score: 3.0   memory length: 301786   epsilon: 0.6004617400086736    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1509   score: 1.0   memory length: 301937   epsilon: 0.6001627600086801    steps: 151    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1510   score: 1.0   memory length: 302110   epsilon: 0.5998202200086875    steps: 173    lr: 1.6000000000000003e-05     evaluation reward: 3.55\n",
      "episode: 1511   score: 3.0   memory length: 302321   epsilon: 0.5994024400086966    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.53\n",
      "episode: 1512   score: 6.0   memory length: 302668   epsilon: 0.5987153800087115    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1513   score: 3.0   memory length: 302900   epsilon: 0.5982560200087215    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1514   score: 3.0   memory length: 303126   epsilon: 0.5978085400087312    steps: 226    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1515   score: 4.0   memory length: 303368   epsilon: 0.5973293800087416    steps: 242    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1516   score: 3.0   memory length: 303597   epsilon: 0.5968759600087514    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1517   score: 3.0   memory length: 303825   epsilon: 0.5964245200087612    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1518   score: 3.0   memory length: 304092   epsilon: 0.5958958600087727    steps: 267    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1519   score: 4.0   memory length: 304370   epsilon: 0.5953454200087847    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n",
      "episode: 1520   score: 4.0   memory length: 304665   epsilon: 0.5947613200087973    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.46\n",
      "episode: 1521   score: 1.0   memory length: 304817   epsilon: 0.5944603600088039    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.41\n",
      "episode: 1522   score: 3.0   memory length: 305063   epsilon: 0.5939732800088144    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.4\n",
      "episode: 1523   score: 2.0   memory length: 305285   epsilon: 0.593533720008824    steps: 222    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n",
      "episode: 1524   score: 3.0   memory length: 305497   epsilon: 0.5931139600088331    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1525   score: 4.0   memory length: 305789   epsilon: 0.5925358000088456    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1526   score: 3.0   memory length: 306018   epsilon: 0.5920823800088555    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1527   score: 1.0   memory length: 306188   epsilon: 0.5917457800088628    steps: 170    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1528   score: 3.0   memory length: 306456   epsilon: 0.5912151400088743    steps: 268    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1529   score: 1.0   memory length: 306608   epsilon: 0.5909141800088809    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.31\n",
      "episode: 1530   score: 3.0   memory length: 306853   epsilon: 0.5904290800088914    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.33\n",
      "episode: 1531   score: 5.0   memory length: 307178   epsilon: 0.5897855800089054    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 3.35\n",
      "episode: 1532   score: 5.0   memory length: 307481   epsilon: 0.5891856400089184    steps: 303    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n",
      "episode: 1533   score: 3.0   memory length: 307713   epsilon: 0.5887262800089283    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n",
      "episode: 1534   score: 3.0   memory length: 307927   epsilon: 0.5883025600089375    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 3.37\n",
      "episode: 1535   score: 1.0   memory length: 308081   epsilon: 0.5879976400089442    steps: 154    lr: 1.6000000000000003e-05     evaluation reward: 3.33\n",
      "episode: 1536   score: 2.0   memory length: 308282   epsilon: 0.5875996600089528    steps: 201    lr: 1.6000000000000003e-05     evaluation reward: 3.3\n",
      "episode: 1537   score: 4.0   memory length: 308535   epsilon: 0.5870987200089637    steps: 253    lr: 1.6000000000000003e-05     evaluation reward: 3.32\n",
      "episode: 1538   score: 1.0   memory length: 308705   epsilon: 0.586762120008971    steps: 170    lr: 1.6000000000000003e-05     evaluation reward: 3.3\n",
      "episode: 1539   score: 8.0   memory length: 309139   epsilon: 0.5859028000089896    steps: 434    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1540   score: 4.0   memory length: 309397   epsilon: 0.5853919600090007    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 3.36\n",
      "episode: 1541   score: 6.0   memory length: 309726   epsilon: 0.5847405400090149    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 3.38\n",
      "episode: 1542   score: 7.0   memory length: 310141   epsilon: 0.5839188400090327    steps: 415    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1543   score: 3.0   memory length: 310410   epsilon: 0.5833862200090443    steps: 269    lr: 1.6000000000000003e-05     evaluation reward: 3.43\n",
      "episode: 1544   score: 3.0   memory length: 310641   epsilon: 0.5829288400090542    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1545   score: 4.0   memory length: 310921   epsilon: 0.5823744400090662    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 3.46\n",
      "episode: 1546   score: 6.0   memory length: 311279   epsilon: 0.5816656000090816    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 3.5\n",
      "episode: 1547   score: 3.0   memory length: 311492   epsilon: 0.5812438600090908    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.5\n",
      "episode: 1548   score: 5.0   memory length: 311814   epsilon: 0.5806063000091046    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n",
      "episode: 1549   score: 3.0   memory length: 312060   epsilon: 0.5801192200091152    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n",
      "episode: 1550   score: 1.0   memory length: 312231   epsilon: 0.5797806400091225    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 3.49\n",
      "episode: 1551   score: 4.0   memory length: 312526   epsilon: 0.5791965400091352    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.5\n",
      "episode: 1552   score: 2.0   memory length: 312707   epsilon: 0.578838160009143    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 3.48\n",
      "episode: 1553   score: 3.0   memory length: 312936   epsilon: 0.5783847400091529    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.48\n",
      "episode: 1554   score: 3.0   memory length: 313163   epsilon: 0.5779352800091626    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.47\n",
      "episode: 1555   score: 6.0   memory length: 313520   epsilon: 0.577228420009178    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 3.49\n",
      "episode: 1556   score: 4.0   memory length: 313779   epsilon: 0.5767156000091891    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 3.46\n",
      "episode: 1557   score: 4.0   memory length: 314041   epsilon: 0.5761968400092004    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 3.47\n",
      "episode: 1558   score: 3.0   memory length: 314286   epsilon: 0.5757117400092109    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n",
      "episode: 1559   score: 4.0   memory length: 314563   epsilon: 0.5751632800092228    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1560   score: 2.0   memory length: 314763   epsilon: 0.5747672800092314    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1561   score: 3.0   memory length: 315010   epsilon: 0.574278220009242    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1562   score: 4.0   memory length: 315286   epsilon: 0.5737317400092539    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1563   score: 1.0   memory length: 315456   epsilon: 0.5733951400092612    steps: 170    lr: 1.6000000000000003e-05     evaluation reward: 3.45\n",
      "episode: 1564   score: 2.0   memory length: 315655   epsilon: 0.5730011200092697    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.44\n",
      "episode: 1565   score: 10.0   memory length: 316087   epsilon: 0.5721457600092883    steps: 432    lr: 1.6000000000000003e-05     evaluation reward: 3.51\n",
      "episode: 1566   score: 4.0   memory length: 316350   epsilon: 0.5716250200092996    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n",
      "episode: 1567   score: 4.0   memory length: 316612   epsilon: 0.5711062600093109    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 3.52\n",
      "episode: 1568   score: 5.0   memory length: 316937   epsilon: 0.5704627600093248    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 3.54\n",
      "episode: 1569   score: 5.0   memory length: 317260   epsilon: 0.5698232200093387    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1570   score: 8.0   memory length: 317659   epsilon: 0.5690332000093559    steps: 399    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1571   score: 2.0   memory length: 317858   epsilon: 0.5686391800093644    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1572   score: 4.0   memory length: 318134   epsilon: 0.5680927000093763    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1573   score: 5.0   memory length: 318441   epsilon: 0.5674848400093895    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 3.62\n",
      "episode: 1574   score: 4.0   memory length: 318699   epsilon: 0.5669740000094006    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1575   score: 7.0   memory length: 319167   epsilon: 0.5660473600094207    steps: 468    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1576   score: 3.0   memory length: 319396   epsilon: 0.5655939400094305    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1577   score: 1.0   memory length: 319567   epsilon: 0.5652553600094379    steps: 171    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1578   score: 4.0   memory length: 319859   epsilon: 0.5646772000094504    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 3.58\n",
      "episode: 1579   score: 4.0   memory length: 320156   epsilon: 0.5640891400094632    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 3.59\n",
      "episode: 1580   score: 4.0   memory length: 320455   epsilon: 0.563497120009476    steps: 299    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1581   score: 3.0   memory length: 320722   epsilon: 0.5629684600094875    steps: 267    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1582   score: 2.0   memory length: 320924   epsilon: 0.5625685000094962    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1583   score: 6.0   memory length: 321297   epsilon: 0.5618299600095122    steps: 373    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1584   score: 3.0   memory length: 321508   epsilon: 0.5614121800095213    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1585   score: 4.0   memory length: 321786   epsilon: 0.5608617400095333    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1586   score: 1.0   memory length: 321956   epsilon: 0.5605251400095406    steps: 170    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1587   score: 4.0   memory length: 322216   epsilon: 0.5600103400095517    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1588   score: 9.0   memory length: 322568   epsilon: 0.5593133800095669    steps: 352    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n",
      "episode: 1589   score: 2.0   memory length: 322767   epsilon: 0.5589193600095754    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1590   score: 2.0   memory length: 322965   epsilon: 0.5585273200095839    steps: 198    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1591   score: 4.0   memory length: 323243   epsilon: 0.5579768800095959    steps: 278    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1592   score: 3.0   memory length: 323488   epsilon: 0.5574917800096064    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n",
      "episode: 1593   score: 5.0   memory length: 323815   epsilon: 0.5568443200096205    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n",
      "episode: 1594   score: 2.0   memory length: 324017   epsilon: 0.5564443600096292    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1595   score: 4.0   memory length: 324294   epsilon: 0.5558959000096411    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1596   score: 2.0   memory length: 324477   epsilon: 0.5555335600096489    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1597   score: 5.0   memory length: 324806   epsilon: 0.5548821400096631    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1598   score: 2.0   memory length: 325025   epsilon: 0.5544485200096725    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n",
      "episode: 1599   score: 3.0   memory length: 325239   epsilon: 0.5540248000096817    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1600   score: 2.0   memory length: 325438   epsilon: 0.5536307800096902    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1601   score: 2.0   memory length: 325621   epsilon: 0.5532684400096981    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1602   score: 4.0   memory length: 325920   epsilon: 0.552676420009711    steps: 299    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1603   score: 7.0   memory length: 326325   epsilon: 0.5518745200097284    steps: 405    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1604   score: 2.0   memory length: 326542   epsilon: 0.5514448600097377    steps: 217    lr: 1.6000000000000003e-05     evaluation reward: 3.54\n",
      "episode: 1605   score: 3.0   memory length: 326809   epsilon: 0.5509162000097492    steps: 267    lr: 1.6000000000000003e-05     evaluation reward: 3.54\n",
      "episode: 1606   score: 4.0   memory length: 327085   epsilon: 0.550369720009761    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1607   score: 5.0   memory length: 327412   epsilon: 0.5497222600097751    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 3.56\n",
      "episode: 1608   score: 4.0   memory length: 327708   epsilon: 0.5491361800097878    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 3.57\n",
      "episode: 1609   score: 5.0   memory length: 328012   epsilon: 0.5485342600098009    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 3.61\n",
      "episode: 1610   score: 3.0   memory length: 328242   epsilon: 0.5480788600098108    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1611   score: 5.0   memory length: 328571   epsilon: 0.5474274400098249    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1612   score: 4.0   memory length: 328834   epsilon: 0.5469067000098362    steps: 263    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1613   score: 3.0   memory length: 329048   epsilon: 0.5464829800098454    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1614   score: 5.0   memory length: 329374   epsilon: 0.5458375000098594    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.65\n",
      "episode: 1615   score: 6.0   memory length: 329732   epsilon: 0.5451286600098748    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1616   score: 3.0   memory length: 329964   epsilon: 0.5446693000098848    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1617   score: 3.0   memory length: 330210   epsilon: 0.5441822200098954    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1618   score: 2.0   memory length: 330410   epsilon: 0.543786220009904    steps: 200    lr: 1.6000000000000003e-05     evaluation reward: 3.66\n",
      "episode: 1619   score: 2.0   memory length: 330593   epsilon: 0.5434238800099118    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.64\n",
      "episode: 1620   score: 3.0   memory length: 330820   epsilon: 0.5429744200099216    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.63\n",
      "episode: 1621   score: 5.0   memory length: 331153   epsilon: 0.5423150800099359    steps: 333    lr: 1.6000000000000003e-05     evaluation reward: 3.67\n",
      "episode: 1622   score: 4.0   memory length: 331411   epsilon: 0.541804240009947    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1623   score: 4.0   memory length: 331706   epsilon: 0.5412201400099597    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n",
      "episode: 1624   score: 3.0   memory length: 331933   epsilon: 0.5407706800099694    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.7\n",
      "episode: 1625   score: 10.0   memory length: 332423   epsilon: 0.5398004800099905    steps: 490    lr: 1.6000000000000003e-05     evaluation reward: 3.76\n",
      "episode: 1626   score: 4.0   memory length: 332700   epsilon: 0.5392520200100024    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n",
      "episode: 1627   score: 4.0   memory length: 332966   epsilon: 0.5387253400100138    steps: 266    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n",
      "episode: 1628   score: 3.0   memory length: 333195   epsilon: 0.5382719200100237    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n",
      "episode: 1629   score: 4.0   memory length: 333456   epsilon: 0.5377551400100349    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n",
      "episode: 1630   score: 6.0   memory length: 333828   epsilon: 0.5370185800100509    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 3.86\n",
      "episode: 1631   score: 1.0   memory length: 333980   epsilon: 0.5367176200100574    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 3.82\n",
      "episode: 1632   score: 4.0   memory length: 334259   epsilon: 0.5361652000100694    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n",
      "episode: 1633   score: 2.0   memory length: 334458   epsilon: 0.535771180010078    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n",
      "episode: 1634   score: 4.0   memory length: 334705   epsilon: 0.5352821200100886    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 3.81\n",
      "episode: 1635   score: 4.0   memory length: 335022   epsilon: 0.5346544600101022    steps: 317    lr: 1.6000000000000003e-05     evaluation reward: 3.84\n",
      "episode: 1636   score: 3.0   memory length: 335254   epsilon: 0.5341951000101122    steps: 232    lr: 1.6000000000000003e-05     evaluation reward: 3.85\n",
      "episode: 1637   score: 2.0   memory length: 335473   epsilon: 0.5337614800101216    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 3.83\n",
      "episode: 1638   score: 3.0   memory length: 335701   epsilon: 0.5333100400101314    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.85\n",
      "episode: 1639   score: 2.0   memory length: 335920   epsilon: 0.5328764200101408    steps: 219    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n",
      "episode: 1640   score: 3.0   memory length: 336132   epsilon: 0.5324566600101499    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.78\n",
      "episode: 1641   score: 5.0   memory length: 336459   epsilon: 0.531809200010164    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 3.77\n",
      "episode: 1642   score: 4.0   memory length: 336757   epsilon: 0.5312191600101768    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n",
      "episode: 1643   score: 3.0   memory length: 337003   epsilon: 0.5307320800101873    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n",
      "episode: 1644   score: 2.0   memory length: 337202   epsilon: 0.5303380600101959    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.73\n",
      "episode: 1645   score: 3.0   memory length: 337429   epsilon: 0.5298886000102057    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.72\n",
      "episode: 1646   score: 3.0   memory length: 337656   epsilon: 0.5294391400102154    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1647   score: 5.0   memory length: 337980   epsilon: 0.5287976200102293    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1648   score: 2.0   memory length: 338162   epsilon: 0.5284372600102372    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1649   score: 3.0   memory length: 338391   epsilon: 0.527983840010247    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 3.68\n",
      "episode: 1650   score: 4.0   memory length: 338637   epsilon: 0.5274967600102576    steps: 246    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1651   score: 2.0   memory length: 338838   epsilon: 0.5270987800102662    steps: 201    lr: 1.6000000000000003e-05     evaluation reward: 3.69\n",
      "episode: 1652   score: 4.0   memory length: 339135   epsilon: 0.526510720010279    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 3.71\n",
      "episode: 1653   score: 7.0   memory length: 339506   epsilon: 0.5257761400102949    steps: 371    lr: 1.6000000000000003e-05     evaluation reward: 3.75\n",
      "episode: 1654   score: 4.0   memory length: 339783   epsilon: 0.5252276800103068    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 3.76\n",
      "episode: 1655   score: 4.0   memory length: 340059   epsilon: 0.5246812000103187    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 3.74\n",
      "episode: 1656   score: 9.0   memory length: 340373   epsilon: 0.5240594800103322    steps: 314    lr: 1.6000000000000003e-05     evaluation reward: 3.79\n",
      "episode: 1657   score: 5.0   memory length: 340696   epsilon: 0.5234199400103461    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 3.8\n",
      "episode: 1658   score: 7.0   memory length: 341056   epsilon: 0.5227071400103616    steps: 360    lr: 1.6000000000000003e-05     evaluation reward: 3.84\n",
      "episode: 1659   score: 4.0   memory length: 341299   epsilon: 0.522226000010372    steps: 243    lr: 1.6000000000000003e-05     evaluation reward: 3.84\n",
      "episode: 1660   score: 11.0   memory length: 341728   epsilon: 0.5213765800103904    steps: 429    lr: 1.6000000000000003e-05     evaluation reward: 3.93\n",
      "episode: 1661   score: 2.0   memory length: 341930   epsilon: 0.5209766200103991    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 3.92\n",
      "episode: 1662   score: 2.0   memory length: 342113   epsilon: 0.520614280010407    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1663   score: 5.0   memory length: 342440   epsilon: 0.519966820010421    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 3.94\n",
      "episode: 1664   score: 3.0   memory length: 342690   epsilon: 0.5194718200104318    steps: 250    lr: 1.6000000000000003e-05     evaluation reward: 3.95\n",
      "episode: 1665   score: 2.0   memory length: 342889   epsilon: 0.5190778000104403    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n",
      "episode: 1666   score: 4.0   memory length: 343150   epsilon: 0.5185610200104516    steps: 261    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n",
      "episode: 1667   score: 6.0   memory length: 343522   epsilon: 0.5178244600104676    steps: 372    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n",
      "episode: 1668   score: 5.0   memory length: 343833   epsilon: 0.5172086800104809    steps: 311    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n",
      "episode: 1669   score: 6.0   memory length: 344211   epsilon: 0.5164602400104972    steps: 378    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1670   score: 6.0   memory length: 344565   epsilon: 0.5157593200105124    steps: 354    lr: 1.6000000000000003e-05     evaluation reward: 3.88\n",
      "episode: 1671   score: 4.0   memory length: 344859   epsilon: 0.515177200010525    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1672   score: 3.0   memory length: 345090   epsilon: 0.514719820010535    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n",
      "episode: 1673   score: 6.0   memory length: 345466   epsilon: 0.5139753400105511    steps: 376    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1674   score: 3.0   memory length: 345694   epsilon: 0.5135239000105609    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n",
      "episode: 1675   score: 5.0   memory length: 346016   epsilon: 0.5128863400105748    steps: 322    lr: 1.6000000000000003e-05     evaluation reward: 3.87\n",
      "episode: 1676   score: 4.0   memory length: 346320   epsilon: 0.5122844200105878    steps: 304    lr: 1.6000000000000003e-05     evaluation reward: 3.88\n",
      "episode: 1677   score: 3.0   memory length: 346532   epsilon: 0.5118646600105969    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 3.9\n",
      "episode: 1678   score: 3.0   memory length: 346783   epsilon: 0.5113676800106077    steps: 251    lr: 1.6000000000000003e-05     evaluation reward: 3.89\n",
      "episode: 1679   score: 9.0   memory length: 347279   epsilon: 0.510385600010629    steps: 496    lr: 1.6000000000000003e-05     evaluation reward: 3.94\n",
      "episode: 1680   score: 6.0   memory length: 347623   epsilon: 0.5097044800106438    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n",
      "episode: 1681   score: 2.0   memory length: 347825   epsilon: 0.5093045200106525    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 3.95\n",
      "episode: 1682   score: 7.0   memory length: 348187   epsilon: 0.5085877600106681    steps: 362    lr: 1.6000000000000003e-05     evaluation reward: 4.0\n",
      "episode: 1683   score: 5.0   memory length: 348513   epsilon: 0.5079422800106821    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n",
      "episode: 1684   score: 3.0   memory length: 348726   epsilon: 0.5075205400106912    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n",
      "episode: 1685   score: 3.0   memory length: 348954   epsilon: 0.507069100010701    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 3.98\n",
      "episode: 1686   score: 6.0   memory length: 349293   epsilon: 0.5063978800107156    steps: 339    lr: 1.6000000000000003e-05     evaluation reward: 4.03\n",
      "episode: 1687   score: 3.0   memory length: 349504   epsilon: 0.5059801000107247    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n",
      "episode: 1688   score: 3.0   memory length: 349713   epsilon: 0.5055662800107337    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 3.96\n",
      "episode: 1689   score: 5.0   memory length: 350020   epsilon: 0.5049584200107469    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 3.99\n",
      "episode: 1690   score: 8.0   memory length: 350391   epsilon: 0.5042238400107628    steps: 371    lr: 1.6000000000000003e-05     evaluation reward: 4.05\n",
      "episode: 1691   score: 1.0   memory length: 350543   epsilon: 0.5039228800107693    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n",
      "episode: 1692   score: 5.0   memory length: 350868   epsilon: 0.5032793800107833    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.04\n",
      "episode: 1693   score: 3.0   memory length: 351116   epsilon: 0.502788340010794    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 4.02\n",
      "episode: 1694   score: 7.0   memory length: 351492   epsilon: 0.5020438600108101    steps: 376    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1695   score: 5.0   memory length: 351838   epsilon: 0.501358780010825    steps: 346    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1696   score: 3.0   memory length: 352086   epsilon: 0.5008677400108357    steps: 248    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1697   score: 3.0   memory length: 352338   epsilon: 0.5003687800108465    steps: 252    lr: 1.6000000000000003e-05     evaluation reward: 4.07\n",
      "episode: 1698   score: 6.0   memory length: 352674   epsilon: 0.4997035000108526    steps: 336    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1699   score: 3.0   memory length: 352887   epsilon: 0.49928176001084995    steps: 213    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1700   score: 1.0   memory length: 353039   epsilon: 0.49898080001084805    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1701   score: 2.0   memory length: 353222   epsilon: 0.49861846001084575    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1702   score: 5.0   memory length: 353538   epsilon: 0.4979927800108418    steps: 316    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1703   score: 4.0   memory length: 353834   epsilon: 0.4974067000108381    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1704   score: 3.0   memory length: 354063   epsilon: 0.4969532800108352    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.09\n",
      "episode: 1705   score: 8.0   memory length: 354419   epsilon: 0.49624840001083076    steps: 356    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1706   score: 4.0   memory length: 354713   epsilon: 0.4956662800108271    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1707   score: 3.0   memory length: 354927   epsilon: 0.4952425600108244    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1708   score: 3.0   memory length: 355172   epsilon: 0.4947574600108213    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1709   score: 5.0   memory length: 355469   epsilon: 0.4941694000108176    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1710   score: 6.0   memory length: 355813   epsilon: 0.4934882800108133    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1711   score: 4.0   memory length: 356092   epsilon: 0.4929358600108098    steps: 279    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1712   score: 5.0   memory length: 356437   epsilon: 0.4922527600108055    steps: 345    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1713   score: 4.0   memory length: 356714   epsilon: 0.491704300010802    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1714   score: 5.0   memory length: 357024   epsilon: 0.4910905000107981    steps: 310    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1715   score: 2.0   memory length: 357223   epsilon: 0.49069648001079563    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1716   score: 3.0   memory length: 357453   epsilon: 0.49024108001079275    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1717   score: 5.0   memory length: 357779   epsilon: 0.48959560001078867    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 4.13\n",
      "episode: 1718   score: 3.0   memory length: 358008   epsilon: 0.4891421800107858    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1719   score: 5.0   memory length: 358325   epsilon: 0.4885145200107818    steps: 317    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n",
      "episode: 1720   score: 3.0   memory length: 358537   epsilon: 0.48809476001077917    steps: 212    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n",
      "episode: 1721   score: 4.0   memory length: 358835   epsilon: 0.48750472001077544    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n",
      "episode: 1722   score: 3.0   memory length: 359064   epsilon: 0.48705130001077257    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1723   score: 4.0   memory length: 359359   epsilon: 0.4864672000107689    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1724   score: 2.0   memory length: 359561   epsilon: 0.48606724001076634    steps: 202    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1725   score: 4.0   memory length: 359857   epsilon: 0.48548116001076264    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.08\n",
      "episode: 1726   score: 7.0   memory length: 360249   epsilon: 0.4847050000107577    steps: 392    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1727   score: 5.0   memory length: 360555   epsilon: 0.4840991200107539    steps: 306    lr: 1.6000000000000003e-05     evaluation reward: 4.12\n",
      "episode: 1728   score: 7.0   memory length: 360954   epsilon: 0.4833091000107489    steps: 399    lr: 1.6000000000000003e-05     evaluation reward: 4.16\n",
      "episode: 1729   score: 3.0   memory length: 361183   epsilon: 0.482855680010746    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1730   score: 1.0   memory length: 361335   epsilon: 0.4825547200107441    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 4.1\n",
      "episode: 1731   score: 2.0   memory length: 361517   epsilon: 0.48219436001074184    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1732   score: 4.0   memory length: 361762   epsilon: 0.48170926001073877    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 4.11\n",
      "episode: 1733   score: 5.0   memory length: 362090   epsilon: 0.48105982001073466    steps: 328    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1734   score: 4.0   memory length: 362389   epsilon: 0.4804678000107309    steps: 299    lr: 1.6000000000000003e-05     evaluation reward: 4.14\n",
      "episode: 1735   score: 5.0   memory length: 362713   epsilon: 0.47982628001072686    steps: 324    lr: 1.6000000000000003e-05     evaluation reward: 4.15\n",
      "episode: 1736   score: 5.0   memory length: 363000   epsilon: 0.47925802001072326    steps: 287    lr: 1.6000000000000003e-05     evaluation reward: 4.17\n",
      "episode: 1737   score: 3.0   memory length: 363230   epsilon: 0.4788026200107204    steps: 230    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1738   score: 3.0   memory length: 363457   epsilon: 0.47835316001071754    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 4.18\n",
      "episode: 1739   score: 4.0   memory length: 363738   epsilon: 0.477796780010714    steps: 281    lr: 1.6000000000000003e-05     evaluation reward: 4.2\n",
      "episode: 1740   score: 2.0   memory length: 363920   epsilon: 0.47743642001071174    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1741   score: 5.0   memory length: 364269   epsilon: 0.47674540001070737    steps: 349    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1742   score: 4.0   memory length: 364546   epsilon: 0.4761969400107039    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1743   score: 5.0   memory length: 364854   epsilon: 0.47558710001070004    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1744   score: 6.0   memory length: 365197   epsilon: 0.47490796001069574    steps: 343    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1745   score: 6.0   memory length: 365591   epsilon: 0.4741278400106908    steps: 394    lr: 1.6000000000000003e-05     evaluation reward: 4.28\n",
      "episode: 1746   score: 5.0   memory length: 365916   epsilon: 0.47348434001068673    steps: 325    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1747   score: 5.0   memory length: 366223   epsilon: 0.4728764800106829    steps: 307    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1748   score: 7.0   memory length: 366614   epsilon: 0.472102300010678    steps: 391    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1749   score: 5.0   memory length: 366905   epsilon: 0.47152612001067434    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 4.37\n",
      "episode: 1750   score: 5.0   memory length: 367198   epsilon: 0.4709459800106707    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 4.38\n",
      "episode: 1751   score: 3.0   memory length: 367427   epsilon: 0.4704925600106678    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1752   score: 1.0   memory length: 367579   epsilon: 0.4701916000106659    steps: 152    lr: 1.6000000000000003e-05     evaluation reward: 4.36\n",
      "episode: 1753   score: 5.0   memory length: 367870   epsilon: 0.46961542001066225    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 4.34\n",
      "episode: 1754   score: 3.0   memory length: 368098   epsilon: 0.4691639800106594    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.33\n",
      "episode: 1755   score: 3.0   memory length: 368329   epsilon: 0.4687066000106565    steps: 231    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1756   score: 4.0   memory length: 368620   epsilon: 0.46813042001065286    steps: 291    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1757   score: 5.0   memory length: 368949   epsilon: 0.46747900001064874    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1758   score: 7.0   memory length: 369343   epsilon: 0.4666988800106438    steps: 394    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1759   score: 0.0   memory length: 369467   epsilon: 0.46645336001064225    steps: 124    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1760   score: 7.0   memory length: 369861   epsilon: 0.4656732400106373    steps: 394    lr: 1.6000000000000003e-05     evaluation reward: 4.19\n",
      "episode: 1761   score: 4.0   memory length: 370155   epsilon: 0.46509112001063363    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1762   score: 3.0   memory length: 370384   epsilon: 0.46463770001063076    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.22\n",
      "episode: 1763   score: 4.0   memory length: 370678   epsilon: 0.4640555800106271    steps: 294    lr: 1.6000000000000003e-05     evaluation reward: 4.21\n",
      "episode: 1764   score: 7.0   memory length: 371037   epsilon: 0.4633447600106226    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1765   score: 6.0   memory length: 371358   epsilon: 0.46270918001061856    steps: 321    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1766   score: 4.0   memory length: 371616   epsilon: 0.4621983400106153    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1767   score: 4.0   memory length: 371876   epsilon: 0.46168354001061207    steps: 260    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1768   score: 5.0   memory length: 372192   epsilon: 0.4610578600106081    steps: 316    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1769   score: 6.0   memory length: 372551   epsilon: 0.4603470400106036    steps: 359    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1770   score: 4.0   memory length: 372810   epsilon: 0.45983422001060037    steps: 259    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1771   score: 2.0   memory length: 373009   epsilon: 0.4594402000105979    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 4.23\n",
      "episode: 1772   score: 7.0   memory length: 373397   epsilon: 0.458671960010593    steps: 388    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1773   score: 4.0   memory length: 373674   epsilon: 0.45812350001058955    steps: 277    lr: 1.6000000000000003e-05     evaluation reward: 4.25\n",
      "episode: 1774   score: 4.0   memory length: 373936   epsilon: 0.45760474001058626    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 4.26\n",
      "episode: 1775   score: 9.0   memory length: 374410   epsilon: 0.4566662200105803    steps: 474    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1776   score: 5.0   memory length: 374740   epsilon: 0.4560128200105762    steps: 330    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1777   score: 3.0   memory length: 374949   epsilon: 0.4555990000105736    steps: 209    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1778   score: 4.0   memory length: 375244   epsilon: 0.4550149000105699    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1779   score: 9.0   memory length: 375689   epsilon: 0.4541338000105643    steps: 445    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1780   score: 5.0   memory length: 376033   epsilon: 0.45345268001056    steps: 344    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1781   score: 5.0   memory length: 376359   epsilon: 0.4528072000105559    steps: 326    lr: 1.6000000000000003e-05     evaluation reward: 4.34\n",
      "episode: 1782   score: 2.0   memory length: 376542   epsilon: 0.4524448600105536    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 4.29\n",
      "episode: 1783   score: 3.0   memory length: 376770   epsilon: 0.45199342001055076    steps: 228    lr: 1.6000000000000003e-05     evaluation reward: 4.27\n",
      "episode: 1784   score: 6.0   memory length: 377100   epsilon: 0.4513400200105466    steps: 330    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1785   score: 3.0   memory length: 377349   epsilon: 0.4508470000105435    steps: 249    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1786   score: 7.0   memory length: 377753   epsilon: 0.45004708001053845    steps: 404    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1787   score: 2.0   memory length: 377952   epsilon: 0.44965306001053595    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1788   score: 10.0   memory length: 378341   epsilon: 0.4488828400105311    steps: 389    lr: 1.6000000000000003e-05     evaluation reward: 4.37\n",
      "episode: 1789   score: 2.0   memory length: 378523   epsilon: 0.4485224800105288    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.34\n",
      "episode: 1790   score: 5.0   memory length: 378840   epsilon: 0.44789482001052483    steps: 317    lr: 1.6000000000000003e-05     evaluation reward: 4.31\n",
      "episode: 1791   score: 2.0   memory length: 379041   epsilon: 0.4474968400105223    steps: 201    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1792   score: 5.0   memory length: 379349   epsilon: 0.44688700001051845    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1793   score: 6.0   memory length: 379720   epsilon: 0.4461524200105138    steps: 371    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1794   score: 4.0   memory length: 379996   epsilon: 0.44560594001051035    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.32\n",
      "episode: 1795   score: 3.0   memory length: 380225   epsilon: 0.4451525200105075    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.3\n",
      "episode: 1796   score: 8.0   memory length: 380673   epsilon: 0.44426548001050187    steps: 448    lr: 1.6000000000000003e-05     evaluation reward: 4.35\n",
      "episode: 1797   score: 2.0   memory length: 380856   epsilon: 0.4439031400104996    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 4.34\n",
      "episode: 1798   score: 8.0   memory length: 381253   epsilon: 0.4431170800104946    steps: 397    lr: 1.6000000000000003e-05     evaluation reward: 4.36\n",
      "episode: 1799   score: 3.0   memory length: 381464   epsilon: 0.44269930001049196    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.36\n",
      "episode: 1800   score: 4.0   memory length: 381764   epsilon: 0.4421053000104882    steps: 300    lr: 1.6000000000000003e-05     evaluation reward: 4.39\n",
      "episode: 1801   score: 9.0   memory length: 382223   epsilon: 0.44119648001048245    steps: 459    lr: 1.6000000000000003e-05     evaluation reward: 4.46\n",
      "episode: 1802   score: 4.0   memory length: 382503   epsilon: 0.44064208001047894    steps: 280    lr: 1.6000000000000003e-05     evaluation reward: 4.45\n",
      "episode: 1803   score: 5.0   memory length: 382826   epsilon: 0.4400025400104749    steps: 323    lr: 1.6000000000000003e-05     evaluation reward: 4.46\n",
      "episode: 1804   score: 5.0   memory length: 383131   epsilon: 0.4393986400104711    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 4.48\n",
      "episode: 1805   score: 3.0   memory length: 383360   epsilon: 0.4389452200104682    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.43\n",
      "episode: 1806   score: 2.0   memory length: 383541   epsilon: 0.43858684001046594    steps: 181    lr: 1.6000000000000003e-05     evaluation reward: 4.41\n",
      "episode: 1807   score: 6.0   memory length: 383902   epsilon: 0.4378720600104614    steps: 361    lr: 1.6000000000000003e-05     evaluation reward: 4.44\n",
      "episode: 1808   score: 2.0   memory length: 384084   epsilon: 0.43751170001045914    steps: 182    lr: 1.6000000000000003e-05     evaluation reward: 4.43\n",
      "episode: 1809   score: 3.0   memory length: 384313   epsilon: 0.43705828001045627    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.41\n",
      "episode: 1810   score: 3.0   memory length: 384524   epsilon: 0.4366405000104536    steps: 211    lr: 1.6000000000000003e-05     evaluation reward: 4.38\n",
      "episode: 1811   score: 6.0   memory length: 384920   epsilon: 0.43585642001044866    steps: 396    lr: 1.6000000000000003e-05     evaluation reward: 4.4\n",
      "episode: 1812   score: 6.0   memory length: 385296   epsilon: 0.43511194001044395    steps: 376    lr: 1.6000000000000003e-05     evaluation reward: 4.41\n",
      "episode: 1813   score: 5.0   memory length: 385594   epsilon: 0.4345219000104402    steps: 298    lr: 1.6000000000000003e-05     evaluation reward: 4.42\n",
      "episode: 1814   score: 5.0   memory length: 385896   epsilon: 0.43392394001043644    steps: 302    lr: 1.6000000000000003e-05     evaluation reward: 4.42\n",
      "episode: 1815   score: 4.0   memory length: 386189   epsilon: 0.43334380001043277    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 4.44\n",
      "episode: 1816   score: 7.0   memory length: 386612   epsilon: 0.43250626001042747    steps: 423    lr: 1.6000000000000003e-05     evaluation reward: 4.48\n",
      "episode: 1817   score: 4.0   memory length: 386886   epsilon: 0.43196374001042404    steps: 274    lr: 1.6000000000000003e-05     evaluation reward: 4.47\n",
      "episode: 1818   score: 10.0   memory length: 387298   epsilon: 0.4311479800104189    steps: 412    lr: 1.6000000000000003e-05     evaluation reward: 4.54\n",
      "episode: 1819   score: 5.0   memory length: 387591   epsilon: 0.4305678400104152    steps: 293    lr: 1.6000000000000003e-05     evaluation reward: 4.54\n",
      "episode: 1820   score: 3.0   memory length: 387818   epsilon: 0.43011838001041236    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 4.54\n",
      "episode: 1821   score: 7.0   memory length: 388199   epsilon: 0.4293640000104076    steps: 381    lr: 1.6000000000000003e-05     evaluation reward: 4.57\n",
      "episode: 1822   score: 7.0   memory length: 388574   epsilon: 0.4286215000104029    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 4.61\n",
      "episode: 1823   score: 4.0   memory length: 388850   epsilon: 0.42807502001039943    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.61\n",
      "episode: 1824   score: 2.0   memory length: 389033   epsilon: 0.42771268001039714    steps: 183    lr: 1.6000000000000003e-05     evaluation reward: 4.61\n",
      "episode: 1825   score: 5.0   memory length: 389328   epsilon: 0.42712858001039344    steps: 295    lr: 1.6000000000000003e-05     evaluation reward: 4.62\n",
      "episode: 1826   score: 6.0   memory length: 389685   epsilon: 0.42642172001038897    steps: 357    lr: 1.6000000000000003e-05     evaluation reward: 4.61\n",
      "episode: 1827   score: 5.0   memory length: 389994   epsilon: 0.4258099000103851    steps: 309    lr: 1.6000000000000003e-05     evaluation reward: 4.61\n",
      "episode: 1828   score: 4.0   memory length: 390270   epsilon: 0.42526342001038164    steps: 276    lr: 1.6000000000000003e-05     evaluation reward: 4.58\n",
      "episode: 1829   score: 6.0   memory length: 390616   epsilon: 0.4245783400103773    steps: 346    lr: 1.6000000000000003e-05     evaluation reward: 4.61\n",
      "episode: 1830   score: 3.0   memory length: 390845   epsilon: 0.42412492001037444    steps: 229    lr: 1.6000000000000003e-05     evaluation reward: 4.63\n",
      "episode: 1831   score: 7.0   memory length: 391219   epsilon: 0.42338440001036975    steps: 374    lr: 1.6000000000000003e-05     evaluation reward: 4.68\n",
      "episode: 1832   score: 6.0   memory length: 391559   epsilon: 0.4227112000103655    steps: 340    lr: 1.6000000000000003e-05     evaluation reward: 4.7\n",
      "episode: 1833   score: 4.0   memory length: 391804   epsilon: 0.4222261000103624    steps: 245    lr: 1.6000000000000003e-05     evaluation reward: 4.69\n",
      "episode: 1834   score: 4.0   memory length: 392066   epsilon: 0.42170734001035914    steps: 262    lr: 1.6000000000000003e-05     evaluation reward: 4.69\n",
      "episode: 1835   score: 5.0   memory length: 392413   epsilon: 0.4210202800103548    steps: 347    lr: 1.6000000000000003e-05     evaluation reward: 4.69\n",
      "episode: 1836   score: 5.0   memory length: 392705   epsilon: 0.42044212001035114    steps: 292    lr: 1.6000000000000003e-05     evaluation reward: 4.69\n",
      "episode: 1837   score: 5.0   memory length: 393010   epsilon: 0.4198382200103473    steps: 305    lr: 1.6000000000000003e-05     evaluation reward: 4.71\n",
      "episode: 1838   score: 4.0   memory length: 393274   epsilon: 0.419315500010344    steps: 264    lr: 1.6000000000000003e-05     evaluation reward: 4.72\n",
      "episode: 1839   score: 3.0   memory length: 393521   epsilon: 0.4188264400103409    steps: 247    lr: 1.6000000000000003e-05     evaluation reward: 4.71\n",
      "episode: 1840   score: 2.0   memory length: 393720   epsilon: 0.4184324200103384    steps: 199    lr: 1.6000000000000003e-05     evaluation reward: 4.71\n",
      "episode: 1841   score: 7.0   memory length: 394080   epsilon: 0.4177196200103339    steps: 360    lr: 1.6000000000000003e-05     evaluation reward: 4.73\n",
      "episode: 1842   score: 4.0   memory length: 394377   epsilon: 0.4171315600103302    steps: 297    lr: 1.6000000000000003e-05     evaluation reward: 4.73\n",
      "episode: 1843   score: 5.0   memory length: 394706   epsilon: 0.41648014001032607    steps: 329    lr: 1.6000000000000003e-05     evaluation reward: 4.73\n",
      "episode: 1844   score: 3.0   memory length: 394933   epsilon: 0.41603068001032323    steps: 227    lr: 1.6000000000000003e-05     evaluation reward: 4.7\n",
      "episode: 1845   score: 3.0   memory length: 395148   epsilon: 0.41560498001032053    steps: 215    lr: 1.6000000000000003e-05     evaluation reward: 4.67\n",
      "episode: 1846   score: 5.0   memory length: 395444   epsilon: 0.4150189000103168    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.67\n",
      "episode: 1847   score: 6.0   memory length: 395802   epsilon: 0.41431006001031234    steps: 358    lr: 1.6000000000000003e-05     evaluation reward: 4.68\n",
      "episode: 1848   score: 3.0   memory length: 396036   epsilon: 0.4138467400103094    steps: 234    lr: 1.6000000000000003e-05     evaluation reward: 4.64\n",
      "episode: 1849   score: 4.0   memory length: 396294   epsilon: 0.4133359000103062    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.63\n",
      "episode: 1850   score: 7.0   memory length: 396671   epsilon: 0.41258944001030146    steps: 377    lr: 1.6000000000000003e-05     evaluation reward: 4.65\n",
      "episode: 1851   score: 6.0   memory length: 396988   epsilon: 0.4119617800102975    steps: 317    lr: 1.6000000000000003e-05     evaluation reward: 4.68\n",
      "episode: 1852   score: 7.0   memory length: 397394   epsilon: 0.4111579000102924    steps: 406    lr: 1.6000000000000003e-05     evaluation reward: 4.74\n",
      "episode: 1853   score: 3.0   memory length: 397608   epsilon: 0.4107341800102897    steps: 214    lr: 1.6000000000000003e-05     evaluation reward: 4.72\n",
      "episode: 1854   score: 5.0   memory length: 397904   epsilon: 0.410148100010286    steps: 296    lr: 1.6000000000000003e-05     evaluation reward: 4.74\n",
      "episode: 1855   score: 5.0   memory length: 398231   epsilon: 0.4095006400102819    steps: 327    lr: 1.6000000000000003e-05     evaluation reward: 4.76\n",
      "episode: 1856   score: 8.0   memory length: 398726   epsilon: 0.4085205400102757    steps: 495    lr: 1.6000000000000003e-05     evaluation reward: 4.8\n",
      "episode: 1857   score: 7.0   memory length: 399101   epsilon: 0.407778040010271    steps: 375    lr: 1.6000000000000003e-05     evaluation reward: 4.82\n",
      "episode: 1858   score: 5.0   memory length: 399403   epsilon: 0.40718008001026723    steps: 302    lr: 1.6000000000000003e-05     evaluation reward: 4.8\n",
      "episode: 1859   score: 5.0   memory length: 399711   epsilon: 0.4065702400102634    steps: 308    lr: 1.6000000000000003e-05     evaluation reward: 4.85\n",
      "episode: 1860   score: 4.0   memory length: 399969   epsilon: 0.40605940001026014    steps: 258    lr: 1.6000000000000003e-05     evaluation reward: 4.82\n",
      "episode: 1861   score: 7.0   memory length: 400359   epsilon: 0.40528720001025526    steps: 390    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 1862   score: 4.0   memory length: 400620   epsilon: 0.404770420010252    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1863   score: 5.0   memory length: 400946   epsilon: 0.4041249400102479    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1864   score: 4.0   memory length: 401214   epsilon: 0.40359430001024454    steps: 268    lr: 6.400000000000001e-06     evaluation reward: 4.84\n",
      "episode: 1865   score: 9.0   memory length: 401676   epsilon: 0.40267954001023876    steps: 462    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1866   score: 3.0   memory length: 401905   epsilon: 0.4022261200102359    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.86\n",
      "episode: 1867   score: 7.0   memory length: 402293   epsilon: 0.401457880010231    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 1868   score: 3.0   memory length: 402522   epsilon: 0.40100446001022816    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1869   score: 4.0   memory length: 402782   epsilon: 0.4004896600102249    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.85\n",
      "episode: 1870   score: 6.0   memory length: 403119   epsilon: 0.3998224000102207    steps: 337    lr: 6.400000000000001e-06     evaluation reward: 4.87\n",
      "episode: 1871   score: 8.0   memory length: 403413   epsilon: 0.399240280010217    steps: 294    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 1872   score: 5.0   memory length: 403711   epsilon: 0.39865024001021326    steps: 298    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 1873   score: 10.0   memory length: 404233   epsilon: 0.3976166800102067    steps: 522    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 1874   score: 4.0   memory length: 404495   epsilon: 0.39709792001020344    steps: 262    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 1875   score: 4.0   memory length: 404771   epsilon: 0.3965514400102    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 1876   score: 4.0   memory length: 405047   epsilon: 0.3960049600101965    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 1877   score: 5.0   memory length: 405376   epsilon: 0.3953535400101924    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 1878   score: 4.0   memory length: 405643   epsilon: 0.39482488001018906    steps: 267    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 1879   score: 14.0   memory length: 406199   epsilon: 0.3937240000101821    steps: 556    lr: 6.400000000000001e-06     evaluation reward: 4.98\n",
      "episode: 1880   score: 4.0   memory length: 406482   epsilon: 0.39316366001017855    steps: 283    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 1881   score: 6.0   memory length: 406802   epsilon: 0.39253006001017454    steps: 320    lr: 6.400000000000001e-06     evaluation reward: 4.98\n",
      "episode: 1882   score: 7.0   memory length: 407141   epsilon: 0.3918588400101703    steps: 339    lr: 6.400000000000001e-06     evaluation reward: 5.03\n",
      "episode: 1883   score: 12.0   memory length: 407635   epsilon: 0.3908807200101641    steps: 494    lr: 6.400000000000001e-06     evaluation reward: 5.12\n",
      "episode: 1884   score: 5.0   memory length: 407948   epsilon: 0.3902609800101602    steps: 313    lr: 6.400000000000001e-06     evaluation reward: 5.11\n",
      "episode: 1885   score: 6.0   memory length: 408308   epsilon: 0.3895481800101557    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 5.14\n",
      "episode: 1886   score: 7.0   memory length: 408706   epsilon: 0.3887601400101507    steps: 398    lr: 6.400000000000001e-06     evaluation reward: 5.14\n",
      "episode: 1887   score: 6.0   memory length: 409081   epsilon: 0.388017640010146    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 5.18\n",
      "episode: 1888   score: 8.0   memory length: 409360   epsilon: 0.3874652200101425    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 5.16\n",
      "episode: 1889   score: 7.0   memory length: 409773   epsilon: 0.3866474800101373    steps: 413    lr: 6.400000000000001e-06     evaluation reward: 5.21\n",
      "episode: 1890   score: 6.0   memory length: 410089   epsilon: 0.38602180001013336    steps: 316    lr: 6.400000000000001e-06     evaluation reward: 5.22\n",
      "episode: 1891   score: 4.0   memory length: 410368   epsilon: 0.38546938001012987    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 5.24\n",
      "episode: 1892   score: 6.0   memory length: 410746   epsilon: 0.38472094001012513    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 5.25\n",
      "episode: 1893   score: 3.0   memory length: 410975   epsilon: 0.38426752001012227    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 5.22\n",
      "episode: 1894   score: 3.0   memory length: 411204   epsilon: 0.3838141000101194    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 5.21\n",
      "episode: 1895   score: 8.0   memory length: 411615   epsilon: 0.38300032001011425    steps: 411    lr: 6.400000000000001e-06     evaluation reward: 5.26\n",
      "episode: 1896   score: 4.0   memory length: 411891   epsilon: 0.3824538400101108    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 5.22\n",
      "episode: 1897   score: 7.0   memory length: 412298   epsilon: 0.3816479800101057    steps: 407    lr: 6.400000000000001e-06     evaluation reward: 5.27\n",
      "episode: 1898   score: 4.0   memory length: 412557   epsilon: 0.38113516001010245    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.23\n",
      "episode: 1899   score: 3.0   memory length: 412788   epsilon: 0.38067778001009955    steps: 231    lr: 6.400000000000001e-06     evaluation reward: 5.23\n",
      "episode: 1900   score: 20.0   memory length: 413394   epsilon: 0.37947790001009196    steps: 606    lr: 6.400000000000001e-06     evaluation reward: 5.39\n",
      "episode: 1901   score: 9.0   memory length: 413723   epsilon: 0.37882648001008784    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 5.39\n",
      "episode: 1902   score: 5.0   memory length: 414051   epsilon: 0.37817704001008373    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 5.4\n",
      "episode: 1903   score: 5.0   memory length: 414343   epsilon: 0.3775988800100801    steps: 292    lr: 6.400000000000001e-06     evaluation reward: 5.4\n",
      "episode: 1904   score: 4.0   memory length: 414620   epsilon: 0.3770504200100766    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 5.39\n",
      "episode: 1905   score: 8.0   memory length: 415080   epsilon: 0.37613962001007084    steps: 460    lr: 6.400000000000001e-06     evaluation reward: 5.44\n",
      "episode: 1906   score: 8.0   memory length: 415359   epsilon: 0.37558720001006735    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 5.5\n",
      "episode: 1907   score: 4.0   memory length: 415640   epsilon: 0.3750308200100638    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 5.48\n",
      "episode: 1908   score: 8.0   memory length: 416056   epsilon: 0.3742071400100586    steps: 416    lr: 6.400000000000001e-06     evaluation reward: 5.54\n",
      "episode: 1909   score: 5.0   memory length: 416382   epsilon: 0.37356166001005453    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 5.56\n",
      "episode: 1910   score: 4.0   memory length: 416643   epsilon: 0.37304488001005126    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 5.57\n",
      "episode: 1911   score: 5.0   memory length: 416955   epsilon: 0.37242712001004735    steps: 312    lr: 6.400000000000001e-06     evaluation reward: 5.56\n",
      "episode: 1912   score: 9.0   memory length: 417443   epsilon: 0.37146088001004124    steps: 488    lr: 6.400000000000001e-06     evaluation reward: 5.59\n",
      "episode: 1913   score: 5.0   memory length: 417769   epsilon: 0.37081540001003716    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 5.59\n",
      "episode: 1914   score: 4.0   memory length: 418043   epsilon: 0.3702728800100337    steps: 274    lr: 6.400000000000001e-06     evaluation reward: 5.58\n",
      "episode: 1915   score: 4.0   memory length: 418339   epsilon: 0.36968680001003    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 5.58\n",
      "episode: 1916   score: 7.0   memory length: 418716   epsilon: 0.3689403400100253    steps: 377    lr: 6.400000000000001e-06     evaluation reward: 5.58\n",
      "episode: 1917   score: 5.0   memory length: 419003   epsilon: 0.3683720800100217    steps: 287    lr: 6.400000000000001e-06     evaluation reward: 5.59\n",
      "episode: 1918   score: 3.0   memory length: 419248   epsilon: 0.3678869800100186    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 5.52\n",
      "episode: 1919   score: 6.0   memory length: 419589   epsilon: 0.36721180001001436    steps: 341    lr: 6.400000000000001e-06     evaluation reward: 5.53\n",
      "episode: 1920   score: 3.0   memory length: 419836   epsilon: 0.36672274001001126    steps: 247    lr: 6.400000000000001e-06     evaluation reward: 5.53\n",
      "episode: 1921   score: 4.0   memory length: 420096   epsilon: 0.366207940010008    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 5.5\n",
      "episode: 1922   score: 6.0   memory length: 420395   epsilon: 0.36561592001000426    steps: 299    lr: 6.400000000000001e-06     evaluation reward: 5.49\n",
      "episode: 1923   score: 2.0   memory length: 420594   epsilon: 0.36522190001000177    steps: 199    lr: 6.400000000000001e-06     evaluation reward: 5.47\n",
      "episode: 1924   score: 3.0   memory length: 420863   epsilon: 0.3646892800099984    steps: 269    lr: 6.400000000000001e-06     evaluation reward: 5.48\n",
      "episode: 1925   score: 5.0   memory length: 421190   epsilon: 0.3640418200099943    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 5.48\n",
      "episode: 1926   score: 2.0   memory length: 421407   epsilon: 0.3636121600099916    steps: 217    lr: 6.400000000000001e-06     evaluation reward: 5.44\n",
      "episode: 1927   score: 6.0   memory length: 421740   epsilon: 0.3629528200099874    steps: 333    lr: 6.400000000000001e-06     evaluation reward: 5.45\n",
      "episode: 1928   score: 4.0   memory length: 422016   epsilon: 0.36240634000998395    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 5.45\n",
      "episode: 1929   score: 6.0   memory length: 422376   epsilon: 0.36169354000997944    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 5.45\n",
      "episode: 1930   score: 3.0   memory length: 422588   epsilon: 0.3612737800099768    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 5.45\n",
      "episode: 1931   score: 4.0   memory length: 422844   epsilon: 0.3607669000099736    steps: 256    lr: 6.400000000000001e-06     evaluation reward: 5.42\n",
      "episode: 1932   score: 5.0   memory length: 423126   epsilon: 0.36020854000997005    steps: 282    lr: 6.400000000000001e-06     evaluation reward: 5.41\n",
      "episode: 1933   score: 4.0   memory length: 423402   epsilon: 0.3596620600099666    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 5.41\n",
      "episode: 1934   score: 4.0   memory length: 423678   epsilon: 0.35911558000996313    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 5.41\n",
      "episode: 1935   score: 4.0   memory length: 423954   epsilon: 0.3585691000099597    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 5.4\n",
      "episode: 1936   score: 5.0   memory length: 424260   epsilon: 0.35796322000995584    steps: 306    lr: 6.400000000000001e-06     evaluation reward: 5.4\n",
      "episode: 1937   score: 6.0   memory length: 424643   epsilon: 0.35720488000995104    steps: 383    lr: 6.400000000000001e-06     evaluation reward: 5.41\n",
      "episode: 1938   score: 8.0   memory length: 425061   epsilon: 0.3563772400099458    steps: 418    lr: 6.400000000000001e-06     evaluation reward: 5.45\n",
      "episode: 1939   score: 3.0   memory length: 425290   epsilon: 0.35592382000994294    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 5.45\n",
      "episode: 1940   score: 7.0   memory length: 425665   epsilon: 0.35518132000993824    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 5.5\n",
      "episode: 1941   score: 3.0   memory length: 425898   epsilon: 0.3547199800099353    steps: 233    lr: 6.400000000000001e-06     evaluation reward: 5.46\n",
      "episode: 1942   score: 4.0   memory length: 426163   epsilon: 0.354195280009932    steps: 265    lr: 6.400000000000001e-06     evaluation reward: 5.46\n",
      "episode: 1943   score: 8.0   memory length: 426601   epsilon: 0.3533280400099265    steps: 438    lr: 6.400000000000001e-06     evaluation reward: 5.49\n",
      "episode: 1944   score: 6.0   memory length: 426941   epsilon: 0.35265484000992225    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 5.52\n",
      "episode: 1945   score: 3.0   memory length: 427191   epsilon: 0.3521598400099191    steps: 250    lr: 6.400000000000001e-06     evaluation reward: 5.52\n",
      "episode: 1946   score: 4.0   memory length: 427469   epsilon: 0.35160940000991564    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.51\n",
      "episode: 1947   score: 9.0   memory length: 427896   epsilon: 0.3507639400099103    steps: 427    lr: 6.400000000000001e-06     evaluation reward: 5.54\n",
      "episode: 1948   score: 4.0   memory length: 428173   epsilon: 0.3502154800099068    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 5.55\n",
      "episode: 1949   score: 3.0   memory length: 428402   epsilon: 0.34976206000990395    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 5.54\n",
      "episode: 1950   score: 4.0   memory length: 428666   epsilon: 0.34923934000990065    steps: 264    lr: 6.400000000000001e-06     evaluation reward: 5.51\n",
      "episode: 1951   score: 3.0   memory length: 428932   epsilon: 0.3487126600098973    steps: 266    lr: 6.400000000000001e-06     evaluation reward: 5.48\n",
      "episode: 1952   score: 6.0   memory length: 429277   epsilon: 0.348029560009893    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 5.47\n",
      "episode: 1953   score: 4.0   memory length: 429556   epsilon: 0.3474771400098895    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 5.48\n",
      "episode: 1954   score: 5.0   memory length: 429885   epsilon: 0.3468257200098854    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 5.48\n",
      "episode: 1955   score: 7.0   memory length: 430279   epsilon: 0.34604560000988044    steps: 394    lr: 6.400000000000001e-06     evaluation reward: 5.5\n",
      "episode: 1956   score: 9.0   memory length: 430610   epsilon: 0.3453902200098763    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 5.51\n",
      "episode: 1957   score: 3.0   memory length: 430821   epsilon: 0.34497244000987365    steps: 211    lr: 6.400000000000001e-06     evaluation reward: 5.47\n",
      "episode: 1958   score: 5.0   memory length: 431110   epsilon: 0.34440022000987003    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 5.47\n",
      "episode: 1959   score: 3.0   memory length: 431339   epsilon: 0.34394680000986716    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 5.45\n",
      "episode: 1960   score: 6.0   memory length: 431687   epsilon: 0.3432577600098628    steps: 348    lr: 6.400000000000001e-06     evaluation reward: 5.47\n",
      "episode: 1961   score: 5.0   memory length: 432013   epsilon: 0.3426122800098587    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 5.45\n",
      "episode: 1962   score: 6.0   memory length: 432349   epsilon: 0.3419470000098545    steps: 336    lr: 6.400000000000001e-06     evaluation reward: 5.47\n",
      "episode: 1963   score: 6.0   memory length: 432707   epsilon: 0.34123816000985    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 5.48\n",
      "episode: 1964   score: 3.0   memory length: 432919   epsilon: 0.34081840000984737    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 5.47\n",
      "episode: 1965   score: 5.0   memory length: 433214   epsilon: 0.34023430000984367    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 5.43\n",
      "episode: 1966   score: 4.0   memory length: 433513   epsilon: 0.3396422800098399    steps: 299    lr: 6.400000000000001e-06     evaluation reward: 5.44\n",
      "episode: 1967   score: 9.0   memory length: 433891   epsilon: 0.3388938400098352    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 5.46\n",
      "episode: 1968   score: 4.0   memory length: 434169   epsilon: 0.3383434000098317    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.47\n",
      "episode: 1969   score: 6.0   memory length: 434527   epsilon: 0.3376345600098272    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 5.49\n",
      "episode: 1970   score: 3.0   memory length: 434779   epsilon: 0.33713560000982407    steps: 252    lr: 6.400000000000001e-06     evaluation reward: 5.46\n",
      "episode: 1971   score: 5.0   memory length: 435076   epsilon: 0.33654754000982035    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 5.43\n",
      "episode: 1972   score: 4.0   memory length: 435352   epsilon: 0.3360010600098169    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 5.42\n",
      "episode: 1973   score: 4.0   memory length: 435648   epsilon: 0.3354149800098132    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 5.36\n",
      "episode: 1974   score: 2.0   memory length: 435830   epsilon: 0.3350546200098109    steps: 182    lr: 6.400000000000001e-06     evaluation reward: 5.34\n",
      "episode: 1975   score: 6.0   memory length: 436135   epsilon: 0.3344507200098071    steps: 305    lr: 6.400000000000001e-06     evaluation reward: 5.36\n",
      "episode: 1976   score: 6.0   memory length: 436485   epsilon: 0.3337577200098027    steps: 350    lr: 6.400000000000001e-06     evaluation reward: 5.38\n",
      "episode: 1977   score: 5.0   memory length: 436795   epsilon: 0.3331439200097988    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 5.38\n",
      "episode: 1978   score: 6.0   memory length: 437110   epsilon: 0.33252022000979486    steps: 315    lr: 6.400000000000001e-06     evaluation reward: 5.4\n",
      "episode: 1979   score: 6.0   memory length: 437463   epsilon: 0.33182128000979044    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 5.32\n",
      "episode: 1980   score: 5.0   memory length: 437743   epsilon: 0.33126688000978693    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 5.33\n",
      "episode: 1981   score: 4.0   memory length: 438019   epsilon: 0.3307204000097835    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 5.31\n",
      "episode: 1982   score: 6.0   memory length: 438397   epsilon: 0.32997196000977874    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 5.3\n",
      "episode: 1983   score: 3.0   memory length: 438611   epsilon: 0.32954824000977606    steps: 214    lr: 6.400000000000001e-06     evaluation reward: 5.21\n",
      "episode: 1984   score: 4.0   memory length: 438928   epsilon: 0.3289205800097721    steps: 317    lr: 6.400000000000001e-06     evaluation reward: 5.2\n",
      "episode: 1985   score: 5.0   memory length: 439246   epsilon: 0.3282909400097681    steps: 318    lr: 6.400000000000001e-06     evaluation reward: 5.19\n",
      "episode: 1986   score: 7.0   memory length: 439674   epsilon: 0.32744350000976274    steps: 428    lr: 6.400000000000001e-06     evaluation reward: 5.19\n",
      "episode: 1987   score: 6.0   memory length: 440030   epsilon: 0.3267386200097583    steps: 356    lr: 6.400000000000001e-06     evaluation reward: 5.19\n",
      "episode: 1988   score: 3.0   memory length: 440242   epsilon: 0.32631886000975563    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 5.14\n",
      "episode: 1989   score: 3.0   memory length: 440454   epsilon: 0.325899100009753    steps: 212    lr: 6.400000000000001e-06     evaluation reward: 5.1\n",
      "episode: 1990   score: 10.0   memory length: 440912   epsilon: 0.32499226000974724    steps: 458    lr: 6.400000000000001e-06     evaluation reward: 5.14\n",
      "episode: 1991   score: 3.0   memory length: 441126   epsilon: 0.32456854000974455    steps: 214    lr: 6.400000000000001e-06     evaluation reward: 5.13\n",
      "episode: 1992   score: 4.0   memory length: 441425   epsilon: 0.3239765200097408    steps: 299    lr: 6.400000000000001e-06     evaluation reward: 5.11\n",
      "episode: 1993   score: 6.0   memory length: 441799   epsilon: 0.3232360000097361    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 5.14\n",
      "episode: 1994   score: 4.0   memory length: 442075   epsilon: 0.32268952000973267    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 5.15\n",
      "episode: 1995   score: 5.0   memory length: 442385   epsilon: 0.3220757200097288    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 5.12\n",
      "episode: 1996   score: 3.0   memory length: 442599   epsilon: 0.3216520000097261    steps: 214    lr: 6.400000000000001e-06     evaluation reward: 5.11\n",
      "episode: 1997   score: 5.0   memory length: 442925   epsilon: 0.321006520009722    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 5.09\n",
      "episode: 1998   score: 4.0   memory length: 443188   epsilon: 0.3204857800097187    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 5.09\n",
      "episode: 1999   score: 4.0   memory length: 443445   epsilon: 0.3199769200097155    steps: 257    lr: 6.400000000000001e-06     evaluation reward: 5.1\n",
      "episode: 2000   score: 3.0   memory length: 443672   epsilon: 0.31952746000971266    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2001   score: 14.0   memory length: 444280   epsilon: 0.31832362000970504    steps: 608    lr: 6.400000000000001e-06     evaluation reward: 4.98\n",
      "episode: 2002   score: 4.0   memory length: 444558   epsilon: 0.31777318000970156    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 2003   score: 9.0   memory length: 445010   epsilon: 0.3168782200096959    steps: 452    lr: 6.400000000000001e-06     evaluation reward: 5.01\n",
      "episode: 2004   score: 5.0   memory length: 445332   epsilon: 0.31624066000969187    steps: 322    lr: 6.400000000000001e-06     evaluation reward: 5.02\n",
      "episode: 2005   score: 4.0   memory length: 445606   epsilon: 0.31569814000968843    steps: 274    lr: 6.400000000000001e-06     evaluation reward: 4.98\n",
      "episode: 2006   score: 7.0   memory length: 445957   epsilon: 0.31500316000968404    steps: 351    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 2007   score: 4.0   memory length: 446217   epsilon: 0.3144883600096808    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 2008   score: 5.0   memory length: 446529   epsilon: 0.31387060000967687    steps: 312    lr: 6.400000000000001e-06     evaluation reward: 4.94\n",
      "episode: 2009   score: 4.0   memory length: 446825   epsilon: 0.31328452000967316    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2010   score: 4.0   memory length: 447106   epsilon: 0.31272814000966964    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2011   score: 5.0   memory length: 447415   epsilon: 0.31211632000966577    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2012   score: 5.0   memory length: 447727   epsilon: 0.31149856000966186    steps: 312    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 2013   score: 6.0   memory length: 448048   epsilon: 0.31086298000965784    steps: 321    lr: 6.400000000000001e-06     evaluation reward: 4.9\n",
      "episode: 2014   score: 5.0   memory length: 448347   epsilon: 0.3102709600096541    steps: 299    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 2015   score: 4.0   memory length: 448627   epsilon: 0.3097165600096506    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 4.91\n",
      "episode: 2016   score: 4.0   memory length: 448924   epsilon: 0.30912850000964687    steps: 297    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 2017   score: 5.0   memory length: 449249   epsilon: 0.3084850000096428    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 4.88\n",
      "episode: 2018   score: 4.0   memory length: 449544   epsilon: 0.3079009000096391    steps: 295    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 2019   score: 6.0   memory length: 449911   epsilon: 0.3071742400096345    steps: 367    lr: 6.400000000000001e-06     evaluation reward: 4.89\n",
      "episode: 2020   score: 6.0   memory length: 450238   epsilon: 0.3065267800096304    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 4.92\n",
      "episode: 2021   score: 5.0   memory length: 450545   epsilon: 0.30591892000962656    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 4.93\n",
      "episode: 2022   score: 9.0   memory length: 450942   epsilon: 0.3051328600096216    steps: 397    lr: 6.400000000000001e-06     evaluation reward: 4.96\n",
      "episode: 2023   score: 3.0   memory length: 451156   epsilon: 0.3047091400096189    steps: 214    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 2024   score: 4.0   memory length: 451416   epsilon: 0.30419434000961565    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 4.98\n",
      "episode: 2025   score: 4.0   memory length: 451695   epsilon: 0.30364192000961215    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 4.97\n",
      "episode: 2026   score: 6.0   memory length: 452048   epsilon: 0.30294298000960773    steps: 353    lr: 6.400000000000001e-06     evaluation reward: 5.01\n",
      "episode: 2027   score: 7.0   memory length: 452423   epsilon: 0.30220048000960303    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 5.02\n",
      "episode: 2028   score: 5.0   memory length: 452714   epsilon: 0.3016243000095994    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 5.03\n",
      "episode: 2029   score: 4.0   memory length: 452972   epsilon: 0.30111346000959616    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 5.01\n",
      "episode: 2030   score: 4.0   memory length: 453253   epsilon: 0.30055708000959264    steps: 281    lr: 6.400000000000001e-06     evaluation reward: 5.02\n",
      "episode: 2031   score: 4.0   memory length: 453516   epsilon: 0.30003634000958934    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 5.02\n",
      "episode: 2032   score: 6.0   memory length: 453847   epsilon: 0.2993809600095852    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 5.03\n",
      "episode: 2033   score: 6.0   memory length: 454222   epsilon: 0.2986384600095805    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 5.05\n",
      "episode: 2034   score: 5.0   memory length: 454533   epsilon: 0.2980226800095766    steps: 311    lr: 6.400000000000001e-06     evaluation reward: 5.06\n",
      "episode: 2035   score: 7.0   memory length: 454922   epsilon: 0.29725246000957173    steps: 389    lr: 6.400000000000001e-06     evaluation reward: 5.09\n",
      "episode: 2036   score: 8.0   memory length: 455380   epsilon: 0.296345620009566    steps: 458    lr: 6.400000000000001e-06     evaluation reward: 5.12\n",
      "episode: 2037   score: 10.0   memory length: 455756   epsilon: 0.2956011400095613    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 5.16\n",
      "episode: 2038   score: 4.0   memory length: 456019   epsilon: 0.295080400009558    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 5.12\n",
      "episode: 2039   score: 8.0   memory length: 456446   epsilon: 0.29423494000955264    steps: 427    lr: 6.400000000000001e-06     evaluation reward: 5.17\n",
      "episode: 2040   score: 4.0   memory length: 456723   epsilon: 0.29368648000954917    steps: 277    lr: 6.400000000000001e-06     evaluation reward: 5.14\n",
      "episode: 2041   score: 6.0   memory length: 457101   epsilon: 0.29293804000954443    steps: 378    lr: 6.400000000000001e-06     evaluation reward: 5.17\n",
      "episode: 2042   score: 4.0   memory length: 457362   epsilon: 0.29242126000954116    steps: 261    lr: 6.400000000000001e-06     evaluation reward: 5.17\n",
      "episode: 2043   score: 4.0   memory length: 457607   epsilon: 0.2919361600095381    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 5.13\n",
      "episode: 2044   score: 4.0   memory length: 457887   epsilon: 0.2913817600095346    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 5.11\n",
      "episode: 2045   score: 5.0   memory length: 458213   epsilon: 0.2907362800095305    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 5.13\n",
      "episode: 2046   score: 5.0   memory length: 458522   epsilon: 0.29012446000952663    steps: 309    lr: 6.400000000000001e-06     evaluation reward: 5.14\n",
      "episode: 2047   score: 3.0   memory length: 458770   epsilon: 0.2896334200095235    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 5.08\n",
      "episode: 2048   score: 5.0   memory length: 459097   epsilon: 0.2889859600095194    steps: 327    lr: 6.400000000000001e-06     evaluation reward: 5.09\n",
      "episode: 2049   score: 4.0   memory length: 459342   epsilon: 0.28850086000951636    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 5.1\n",
      "episode: 2050   score: 4.0   memory length: 459620   epsilon: 0.2879504200095129    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.1\n",
      "episode: 2051   score: 3.0   memory length: 459871   epsilon: 0.28745344000950973    steps: 251    lr: 6.400000000000001e-06     evaluation reward: 5.1\n",
      "episode: 2052   score: 10.0   memory length: 460369   epsilon: 0.2864674000095035    steps: 498    lr: 6.400000000000001e-06     evaluation reward: 5.14\n",
      "episode: 2053   score: 5.0   memory length: 460676   epsilon: 0.28585954000949965    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 5.15\n",
      "episode: 2054   score: 8.0   memory length: 461008   epsilon: 0.2852021800094955    steps: 332    lr: 6.400000000000001e-06     evaluation reward: 5.18\n",
      "episode: 2055   score: 8.0   memory length: 461466   epsilon: 0.28429534000948975    steps: 458    lr: 6.400000000000001e-06     evaluation reward: 5.19\n",
      "episode: 2056   score: 6.0   memory length: 461824   epsilon: 0.28358650000948527    steps: 358    lr: 6.400000000000001e-06     evaluation reward: 5.16\n",
      "episode: 2057   score: 3.0   memory length: 462072   epsilon: 0.28309546000948216    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 5.16\n",
      "episode: 2058   score: 4.0   memory length: 462331   epsilon: 0.2825826400094789    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.15\n",
      "episode: 2059   score: 7.0   memory length: 462706   epsilon: 0.2818401400094742    steps: 375    lr: 6.400000000000001e-06     evaluation reward: 5.19\n",
      "episode: 2060   score: 4.0   memory length: 462970   epsilon: 0.2813174200094709    steps: 264    lr: 6.400000000000001e-06     evaluation reward: 5.17\n",
      "episode: 2061   score: 14.0   memory length: 463424   epsilon: 0.2804185000094652    steps: 454    lr: 6.400000000000001e-06     evaluation reward: 5.26\n",
      "episode: 2062   score: 5.0   memory length: 463715   epsilon: 0.2798423200094616    steps: 291    lr: 6.400000000000001e-06     evaluation reward: 5.25\n",
      "episode: 2063   score: 6.0   memory length: 464036   epsilon: 0.27920674000945755    steps: 321    lr: 6.400000000000001e-06     evaluation reward: 5.25\n",
      "episode: 2064   score: 5.0   memory length: 464381   epsilon: 0.27852364000945323    steps: 345    lr: 6.400000000000001e-06     evaluation reward: 5.27\n",
      "episode: 2065   score: 7.0   memory length: 464773   epsilon: 0.2777474800094483    steps: 392    lr: 6.400000000000001e-06     evaluation reward: 5.29\n",
      "episode: 2066   score: 5.0   memory length: 465073   epsilon: 0.27715348000944456    steps: 300    lr: 6.400000000000001e-06     evaluation reward: 5.3\n",
      "episode: 2067   score: 7.0   memory length: 465443   epsilon: 0.27642088000943993    steps: 370    lr: 6.400000000000001e-06     evaluation reward: 5.28\n",
      "episode: 2068   score: 4.0   memory length: 465723   epsilon: 0.2758664800094364    steps: 280    lr: 6.400000000000001e-06     evaluation reward: 5.28\n",
      "episode: 2069   score: 4.0   memory length: 465968   epsilon: 0.27538138000943335    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 5.26\n",
      "episode: 2070   score: 4.0   memory length: 466246   epsilon: 0.27483094000942987    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.27\n",
      "episode: 2071   score: 4.0   memory length: 466522   epsilon: 0.2742844600094264    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 5.26\n",
      "episode: 2072   score: 4.0   memory length: 466800   epsilon: 0.27373402000942293    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.26\n",
      "episode: 2073   score: 4.0   memory length: 467076   epsilon: 0.27318754000941947    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 5.26\n",
      "episode: 2074   score: 7.0   memory length: 467489   epsilon: 0.2723698000094143    steps: 413    lr: 6.400000000000001e-06     evaluation reward: 5.31\n",
      "episode: 2075   score: 8.0   memory length: 467967   epsilon: 0.2714233600094083    steps: 478    lr: 6.400000000000001e-06     evaluation reward: 5.33\n",
      "episode: 2076   score: 6.0   memory length: 468305   epsilon: 0.2707541200094041    steps: 338    lr: 6.400000000000001e-06     evaluation reward: 5.33\n",
      "episode: 2077   score: 4.0   memory length: 468547   epsilon: 0.27027496000940104    steps: 242    lr: 6.400000000000001e-06     evaluation reward: 5.32\n",
      "episode: 2078   score: 5.0   memory length: 468879   epsilon: 0.2696176000093969    steps: 332    lr: 6.400000000000001e-06     evaluation reward: 5.31\n",
      "episode: 2079   score: 5.0   memory length: 469204   epsilon: 0.2689741000093928    steps: 325    lr: 6.400000000000001e-06     evaluation reward: 5.3\n",
      "episode: 2080   score: 10.0   memory length: 469581   epsilon: 0.2682276400093881    steps: 377    lr: 6.400000000000001e-06     evaluation reward: 5.35\n",
      "episode: 2081   score: 5.0   memory length: 469867   epsilon: 0.2676613600093845    steps: 286    lr: 6.400000000000001e-06     evaluation reward: 5.36\n",
      "episode: 2082   score: 8.0   memory length: 470305   epsilon: 0.266794120009379    steps: 438    lr: 6.400000000000001e-06     evaluation reward: 5.38\n",
      "episode: 2083   score: 4.0   memory length: 470565   epsilon: 0.26627932000937576    steps: 260    lr: 6.400000000000001e-06     evaluation reward: 5.39\n",
      "episode: 2084   score: 5.0   memory length: 470864   epsilon: 0.265687300009372    steps: 299    lr: 6.400000000000001e-06     evaluation reward: 5.4\n",
      "episode: 2085   score: 7.0   memory length: 471259   epsilon: 0.26490520000936707    steps: 395    lr: 6.400000000000001e-06     evaluation reward: 5.42\n",
      "episode: 2086   score: 5.0   memory length: 471570   epsilon: 0.2642894200093632    steps: 311    lr: 6.400000000000001e-06     evaluation reward: 5.4\n",
      "episode: 2087   score: 6.0   memory length: 471905   epsilon: 0.263626120009359    steps: 335    lr: 6.400000000000001e-06     evaluation reward: 5.4\n",
      "episode: 2088   score: 7.0   memory length: 472291   epsilon: 0.26286184000935414    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 5.44\n",
      "episode: 2089   score: 7.0   memory length: 472730   epsilon: 0.26199262000934864    steps: 439    lr: 6.400000000000001e-06     evaluation reward: 5.48\n",
      "episode: 2090   score: 7.0   memory length: 473061   epsilon: 0.2613372400093445    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 5.45\n",
      "episode: 2091   score: 7.0   memory length: 473441   epsilon: 0.26058484000933974    steps: 380    lr: 6.400000000000001e-06     evaluation reward: 5.49\n",
      "episode: 2092   score: 8.0   memory length: 473822   epsilon: 0.25983046000933496    steps: 381    lr: 6.400000000000001e-06     evaluation reward: 5.53\n",
      "episode: 2093   score: 3.0   memory length: 474071   epsilon: 0.25933744000933184    steps: 249    lr: 6.400000000000001e-06     evaluation reward: 5.5\n",
      "episode: 2094   score: 9.0   memory length: 474397   epsilon: 0.25869196000932776    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 5.55\n",
      "episode: 2095   score: 6.0   memory length: 474740   epsilon: 0.25801282000932346    steps: 343    lr: 6.400000000000001e-06     evaluation reward: 5.56\n",
      "episode: 2096   score: 3.0   memory length: 474954   epsilon: 0.2575891000093208    steps: 214    lr: 6.400000000000001e-06     evaluation reward: 5.56\n",
      "episode: 2097   score: 7.0   memory length: 475328   epsilon: 0.2568485800093161    steps: 374    lr: 6.400000000000001e-06     evaluation reward: 5.58\n",
      "episode: 2098   score: 9.0   memory length: 475743   epsilon: 0.2560268800093109    steps: 415    lr: 6.400000000000001e-06     evaluation reward: 5.63\n",
      "episode: 2099   score: 5.0   memory length: 476051   epsilon: 0.25541704000930704    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 5.64\n",
      "episode: 2100   score: 3.0   memory length: 476299   epsilon: 0.25492600000930393    steps: 248    lr: 6.400000000000001e-06     evaluation reward: 5.64\n",
      "episode: 2101   score: 5.0   memory length: 476609   epsilon: 0.25431220000930005    steps: 310    lr: 6.400000000000001e-06     evaluation reward: 5.55\n",
      "episode: 2102   score: 7.0   memory length: 477031   epsilon: 0.25347664000929476    steps: 422    lr: 6.400000000000001e-06     evaluation reward: 5.58\n",
      "episode: 2103   score: 6.0   memory length: 477426   epsilon: 0.2526945400092898    steps: 395    lr: 6.400000000000001e-06     evaluation reward: 5.55\n",
      "episode: 2104   score: 4.0   memory length: 477691   epsilon: 0.2521698400092865    steps: 265    lr: 6.400000000000001e-06     evaluation reward: 5.54\n",
      "episode: 2105   score: 3.0   memory length: 477920   epsilon: 0.2517164200092836    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 5.53\n",
      "episode: 2106   score: 5.0   memory length: 478246   epsilon: 0.25107094000927954    steps: 326    lr: 6.400000000000001e-06     evaluation reward: 5.51\n",
      "episode: 2107   score: 6.0   memory length: 478600   epsilon: 0.2503700200092751    steps: 354    lr: 6.400000000000001e-06     evaluation reward: 5.53\n",
      "episode: 2108   score: 7.0   memory length: 478986   epsilon: 0.24960574000927027    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 5.55\n",
      "episode: 2109   score: 5.0   memory length: 479314   epsilon: 0.24895630000926616    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 5.56\n",
      "episode: 2110   score: 6.0   memory length: 479673   epsilon: 0.24824548000926167    steps: 359    lr: 6.400000000000001e-06     evaluation reward: 5.58\n",
      "episode: 2111   score: 6.0   memory length: 480013   epsilon: 0.2475722800092574    steps: 340    lr: 6.400000000000001e-06     evaluation reward: 5.59\n",
      "episode: 2112   score: 4.0   memory length: 480289   epsilon: 0.24702580000925395    steps: 276    lr: 6.400000000000001e-06     evaluation reward: 5.58\n",
      "episode: 2113   score: 7.0   memory length: 480677   epsilon: 0.2462575600092491    steps: 388    lr: 6.400000000000001e-06     evaluation reward: 5.59\n",
      "episode: 2114   score: 5.0   memory length: 481001   epsilon: 0.24561604000924503    steps: 324    lr: 6.400000000000001e-06     evaluation reward: 5.59\n",
      "episode: 2115   score: 4.0   memory length: 481246   epsilon: 0.24513094000924196    steps: 245    lr: 6.400000000000001e-06     evaluation reward: 5.59\n",
      "episode: 2116   score: 11.0   memory length: 481700   epsilon: 0.24423202000923627    steps: 454    lr: 6.400000000000001e-06     evaluation reward: 5.66\n",
      "episode: 2117   score: 5.0   memory length: 482046   epsilon: 0.24354694000923194    steps: 346    lr: 6.400000000000001e-06     evaluation reward: 5.66\n",
      "episode: 2118   score: 6.0   memory length: 482406   epsilon: 0.24283414000922743    steps: 360    lr: 6.400000000000001e-06     evaluation reward: 5.68\n",
      "episode: 2119   score: 10.0   memory length: 482876   epsilon: 0.24190354000922154    steps: 470    lr: 6.400000000000001e-06     evaluation reward: 5.72\n",
      "episode: 2120   score: 4.0   memory length: 483150   epsilon: 0.2413610200092181    steps: 274    lr: 6.400000000000001e-06     evaluation reward: 5.7\n",
      "episode: 2121   score: 5.0   memory length: 483451   epsilon: 0.24076504000921434    steps: 301    lr: 6.400000000000001e-06     evaluation reward: 5.7\n",
      "episode: 2122   score: 7.0   memory length: 483808   epsilon: 0.24005818000920986    steps: 357    lr: 6.400000000000001e-06     evaluation reward: 5.68\n",
      "episode: 2123   score: 4.0   memory length: 484071   epsilon: 0.23953744000920657    steps: 263    lr: 6.400000000000001e-06     evaluation reward: 5.69\n",
      "episode: 2124   score: 4.0   memory length: 484330   epsilon: 0.23902462000920333    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.69\n",
      "episode: 2125   score: 5.0   memory length: 484608   epsilon: 0.23847418000919984    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.7\n",
      "episode: 2126   score: 4.0   memory length: 484925   epsilon: 0.23784652000919587    steps: 317    lr: 6.400000000000001e-06     evaluation reward: 5.68\n",
      "episode: 2127   score: 5.0   memory length: 485247   epsilon: 0.23720896000919184    steps: 322    lr: 6.400000000000001e-06     evaluation reward: 5.66\n",
      "episode: 2128   score: 6.0   memory length: 485623   epsilon: 0.23646448000918713    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 5.67\n",
      "episode: 2129   score: 3.0   memory length: 485857   epsilon: 0.2360011600091842    steps: 234    lr: 6.400000000000001e-06     evaluation reward: 5.66\n",
      "episode: 2130   score: 8.0   memory length: 486314   epsilon: 0.23509630000917847    steps: 457    lr: 6.400000000000001e-06     evaluation reward: 5.7\n",
      "episode: 2131   score: 4.0   memory length: 486593   epsilon: 0.23454388000917498    steps: 279    lr: 6.400000000000001e-06     evaluation reward: 5.7\n",
      "episode: 2132   score: 3.0   memory length: 486821   epsilon: 0.23409244000917212    steps: 228    lr: 6.400000000000001e-06     evaluation reward: 5.67\n",
      "episode: 2133   score: 3.0   memory length: 487048   epsilon: 0.23364298000916928    steps: 227    lr: 6.400000000000001e-06     evaluation reward: 5.64\n",
      "episode: 2134   score: 4.0   memory length: 487306   epsilon: 0.23313214000916604    steps: 258    lr: 6.400000000000001e-06     evaluation reward: 5.63\n",
      "episode: 2135   score: 5.0   memory length: 487637   epsilon: 0.2324767600091619    steps: 331    lr: 6.400000000000001e-06     evaluation reward: 5.61\n",
      "episode: 2136   score: 4.0   memory length: 487915   epsilon: 0.23192632000915842    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.57\n",
      "episode: 2137   score: 8.0   memory length: 488367   epsilon: 0.23103136000915275    steps: 452    lr: 6.400000000000001e-06     evaluation reward: 5.55\n",
      "episode: 2138   score: 7.0   memory length: 488762   epsilon: 0.2302492600091478    steps: 395    lr: 6.400000000000001e-06     evaluation reward: 5.58\n",
      "episode: 2139   score: 9.0   memory length: 489090   epsilon: 0.2295998200091437    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 5.59\n",
      "episode: 2140   score: 5.0   memory length: 489397   epsilon: 0.22899196000913985    steps: 307    lr: 6.400000000000001e-06     evaluation reward: 5.6\n",
      "episode: 2141   score: 3.0   memory length: 489626   epsilon: 0.22853854000913698    steps: 229    lr: 6.400000000000001e-06     evaluation reward: 5.57\n",
      "episode: 2142   score: 7.0   memory length: 490029   epsilon: 0.22774060000913193    steps: 403    lr: 6.400000000000001e-06     evaluation reward: 5.6\n",
      "episode: 2143   score: 12.0   memory length: 490600   epsilon: 0.22661002000912478    steps: 571    lr: 6.400000000000001e-06     evaluation reward: 5.68\n",
      "episode: 2144   score: 5.0   memory length: 490928   epsilon: 0.22596058000912067    steps: 328    lr: 6.400000000000001e-06     evaluation reward: 5.69\n",
      "episode: 2145   score: 9.0   memory length: 491363   epsilon: 0.22509928000911522    steps: 435    lr: 6.400000000000001e-06     evaluation reward: 5.73\n",
      "episode: 2146   score: 9.0   memory length: 491802   epsilon: 0.22423006000910972    steps: 439    lr: 6.400000000000001e-06     evaluation reward: 5.77\n",
      "episode: 2147   score: 5.0   memory length: 492143   epsilon: 0.22355488000910545    steps: 341    lr: 6.400000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2148   score: 6.0   memory length: 492516   epsilon: 0.22281634000910078    steps: 373    lr: 6.400000000000001e-06     evaluation reward: 5.8\n",
      "episode: 2149   score: 8.0   memory length: 492902   epsilon: 0.22205206000909594    steps: 386    lr: 6.400000000000001e-06     evaluation reward: 5.84\n",
      "episode: 2150   score: 4.0   memory length: 493184   epsilon: 0.2214937000090924    steps: 282    lr: 6.400000000000001e-06     evaluation reward: 5.84\n",
      "episode: 2151   score: 4.0   memory length: 493451   epsilon: 0.22096504000908906    steps: 267    lr: 6.400000000000001e-06     evaluation reward: 5.85\n",
      "episode: 2152   score: 4.0   memory length: 493729   epsilon: 0.22041460000908558    steps: 278    lr: 6.400000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2153   score: 5.0   memory length: 494022   epsilon: 0.2198344600090819    steps: 293    lr: 6.400000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2154   score: 7.0   memory length: 494462   epsilon: 0.2189632600090764    steps: 440    lr: 6.400000000000001e-06     evaluation reward: 5.78\n",
      "episode: 2155   score: 9.0   memory length: 494935   epsilon: 0.21802672000907047    steps: 473    lr: 6.400000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2156   score: 7.0   memory length: 495311   epsilon: 0.21728224000906576    steps: 376    lr: 6.400000000000001e-06     evaluation reward: 5.8\n",
      "episode: 2157   score: 7.0   memory length: 495676   epsilon: 0.2165595400090612    steps: 365    lr: 6.400000000000001e-06     evaluation reward: 5.84\n",
      "episode: 2158   score: 5.0   memory length: 496005   epsilon: 0.21590812000905707    steps: 329    lr: 6.400000000000001e-06     evaluation reward: 5.85\n",
      "episode: 2159   score: 5.0   memory length: 496319   epsilon: 0.21528640000905314    steps: 314    lr: 6.400000000000001e-06     evaluation reward: 5.83\n",
      "episode: 2160   score: 3.0   memory length: 496528   epsilon: 0.21487258000905052    steps: 209    lr: 6.400000000000001e-06     evaluation reward: 5.82\n",
      "episode: 2161   score: 5.0   memory length: 496817   epsilon: 0.2143003600090469    steps: 289    lr: 6.400000000000001e-06     evaluation reward: 5.73\n",
      "episode: 2162   score: 6.0   memory length: 497130   epsilon: 0.21368062000904298    steps: 313    lr: 6.400000000000001e-06     evaluation reward: 5.74\n",
      "episode: 2163   score: 4.0   memory length: 497389   epsilon: 0.21316780000903973    steps: 259    lr: 6.400000000000001e-06     evaluation reward: 5.72\n",
      "episode: 2164   score: 6.0   memory length: 497784   epsilon: 0.21238570000903478    steps: 395    lr: 6.400000000000001e-06     evaluation reward: 5.73\n",
      "episode: 2165   score: 9.0   memory length: 498232   epsilon: 0.21149866000902917    steps: 448    lr: 6.400000000000001e-06     evaluation reward: 5.75\n",
      "episode: 2166   score: 5.0   memory length: 498540   epsilon: 0.2108888200090253    steps: 308    lr: 6.400000000000001e-06     evaluation reward: 5.75\n",
      "episode: 2167   score: 9.0   memory length: 498952   epsilon: 0.21007306000902015    steps: 412    lr: 6.400000000000001e-06     evaluation reward: 5.77\n",
      "episode: 2168   score: 5.0   memory length: 499248   epsilon: 0.20948698000901644    steps: 296    lr: 6.400000000000001e-06     evaluation reward: 5.78\n",
      "episode: 2169   score: 7.0   memory length: 499633   epsilon: 0.20872468000901162    steps: 385    lr: 6.400000000000001e-06     evaluation reward: 5.81\n",
      "episode: 2170   score: 6.0   memory length: 499963   epsilon: 0.2080712800090075    steps: 330    lr: 6.400000000000001e-06     evaluation reward: 5.83\n",
      "episode: 2171   score: 7.0   memory length: 500344   epsilon: 0.2073169000090027    steps: 381    lr: 2.560000000000001e-06     evaluation reward: 5.86\n",
      "episode: 2172   score: 4.0   memory length: 500587   epsilon: 0.20683576000899967    steps: 243    lr: 2.560000000000001e-06     evaluation reward: 5.86\n",
      "episode: 2173   score: 5.0   memory length: 500883   epsilon: 0.20624968000899596    steps: 296    lr: 2.560000000000001e-06     evaluation reward: 5.87\n",
      "episode: 2174   score: 5.0   memory length: 501198   epsilon: 0.20562598000899202    steps: 315    lr: 2.560000000000001e-06     evaluation reward: 5.85\n",
      "episode: 2175   score: 4.0   memory length: 501458   epsilon: 0.20511118000898876    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 2176   score: 7.0   memory length: 501861   epsilon: 0.2043132400089837    steps: 403    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 2177   score: 6.0   memory length: 502218   epsilon: 0.20360638000897924    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 5.84\n",
      "episode: 2178   score: 6.0   memory length: 502572   epsilon: 0.2029054600089748    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 5.85\n",
      "episode: 2179   score: 5.0   memory length: 502843   epsilon: 0.2023688800089714    steps: 271    lr: 2.560000000000001e-06     evaluation reward: 5.85\n",
      "episode: 2180   score: 9.0   memory length: 503311   epsilon: 0.20144224000896555    steps: 468    lr: 2.560000000000001e-06     evaluation reward: 5.84\n",
      "episode: 2181   score: 5.0   memory length: 503605   epsilon: 0.20086012000896186    steps: 294    lr: 2.560000000000001e-06     evaluation reward: 5.84\n",
      "episode: 2182   score: 5.0   memory length: 503949   epsilon: 0.20017900000895755    steps: 344    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 2183   score: 3.0   memory length: 504182   epsilon: 0.19971766000895463    steps: 233    lr: 2.560000000000001e-06     evaluation reward: 5.8\n",
      "episode: 2184   score: 5.0   memory length: 504487   epsilon: 0.1991137600089508    steps: 305    lr: 2.560000000000001e-06     evaluation reward: 5.8\n",
      "episode: 2185   score: 4.0   memory length: 504764   epsilon: 0.19856530000894734    steps: 277    lr: 2.560000000000001e-06     evaluation reward: 5.77\n",
      "episode: 2186   score: 6.0   memory length: 505118   epsilon: 0.1978643800089429    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 5.78\n",
      "episode: 2187   score: 6.0   memory length: 505495   epsilon: 0.19711792000893819    steps: 377    lr: 2.560000000000001e-06     evaluation reward: 5.78\n",
      "episode: 2188   score: 6.0   memory length: 505870   epsilon: 0.1963754200089335    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 5.77\n",
      "episode: 2189   score: 5.0   memory length: 506180   epsilon: 0.1957616200089296    steps: 310    lr: 2.560000000000001e-06     evaluation reward: 5.75\n",
      "episode: 2190   score: 4.0   memory length: 506458   epsilon: 0.19521118000892612    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 5.72\n",
      "episode: 2191   score: 6.0   memory length: 506796   epsilon: 0.1945419400089219    steps: 338    lr: 2.560000000000001e-06     evaluation reward: 5.71\n",
      "episode: 2192   score: 8.0   memory length: 507221   epsilon: 0.19370044000891656    steps: 425    lr: 2.560000000000001e-06     evaluation reward: 5.71\n",
      "episode: 2193   score: 4.0   memory length: 507498   epsilon: 0.1931519800089131    steps: 277    lr: 2.560000000000001e-06     evaluation reward: 5.72\n",
      "episode: 2194   score: 4.0   memory length: 507774   epsilon: 0.19260550000890964    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 5.67\n",
      "episode: 2195   score: 6.0   memory length: 508104   epsilon: 0.1919521000089055    steps: 330    lr: 2.560000000000001e-06     evaluation reward: 5.67\n",
      "episode: 2196   score: 3.0   memory length: 508315   epsilon: 0.19153432000890286    steps: 211    lr: 2.560000000000001e-06     evaluation reward: 5.67\n",
      "episode: 2197   score: 8.0   memory length: 508750   epsilon: 0.1906730200088974    steps: 435    lr: 2.560000000000001e-06     evaluation reward: 5.68\n",
      "episode: 2198   score: 9.0   memory length: 509079   epsilon: 0.1900216000088933    steps: 329    lr: 2.560000000000001e-06     evaluation reward: 5.68\n",
      "episode: 2199   score: 5.0   memory length: 509388   epsilon: 0.18940978000888942    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 5.68\n",
      "episode: 2200   score: 3.0   memory length: 509600   epsilon: 0.18899002000888676    steps: 212    lr: 2.560000000000001e-06     evaluation reward: 5.68\n",
      "episode: 2201   score: 6.0   memory length: 509941   epsilon: 0.1883148400088825    steps: 341    lr: 2.560000000000001e-06     evaluation reward: 5.69\n",
      "episode: 2202   score: 2.0   memory length: 510142   epsilon: 0.18791686000887997    steps: 201    lr: 2.560000000000001e-06     evaluation reward: 5.64\n",
      "episode: 2203   score: 5.0   memory length: 510451   epsilon: 0.1873050400088761    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 5.63\n",
      "episode: 2204   score: 6.0   memory length: 510828   epsilon: 0.18655858000887138    steps: 377    lr: 2.560000000000001e-06     evaluation reward: 5.65\n",
      "episode: 2205   score: 5.0   memory length: 511154   epsilon: 0.1859131000088673    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 5.67\n",
      "episode: 2206   score: 6.0   memory length: 511509   epsilon: 0.18521020000886285    steps: 355    lr: 2.560000000000001e-06     evaluation reward: 5.68\n",
      "episode: 2207   score: 10.0   memory length: 511918   epsilon: 0.18440038000885772    steps: 409    lr: 2.560000000000001e-06     evaluation reward: 5.72\n",
      "episode: 2208   score: 4.0   memory length: 512178   epsilon: 0.18388558000885447    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 5.69\n",
      "episode: 2209   score: 5.0   memory length: 512482   epsilon: 0.18328366000885066    steps: 304    lr: 2.560000000000001e-06     evaluation reward: 5.69\n",
      "episode: 2210   score: 5.0   memory length: 512774   epsilon: 0.182705500008847    steps: 292    lr: 2.560000000000001e-06     evaluation reward: 5.68\n",
      "episode: 2211   score: 4.0   memory length: 513052   epsilon: 0.18215506000884352    steps: 278    lr: 2.560000000000001e-06     evaluation reward: 5.66\n",
      "episode: 2212   score: 4.0   memory length: 513349   epsilon: 0.1815670000088398    steps: 297    lr: 2.560000000000001e-06     evaluation reward: 5.66\n",
      "episode: 2213   score: 6.0   memory length: 513705   epsilon: 0.18086212000883534    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 5.65\n",
      "episode: 2214   score: 7.0   memory length: 514089   epsilon: 0.18010180000883053    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 5.67\n",
      "episode: 2215   score: 4.0   memory length: 514353   epsilon: 0.17957908000882722    steps: 264    lr: 2.560000000000001e-06     evaluation reward: 5.67\n",
      "episode: 2216   score: 4.0   memory length: 514616   epsilon: 0.17905834000882392    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 5.6\n",
      "episode: 2217   score: 7.0   memory length: 515018   epsilon: 0.1782623800088189    steps: 402    lr: 2.560000000000001e-06     evaluation reward: 5.62\n",
      "episode: 2218   score: 4.0   memory length: 515297   epsilon: 0.1777099600088154    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 5.6\n",
      "episode: 2219   score: 5.0   memory length: 515591   epsilon: 0.1771278400088117    steps: 294    lr: 2.560000000000001e-06     evaluation reward: 5.55\n",
      "episode: 2220   score: 6.0   memory length: 515932   epsilon: 0.17645266000880744    steps: 341    lr: 2.560000000000001e-06     evaluation reward: 5.57\n",
      "episode: 2221   score: 6.0   memory length: 516291   epsilon: 0.17574184000880294    steps: 359    lr: 2.560000000000001e-06     evaluation reward: 5.58\n",
      "episode: 2222   score: 10.0   memory length: 516797   epsilon: 0.1747399600087966    steps: 506    lr: 2.560000000000001e-06     evaluation reward: 5.61\n",
      "episode: 2223   score: 3.0   memory length: 517028   epsilon: 0.1742825800087937    steps: 231    lr: 2.560000000000001e-06     evaluation reward: 5.6\n",
      "episode: 2224   score: 5.0   memory length: 517337   epsilon: 0.17367076000878984    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 5.61\n",
      "episode: 2225   score: 5.0   memory length: 517626   epsilon: 0.17309854000878622    steps: 289    lr: 2.560000000000001e-06     evaluation reward: 5.61\n",
      "episode: 2226   score: 13.0   memory length: 518094   epsilon: 0.17217190000878035    steps: 468    lr: 2.560000000000001e-06     evaluation reward: 5.7\n",
      "episode: 2227   score: 4.0   memory length: 518387   epsilon: 0.17159176000877668    steps: 293    lr: 2.560000000000001e-06     evaluation reward: 5.69\n",
      "episode: 2228   score: 6.0   memory length: 518728   epsilon: 0.1709165800087724    steps: 341    lr: 2.560000000000001e-06     evaluation reward: 5.69\n",
      "episode: 2229   score: 6.0   memory length: 519105   epsilon: 0.1701701200087677    steps: 377    lr: 2.560000000000001e-06     evaluation reward: 5.72\n",
      "episode: 2230   score: 7.0   memory length: 519455   epsilon: 0.1694771200087633    steps: 350    lr: 2.560000000000001e-06     evaluation reward: 5.71\n",
      "episode: 2231   score: 4.0   memory length: 519734   epsilon: 0.1689247000087598    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 5.71\n",
      "episode: 2232   score: 4.0   memory length: 520014   epsilon: 0.1683703000087563    steps: 280    lr: 2.560000000000001e-06     evaluation reward: 5.72\n",
      "episode: 2233   score: 5.0   memory length: 520324   epsilon: 0.16775650000875242    steps: 310    lr: 2.560000000000001e-06     evaluation reward: 5.74\n",
      "episode: 2234   score: 9.0   memory length: 520627   epsilon: 0.16715656000874862    steps: 303    lr: 2.560000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2235   score: 8.0   memory length: 521017   epsilon: 0.16638436000874374    steps: 390    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 2236   score: 7.0   memory length: 521392   epsilon: 0.16564186000873904    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 5.85\n",
      "episode: 2237   score: 4.0   memory length: 521655   epsilon: 0.16512112000873574    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 2238   score: 10.0   memory length: 522173   epsilon: 0.16409548000872926    steps: 518    lr: 2.560000000000001e-06     evaluation reward: 5.84\n",
      "episode: 2239   score: 7.0   memory length: 522543   epsilon: 0.16336288000872462    steps: 370    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 2240   score: 5.0   memory length: 522850   epsilon: 0.16275502000872077    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 2241   score: 5.0   memory length: 523160   epsilon: 0.1621412200087169    steps: 310    lr: 2.560000000000001e-06     evaluation reward: 5.84\n",
      "episode: 2242   score: 8.0   memory length: 523571   epsilon: 0.16132744000871174    steps: 411    lr: 2.560000000000001e-06     evaluation reward: 5.85\n",
      "episode: 2243   score: 9.0   memory length: 524034   epsilon: 0.16041070000870594    steps: 463    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 2244   score: 5.0   memory length: 524345   epsilon: 0.15979492000870205    steps: 311    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 2245   score: 6.0   memory length: 524722   epsilon: 0.15904846000869732    steps: 377    lr: 2.560000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2246   score: 6.0   memory length: 525041   epsilon: 0.15841684000869333    steps: 319    lr: 2.560000000000001e-06     evaluation reward: 5.76\n",
      "episode: 2247   score: 6.0   memory length: 525394   epsilon: 0.1577179000086889    steps: 353    lr: 2.560000000000001e-06     evaluation reward: 5.77\n",
      "episode: 2248   score: 6.0   memory length: 525724   epsilon: 0.15706450000868477    steps: 330    lr: 2.560000000000001e-06     evaluation reward: 5.77\n",
      "episode: 2249   score: 8.0   memory length: 526178   epsilon: 0.15616558000867908    steps: 454    lr: 2.560000000000001e-06     evaluation reward: 5.77\n",
      "episode: 2250   score: 3.0   memory length: 526407   epsilon: 0.15571216000867621    steps: 229    lr: 2.560000000000001e-06     evaluation reward: 5.76\n",
      "episode: 2251   score: 5.0   memory length: 526706   epsilon: 0.15512014000867247    steps: 299    lr: 2.560000000000001e-06     evaluation reward: 5.77\n",
      "episode: 2252   score: 3.0   memory length: 526951   epsilon: 0.1546350400086694    steps: 245    lr: 2.560000000000001e-06     evaluation reward: 5.76\n",
      "episode: 2253   score: 13.0   memory length: 527411   epsilon: 0.15372424000866364    steps: 460    lr: 2.560000000000001e-06     evaluation reward: 5.84\n",
      "episode: 2254   score: 5.0   memory length: 527735   epsilon: 0.15308272000865958    steps: 324    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 2255   score: 4.0   memory length: 527993   epsilon: 0.15257188000865635    steps: 258    lr: 2.560000000000001e-06     evaluation reward: 5.77\n",
      "episode: 2256   score: 5.0   memory length: 528319   epsilon: 0.15192640000865226    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 5.75\n",
      "episode: 2257   score: 6.0   memory length: 528651   epsilon: 0.1512690400086481    steps: 332    lr: 2.560000000000001e-06     evaluation reward: 5.74\n",
      "episode: 2258   score: 5.0   memory length: 528963   epsilon: 0.1506512800086442    steps: 312    lr: 2.560000000000001e-06     evaluation reward: 5.74\n",
      "episode: 2259   score: 5.0   memory length: 529290   epsilon: 0.1500038200086401    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 5.74\n",
      "episode: 2260   score: 9.0   memory length: 529762   epsilon: 0.14906926000863419    steps: 472    lr: 2.560000000000001e-06     evaluation reward: 5.8\n",
      "episode: 2261   score: 3.0   memory length: 529976   epsilon: 0.1486455400086315    steps: 214    lr: 2.560000000000001e-06     evaluation reward: 5.78\n",
      "episode: 2262   score: 6.0   memory length: 530352   epsilon: 0.1479010600086268    steps: 376    lr: 2.560000000000001e-06     evaluation reward: 5.78\n",
      "episode: 2263   score: 3.0   memory length: 530582   epsilon: 0.1474456600086239    steps: 230    lr: 2.560000000000001e-06     evaluation reward: 5.77\n",
      "episode: 2264   score: 3.0   memory length: 530795   epsilon: 0.14702392000862124    steps: 213    lr: 2.560000000000001e-06     evaluation reward: 5.74\n",
      "episode: 2265   score: 10.0   memory length: 531120   epsilon: 0.14638042000861717    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 5.75\n",
      "episode: 2266   score: 6.0   memory length: 531468   epsilon: 0.14569138000861281    steps: 348    lr: 2.560000000000001e-06     evaluation reward: 5.76\n",
      "episode: 2267   score: 5.0   memory length: 531775   epsilon: 0.14508352000860897    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 5.72\n",
      "episode: 2268   score: 5.0   memory length: 532097   epsilon: 0.14444596000860493    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 5.72\n",
      "episode: 2269   score: 7.0   memory length: 532457   epsilon: 0.14373316000860042    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 5.72\n",
      "episode: 2270   score: 5.0   memory length: 532783   epsilon: 0.14308768000859634    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 5.71\n",
      "episode: 2271   score: 8.0   memory length: 533222   epsilon: 0.14221846000859084    steps: 439    lr: 2.560000000000001e-06     evaluation reward: 5.72\n",
      "episode: 2272   score: 12.0   memory length: 533803   epsilon: 0.14106808000858356    steps: 581    lr: 2.560000000000001e-06     evaluation reward: 5.8\n",
      "episode: 2273   score: 4.0   memory length: 534077   epsilon: 0.14052556000858013    steps: 274    lr: 2.560000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2274   score: 5.0   memory length: 534420   epsilon: 0.13984642000857583    steps: 343    lr: 2.560000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2275   score: 5.0   memory length: 534765   epsilon: 0.1391633200085715    steps: 345    lr: 2.560000000000001e-06     evaluation reward: 5.8\n",
      "episode: 2276   score: 6.0   memory length: 535100   epsilon: 0.13850002000856731    steps: 335    lr: 2.560000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2277   score: 7.0   memory length: 535505   epsilon: 0.13769812000856224    steps: 405    lr: 2.560000000000001e-06     evaluation reward: 5.8\n",
      "episode: 2278   score: 5.0   memory length: 535812   epsilon: 0.1370902600085584    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2279   score: 7.0   memory length: 536186   epsilon: 0.1363497400085537    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 2280   score: 9.0   memory length: 536613   epsilon: 0.13550428000854836    steps: 427    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 2281   score: 3.0   memory length: 536827   epsilon: 0.13508056000854568    steps: 214    lr: 2.560000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2282   score: 5.0   memory length: 537131   epsilon: 0.13447864000854187    steps: 304    lr: 2.560000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2283   score: 5.0   memory length: 537441   epsilon: 0.133864840008538    steps: 310    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 2284   score: 2.0   memory length: 537624   epsilon: 0.1335025000085357    steps: 183    lr: 2.560000000000001e-06     evaluation reward: 5.78\n",
      "episode: 2285   score: 8.0   memory length: 538020   epsilon: 0.13271842000853074    steps: 396    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 2286   score: 5.0   memory length: 538318   epsilon: 0.132128380008527    steps: 298    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 2287   score: 6.0   memory length: 538657   epsilon: 0.13145716000852276    steps: 339    lr: 2.560000000000001e-06     evaluation reward: 5.81\n",
      "episode: 2288   score: 3.0   memory length: 538871   epsilon: 0.13103344000852007    steps: 214    lr: 2.560000000000001e-06     evaluation reward: 5.78\n",
      "episode: 2289   score: 5.0   memory length: 539181   epsilon: 0.1304196400085162    steps: 310    lr: 2.560000000000001e-06     evaluation reward: 5.78\n",
      "episode: 2290   score: 5.0   memory length: 539504   epsilon: 0.12978010000851214    steps: 323    lr: 2.560000000000001e-06     evaluation reward: 5.79\n",
      "episode: 2291   score: 7.0   memory length: 539885   epsilon: 0.12902572000850737    steps: 381    lr: 2.560000000000001e-06     evaluation reward: 5.8\n",
      "episode: 2292   score: 5.0   memory length: 540255   epsilon: 0.12829312000850274    steps: 370    lr: 2.560000000000001e-06     evaluation reward: 5.77\n",
      "episode: 2293   score: 7.0   memory length: 540699   epsilon: 0.12741400000849717    steps: 444    lr: 2.560000000000001e-06     evaluation reward: 5.8\n",
      "episode: 2294   score: 7.0   memory length: 541073   epsilon: 0.1266734800084925    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 5.83\n",
      "episode: 2295   score: 5.0   memory length: 541355   epsilon: 0.12611512000848896    steps: 282    lr: 2.560000000000001e-06     evaluation reward: 5.82\n",
      "episode: 2296   score: 6.0   memory length: 541748   epsilon: 0.12533698000848403    steps: 393    lr: 2.560000000000001e-06     evaluation reward: 5.85\n",
      "episode: 2297   score: 11.0   memory length: 542178   epsilon: 0.12448558000848226    steps: 430    lr: 2.560000000000001e-06     evaluation reward: 5.88\n",
      "episode: 2298   score: 9.0   memory length: 542500   epsilon: 0.12384802000848269    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 5.88\n",
      "episode: 2299   score: 3.0   memory length: 542714   epsilon: 0.12342430000848298    steps: 214    lr: 2.560000000000001e-06     evaluation reward: 5.86\n",
      "episode: 2300   score: 8.0   memory length: 543123   epsilon: 0.12261448000848353    steps: 409    lr: 2.560000000000001e-06     evaluation reward: 5.91\n",
      "episode: 2301   score: 4.0   memory length: 543368   epsilon: 0.12212938000848386    steps: 245    lr: 2.560000000000001e-06     evaluation reward: 5.89\n",
      "episode: 2302   score: 5.0   memory length: 543694   epsilon: 0.1214839000084843    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 5.92\n",
      "episode: 2303   score: 6.0   memory length: 544054   epsilon: 0.12077110000848479    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 5.93\n",
      "episode: 2304   score: 6.0   memory length: 544384   epsilon: 0.12011770000848523    steps: 330    lr: 2.560000000000001e-06     evaluation reward: 5.93\n",
      "episode: 2305   score: 4.0   memory length: 544660   epsilon: 0.11957122000848561    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 5.92\n",
      "episode: 2306   score: 8.0   memory length: 545102   epsilon: 0.1186960600084862    steps: 442    lr: 2.560000000000001e-06     evaluation reward: 5.94\n",
      "episode: 2307   score: 3.0   memory length: 545316   epsilon: 0.11827234000848649    steps: 214    lr: 2.560000000000001e-06     evaluation reward: 5.87\n",
      "episode: 2308   score: 5.0   memory length: 545638   epsilon: 0.11763478000848693    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 5.88\n",
      "episode: 2309   score: 8.0   memory length: 545917   epsilon: 0.1170823600084873    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 5.91\n",
      "episode: 2310   score: 4.0   memory length: 546193   epsilon: 0.11653588000848768    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 5.9\n",
      "episode: 2311   score: 5.0   memory length: 546516   epsilon: 0.11589634000848811    steps: 323    lr: 2.560000000000001e-06     evaluation reward: 5.91\n",
      "episode: 2312   score: 7.0   memory length: 546877   epsilon: 0.1151815600084886    steps: 361    lr: 2.560000000000001e-06     evaluation reward: 5.94\n",
      "episode: 2313   score: 9.0   memory length: 547383   epsilon: 0.11417968000848928    steps: 506    lr: 2.560000000000001e-06     evaluation reward: 5.97\n",
      "episode: 2314   score: 7.0   memory length: 547788   epsilon: 0.11337778000848983    steps: 405    lr: 2.560000000000001e-06     evaluation reward: 5.97\n",
      "episode: 2315   score: 6.0   memory length: 548159   epsilon: 0.11264320000849033    steps: 371    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 2316   score: 6.0   memory length: 548539   epsilon: 0.11189080000849085    steps: 380    lr: 2.560000000000001e-06     evaluation reward: 6.01\n",
      "episode: 2317   score: 5.0   memory length: 548848   epsilon: 0.11127898000849126    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 2318   score: 10.0   memory length: 549209   epsilon: 0.11056420000849175    steps: 361    lr: 2.560000000000001e-06     evaluation reward: 6.05\n",
      "episode: 2319   score: 5.0   memory length: 549517   epsilon: 0.10995436000849217    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 6.05\n",
      "episode: 2320   score: 4.0   memory length: 549775   epsilon: 0.10944352000849251    steps: 258    lr: 2.560000000000001e-06     evaluation reward: 6.03\n",
      "episode: 2321   score: 7.0   memory length: 550159   epsilon: 0.10868320000849303    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 6.04\n",
      "episode: 2322   score: 4.0   memory length: 550439   epsilon: 0.10812880000849341    steps: 280    lr: 2.560000000000001e-06     evaluation reward: 5.98\n",
      "episode: 2323   score: 4.0   memory length: 550737   epsilon: 0.10753876000849381    steps: 298    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 2324   score: 9.0   memory length: 551199   epsilon: 0.10662400000849444    steps: 462    lr: 2.560000000000001e-06     evaluation reward: 6.03\n",
      "episode: 2325   score: 9.0   memory length: 551500   epsilon: 0.10602802000849484    steps: 301    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2326   score: 5.0   memory length: 551810   epsilon: 0.10541422000849526    steps: 310    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 2327   score: 9.0   memory length: 552157   epsilon: 0.10472716000849573    steps: 347    lr: 2.560000000000001e-06     evaluation reward: 6.04\n",
      "episode: 2328   score: 4.0   memory length: 552434   epsilon: 0.1041787000084961    steps: 277    lr: 2.560000000000001e-06     evaluation reward: 6.02\n",
      "episode: 2329   score: 7.0   memory length: 552782   epsilon: 0.10348966000849658    steps: 348    lr: 2.560000000000001e-06     evaluation reward: 6.03\n",
      "episode: 2330   score: 10.0   memory length: 553201   epsilon: 0.10266004000849714    steps: 419    lr: 2.560000000000001e-06     evaluation reward: 6.06\n",
      "episode: 2331   score: 6.0   memory length: 553581   epsilon: 0.10190764000849765    steps: 380    lr: 2.560000000000001e-06     evaluation reward: 6.08\n",
      "episode: 2332   score: 6.0   memory length: 553922   epsilon: 0.10123246000849812    steps: 341    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2333   score: 7.0   memory length: 554317   epsilon: 0.10045036000849865    steps: 395    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2334   score: 6.0   memory length: 554673   epsilon: 0.09974548000849913    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 6.09\n",
      "episode: 2335   score: 7.0   memory length: 555047   epsilon: 0.09900496000849963    steps: 374    lr: 2.560000000000001e-06     evaluation reward: 6.08\n",
      "episode: 2336   score: 4.0   memory length: 555309   epsilon: 0.09848620000849999    steps: 262    lr: 2.560000000000001e-06     evaluation reward: 6.05\n",
      "episode: 2337   score: 6.0   memory length: 555616   epsilon: 0.0978783400085004    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2338   score: 5.0   memory length: 555913   epsilon: 0.0972902800085008    steps: 297    lr: 2.560000000000001e-06     evaluation reward: 6.02\n",
      "episode: 2339   score: 4.0   memory length: 556176   epsilon: 0.09676954000850116    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 2340   score: 6.0   memory length: 556530   epsilon: 0.09606862000850164    steps: 354    lr: 2.560000000000001e-06     evaluation reward: 6.0\n",
      "episode: 2341   score: 4.0   memory length: 556790   epsilon: 0.09555382000850199    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 2342   score: 3.0   memory length: 557021   epsilon: 0.0950964400085023    steps: 231    lr: 2.560000000000001e-06     evaluation reward: 5.94\n",
      "episode: 2343   score: 10.0   memory length: 557399   epsilon: 0.09434800000850281    steps: 378    lr: 2.560000000000001e-06     evaluation reward: 5.95\n",
      "episode: 2344   score: 6.0   memory length: 557776   epsilon: 0.09360154000850332    steps: 377    lr: 2.560000000000001e-06     evaluation reward: 5.96\n",
      "episode: 2345   score: 10.0   memory length: 558264   epsilon: 0.09263530000850398    steps: 488    lr: 2.560000000000001e-06     evaluation reward: 6.0\n",
      "episode: 2346   score: 7.0   memory length: 558628   epsilon: 0.09191458000850447    steps: 364    lr: 2.560000000000001e-06     evaluation reward: 6.01\n",
      "episode: 2347   score: 6.0   memory length: 558981   epsilon: 0.09121564000850495    steps: 353    lr: 2.560000000000001e-06     evaluation reward: 6.01\n",
      "episode: 2348   score: 5.0   memory length: 559269   epsilon: 0.09064540000850534    steps: 288    lr: 2.560000000000001e-06     evaluation reward: 6.0\n",
      "episode: 2349   score: 6.0   memory length: 559586   epsilon: 0.09001774000850576    steps: 317    lr: 2.560000000000001e-06     evaluation reward: 5.98\n",
      "episode: 2350   score: 7.0   memory length: 559993   epsilon: 0.08921188000850631    steps: 407    lr: 2.560000000000001e-06     evaluation reward: 6.02\n",
      "episode: 2351   score: 5.0   memory length: 560300   epsilon: 0.08860402000850673    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 6.02\n",
      "episode: 2352   score: 5.0   memory length: 560623   epsilon: 0.08796448000850716    steps: 323    lr: 2.560000000000001e-06     evaluation reward: 6.04\n",
      "episode: 2353   score: 6.0   memory length: 560981   epsilon: 0.08725564000850765    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 5.97\n",
      "episode: 2354   score: 7.0   memory length: 561381   epsilon: 0.08646364000850819    steps: 400    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 2355   score: 4.0   memory length: 561680   epsilon: 0.08587162000850859    steps: 299    lr: 2.560000000000001e-06     evaluation reward: 5.99\n",
      "episode: 2356   score: 14.0   memory length: 562211   epsilon: 0.08482024000850931    steps: 531    lr: 2.560000000000001e-06     evaluation reward: 6.08\n",
      "episode: 2357   score: 7.0   memory length: 562632   epsilon: 0.08398666000850988    steps: 421    lr: 2.560000000000001e-06     evaluation reward: 6.09\n",
      "episode: 2358   score: 6.0   memory length: 562990   epsilon: 0.08327782000851036    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2359   score: 7.0   memory length: 563380   epsilon: 0.08250562000851089    steps: 390    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2360   score: 6.0   memory length: 563737   epsilon: 0.08179876000851137    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 6.09\n",
      "episode: 2361   score: 5.0   memory length: 564050   epsilon: 0.08117902000851179    steps: 313    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2362   score: 6.0   memory length: 564389   epsilon: 0.08050780000851225    steps: 339    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2363   score: 8.0   memory length: 564813   epsilon: 0.07966828000851282    steps: 424    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 2364   score: 5.0   memory length: 565100   epsilon: 0.07910002000851321    steps: 287    lr: 2.560000000000001e-06     evaluation reward: 6.18\n",
      "episode: 2365   score: 6.0   memory length: 565460   epsilon: 0.0783872200085137    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2366   score: 4.0   memory length: 565755   epsilon: 0.0778031200085141    steps: 295    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2367   score: 5.0   memory length: 566064   epsilon: 0.07719130000851451    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2368   score: 5.0   memory length: 566351   epsilon: 0.0766230400085149    steps: 287    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2369   score: 9.0   memory length: 566850   epsilon: 0.07563502000851557    steps: 499    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2370   score: 6.0   memory length: 567192   epsilon: 0.07495786000851604    steps: 342    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2371   score: 4.0   memory length: 567455   epsilon: 0.07443712000851639    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2372   score: 5.0   memory length: 567766   epsilon: 0.07382134000851681    steps: 311    lr: 2.560000000000001e-06     evaluation reward: 6.04\n",
      "episode: 2373   score: 4.0   memory length: 568029   epsilon: 0.07330060000851717    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 6.04\n",
      "episode: 2374   score: 4.0   memory length: 568286   epsilon: 0.07279174000851751    steps: 257    lr: 2.560000000000001e-06     evaluation reward: 6.03\n",
      "episode: 2375   score: 6.0   memory length: 568642   epsilon: 0.072086860008518    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 6.04\n",
      "episode: 2376   score: 8.0   memory length: 569078   epsilon: 0.07122358000851858    steps: 436    lr: 2.560000000000001e-06     evaluation reward: 6.06\n",
      "episode: 2377   score: 4.0   memory length: 569374   epsilon: 0.07063750000851898    steps: 296    lr: 2.560000000000001e-06     evaluation reward: 6.03\n",
      "episode: 2378   score: 9.0   memory length: 569878   epsilon: 0.06963958000851966    steps: 504    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2379   score: 7.0   memory length: 570282   epsilon: 0.06883966000852021    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 6.07\n",
      "episode: 2380   score: 4.0   memory length: 570542   epsilon: 0.06832486000852056    steps: 260    lr: 2.560000000000001e-06     evaluation reward: 6.02\n",
      "episode: 2381   score: 5.0   memory length: 570838   epsilon: 0.06773878000852096    steps: 296    lr: 2.560000000000001e-06     evaluation reward: 6.04\n",
      "episode: 2382   score: 4.0   memory length: 571115   epsilon: 0.06719032000852133    steps: 277    lr: 2.560000000000001e-06     evaluation reward: 6.03\n",
      "episode: 2383   score: 5.0   memory length: 571441   epsilon: 0.06654484000852177    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 6.03\n",
      "episode: 2384   score: 5.0   memory length: 571750   epsilon: 0.06593302000852219    steps: 309    lr: 2.560000000000001e-06     evaluation reward: 6.06\n",
      "episode: 2385   score: 4.0   memory length: 572029   epsilon: 0.06538060000852257    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 6.02\n",
      "episode: 2386   score: 7.0   memory length: 572393   epsilon: 0.06465988000852306    steps: 364    lr: 2.560000000000001e-06     evaluation reward: 6.04\n",
      "episode: 2387   score: 7.0   memory length: 572776   epsilon: 0.06390154000852358    steps: 383    lr: 2.560000000000001e-06     evaluation reward: 6.05\n",
      "episode: 2388   score: 8.0   memory length: 573188   epsilon: 0.06308578000852413    steps: 412    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2389   score: 5.0   memory length: 573513   epsilon: 0.06244228000852457    steps: 325    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2390   score: 8.0   memory length: 573948   epsilon: 0.06158098000852516    steps: 435    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2391   score: 5.0   memory length: 574292   epsilon: 0.060899860008525625    steps: 344    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2392   score: 9.0   memory length: 574620   epsilon: 0.06025042000852607    steps: 328    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2393   score: 5.0   memory length: 574932   epsilon: 0.05963266000852649    steps: 312    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2394   score: 5.0   memory length: 575262   epsilon: 0.058979260008526935    steps: 330    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2395   score: 7.0   memory length: 575626   epsilon: 0.058258540008527426    steps: 364    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2396   score: 5.0   memory length: 575952   epsilon: 0.05761306000852787    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2397   score: 12.0   memory length: 576356   epsilon: 0.05681314000852841    steps: 404    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2398   score: 4.0   memory length: 576617   epsilon: 0.056296360008528765    steps: 261    lr: 2.560000000000001e-06     evaluation reward: 6.08\n",
      "episode: 2399   score: 9.0   memory length: 577035   epsilon: 0.05546872000852933    steps: 418    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2400   score: 8.0   memory length: 577489   epsilon: 0.05456980000852994    steps: 454    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2401   score: 6.0   memory length: 577829   epsilon: 0.0538966000085304    steps: 340    lr: 2.560000000000001e-06     evaluation reward: 6.16\n",
      "episode: 2402   score: 11.0   memory length: 578343   epsilon: 0.052878880008531096    steps: 514    lr: 2.560000000000001e-06     evaluation reward: 6.22\n",
      "episode: 2403   score: 5.0   memory length: 578669   epsilon: 0.052233400008531536    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 6.21\n",
      "episode: 2404   score: 5.0   memory length: 578982   epsilon: 0.05161366000853196    steps: 313    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2405   score: 6.0   memory length: 579340   epsilon: 0.05090482000853244    steps: 358    lr: 2.560000000000001e-06     evaluation reward: 6.22\n",
      "episode: 2406   score: 5.0   memory length: 579667   epsilon: 0.050257360008532884    steps: 327    lr: 2.560000000000001e-06     evaluation reward: 6.19\n",
      "episode: 2407   score: 5.0   memory length: 579971   epsilon: 0.049655440008533294    steps: 304    lr: 2.560000000000001e-06     evaluation reward: 6.21\n",
      "episode: 2408   score: 5.0   memory length: 580264   epsilon: 0.04907530000853369    steps: 293    lr: 2.560000000000001e-06     evaluation reward: 6.21\n",
      "episode: 2409   score: 5.0   memory length: 580556   epsilon: 0.048497140008534084    steps: 292    lr: 2.560000000000001e-06     evaluation reward: 6.18\n",
      "episode: 2410   score: 6.0   memory length: 580913   epsilon: 0.047790280008534566    steps: 357    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2411   score: 11.0   memory length: 581448   epsilon: 0.04673098000853529    steps: 535    lr: 2.560000000000001e-06     evaluation reward: 6.26\n",
      "episode: 2412   score: 8.0   memory length: 581842   epsilon: 0.04595086000853582    steps: 394    lr: 2.560000000000001e-06     evaluation reward: 6.27\n",
      "episode: 2413   score: 3.0   memory length: 582056   epsilon: 0.04552714000853611    steps: 214    lr: 2.560000000000001e-06     evaluation reward: 6.21\n",
      "episode: 2414   score: 6.0   memory length: 582392   epsilon: 0.044861860008536564    steps: 336    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2415   score: 6.0   memory length: 582769   epsilon: 0.04411540000853707    steps: 377    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2416   score: 5.0   memory length: 583077   epsilon: 0.04350556000853749    steps: 308    lr: 2.560000000000001e-06     evaluation reward: 6.19\n",
      "episode: 2417   score: 8.0   memory length: 583356   epsilon: 0.042953140008537866    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 6.22\n",
      "episode: 2418   score: 9.0   memory length: 583794   epsilon: 0.04208590000853846    steps: 438    lr: 2.560000000000001e-06     evaluation reward: 6.21\n",
      "episode: 2419   score: 4.0   memory length: 584074   epsilon: 0.041531500008538835    steps: 280    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2420   score: 4.0   memory length: 584337   epsilon: 0.04101076000853919    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2421   score: 5.0   memory length: 584641   epsilon: 0.0404088400085396    steps: 304    lr: 2.560000000000001e-06     evaluation reward: 6.18\n",
      "episode: 2422   score: 6.0   memory length: 584984   epsilon: 0.039729700008540064    steps: 343    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2423   score: 3.0   memory length: 585213   epsilon: 0.039276280008540373    steps: 229    lr: 2.560000000000001e-06     evaluation reward: 6.19\n",
      "episode: 2424   score: 10.0   memory length: 585588   epsilon: 0.03853378000854088    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2425   score: 6.0   memory length: 585881   epsilon: 0.037953640008541276    steps: 293    lr: 2.560000000000001e-06     evaluation reward: 6.17\n",
      "episode: 2426   score: 8.0   memory length: 586297   epsilon: 0.03712996000854184    steps: 416    lr: 2.560000000000001e-06     evaluation reward: 6.2\n",
      "episode: 2427   score: 4.0   memory length: 586573   epsilon: 0.03658348000854221    steps: 276    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2428   score: 4.0   memory length: 586836   epsilon: 0.036062740008542565    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2429   score: 6.0   memory length: 587196   epsilon: 0.03534994000854305    steps: 360    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2430   score: 8.0   memory length: 587475   epsilon: 0.03479752000854343    steps: 279    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2431   score: 7.0   memory length: 587897   epsilon: 0.033961960008544    steps: 422    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2432   score: 3.0   memory length: 588142   epsilon: 0.03347686000854433    steps: 245    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2433   score: 8.0   memory length: 588597   epsilon: 0.032575960008544944    steps: 455    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2434   score: 5.0   memory length: 588889   epsilon: 0.03199780000854534    steps: 292    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2435   score: 6.0   memory length: 589265   epsilon: 0.031253320008545846    steps: 376    lr: 2.560000000000001e-06     evaluation reward: 6.09\n",
      "episode: 2436   score: 5.0   memory length: 589613   epsilon: 0.030564280008546316    steps: 348    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2437   score: 6.0   memory length: 589992   epsilon: 0.029813860008546827    steps: 379    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2438   score: 6.0   memory length: 590347   epsilon: 0.029110960008547307    steps: 355    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2439   score: 4.0   memory length: 590642   epsilon: 0.028526860008547705    steps: 295    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2440   score: 5.0   memory length: 590968   epsilon: 0.027881380008548146    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 6.1\n",
      "episode: 2441   score: 5.0   memory length: 591275   epsilon: 0.02727352000854856    steps: 307    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2442   score: 9.0   memory length: 591639   epsilon: 0.026552800008549052    steps: 364    lr: 2.560000000000001e-06     evaluation reward: 6.17\n",
      "episode: 2443   score: 7.0   memory length: 592062   epsilon: 0.025715260008549623    steps: 423    lr: 2.560000000000001e-06     evaluation reward: 6.14\n",
      "episode: 2444   score: 11.0   memory length: 592580   epsilon: 0.024689620008550323    steps: 518    lr: 2.560000000000001e-06     evaluation reward: 6.19\n",
      "episode: 2445   score: 6.0   memory length: 592951   epsilon: 0.023955040008550824    steps: 371    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2446   score: 3.0   memory length: 593180   epsilon: 0.023501620008551133    steps: 229    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2447   score: 6.0   memory length: 593553   epsilon: 0.022763080008551637    steps: 373    lr: 2.560000000000001e-06     evaluation reward: 6.11\n",
      "episode: 2448   score: 13.0   memory length: 594035   epsilon: 0.021808720008552288    steps: 482    lr: 2.560000000000001e-06     evaluation reward: 6.19\n",
      "episode: 2449   score: 6.0   memory length: 594357   epsilon: 0.021171160008552722    steps: 322    lr: 2.560000000000001e-06     evaluation reward: 6.19\n",
      "episode: 2450   score: 6.0   memory length: 594732   epsilon: 0.02042866000855323    steps: 375    lr: 2.560000000000001e-06     evaluation reward: 6.18\n",
      "episode: 2451   score: 9.0   memory length: 595219   epsilon: 0.019464400008553887    steps: 487    lr: 2.560000000000001e-06     evaluation reward: 6.22\n",
      "episode: 2452   score: 5.0   memory length: 595509   epsilon: 0.018890200008554278    steps: 290    lr: 2.560000000000001e-06     evaluation reward: 6.22\n",
      "episode: 2453   score: 7.0   memory length: 595912   epsilon: 0.018092260008554822    steps: 403    lr: 2.560000000000001e-06     evaluation reward: 6.23\n",
      "episode: 2454   score: 5.0   memory length: 596194   epsilon: 0.017533900008555203    steps: 282    lr: 2.560000000000001e-06     evaluation reward: 6.21\n",
      "episode: 2455   score: 6.0   memory length: 596550   epsilon: 0.016829020008555684    steps: 356    lr: 2.560000000000001e-06     evaluation reward: 6.23\n",
      "episode: 2456   score: 4.0   memory length: 596813   epsilon: 0.01630828000855604    steps: 263    lr: 2.560000000000001e-06     evaluation reward: 6.13\n",
      "episode: 2457   score: 6.0   memory length: 597136   epsilon: 0.015668740008556475    steps: 323    lr: 2.560000000000001e-06     evaluation reward: 6.12\n",
      "episode: 2458   score: 9.0   memory length: 597573   epsilon: 0.014803480008556346    steps: 437    lr: 2.560000000000001e-06     evaluation reward: 6.15\n",
      "episode: 2459   score: 13.0   memory length: 597957   epsilon: 0.014043160008556198    steps: 384    lr: 2.560000000000001e-06     evaluation reward: 6.21\n",
      "episode: 2460   score: 9.0   memory length: 598453   epsilon: 0.013061080008556008    steps: 496    lr: 2.560000000000001e-06     evaluation reward: 6.24\n",
      "episode: 2461   score: 5.0   memory length: 598779   epsilon: 0.012415600008555882    steps: 326    lr: 2.560000000000001e-06     evaluation reward: 6.24\n",
      "episode: 2462   score: 6.0   memory length: 599100   epsilon: 0.011780020008555759    steps: 321    lr: 2.560000000000001e-06     evaluation reward: 6.24\n",
      "episode: 2463   score: 8.0   memory length: 599536   epsilon: 0.010916740008555591    steps: 436    lr: 2.560000000000001e-06     evaluation reward: 6.24\n",
      "episode: 2464   score: 5.0   memory length: 599834   epsilon: 0.010326700008555477    steps: 298    lr: 2.560000000000001e-06     evaluation reward: 6.24\n",
      "episode: 2465   score: 5.0   memory length: 600161   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.23\n",
      "episode: 2466   score: 9.0   memory length: 600631   epsilon: 0.009998020008555413    steps: 470    lr: 1.0240000000000005e-06     evaluation reward: 6.28\n",
      "episode: 2467   score: 7.0   memory length: 601021   epsilon: 0.009998020008555413    steps: 390    lr: 1.0240000000000005e-06     evaluation reward: 6.3\n",
      "episode: 2468   score: 10.0   memory length: 601502   epsilon: 0.009998020008555413    steps: 481    lr: 1.0240000000000005e-06     evaluation reward: 6.35\n",
      "episode: 2469   score: 5.0   memory length: 601831   epsilon: 0.009998020008555413    steps: 329    lr: 1.0240000000000005e-06     evaluation reward: 6.31\n",
      "episode: 2470   score: 8.0   memory length: 602250   epsilon: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     evaluation reward: 6.33\n",
      "episode: 2471   score: 7.0   memory length: 602620   epsilon: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     evaluation reward: 6.36\n",
      "episode: 2472   score: 8.0   memory length: 603078   epsilon: 0.009998020008555413    steps: 458    lr: 1.0240000000000005e-06     evaluation reward: 6.39\n",
      "episode: 2473   score: 4.0   memory length: 603358   epsilon: 0.009998020008555413    steps: 280    lr: 1.0240000000000005e-06     evaluation reward: 6.39\n",
      "episode: 2474   score: 6.0   memory length: 603751   epsilon: 0.009998020008555413    steps: 393    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2475   score: 6.0   memory length: 604125   epsilon: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2476   score: 6.0   memory length: 604480   epsilon: 0.009998020008555413    steps: 355    lr: 1.0240000000000005e-06     evaluation reward: 6.39\n",
      "episode: 2477   score: 7.0   memory length: 604905   epsilon: 0.009998020008555413    steps: 425    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2478   score: 7.0   memory length: 605329   epsilon: 0.009998020008555413    steps: 424    lr: 1.0240000000000005e-06     evaluation reward: 6.4\n",
      "episode: 2479   score: 5.0   memory length: 605613   epsilon: 0.009998020008555413    steps: 284    lr: 1.0240000000000005e-06     evaluation reward: 6.38\n",
      "episode: 2480   score: 9.0   memory length: 605954   epsilon: 0.009998020008555413    steps: 341    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2481   score: 4.0   memory length: 606219   epsilon: 0.009998020008555413    steps: 265    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2482   score: 4.0   memory length: 606497   epsilon: 0.009998020008555413    steps: 278    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2483   score: 9.0   memory length: 606979   epsilon: 0.009998020008555413    steps: 482    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2484   score: 9.0   memory length: 607398   epsilon: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2485   score: 4.0   memory length: 607695   epsilon: 0.009998020008555413    steps: 297    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2486   score: 6.0   memory length: 608049   epsilon: 0.009998020008555413    steps: 354    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2487   score: 5.0   memory length: 608356   epsilon: 0.009998020008555413    steps: 307    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2488   score: 8.0   memory length: 608777   epsilon: 0.009998020008555413    steps: 421    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2489   score: 5.0   memory length: 609104   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2490   score: 6.0   memory length: 609422   epsilon: 0.009998020008555413    steps: 318    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2491   score: 4.0   memory length: 609678   epsilon: 0.009998020008555413    steps: 256    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2492   score: 4.0   memory length: 609972   epsilon: 0.009998020008555413    steps: 294    lr: 1.0240000000000005e-06     evaluation reward: 6.39\n",
      "episode: 2493   score: 5.0   memory length: 610280   epsilon: 0.009998020008555413    steps: 308    lr: 1.0240000000000005e-06     evaluation reward: 6.39\n",
      "episode: 2494   score: 6.0   memory length: 610638   epsilon: 0.009998020008555413    steps: 358    lr: 1.0240000000000005e-06     evaluation reward: 6.4\n",
      "episode: 2495   score: 5.0   memory length: 610946   epsilon: 0.009998020008555413    steps: 308    lr: 1.0240000000000005e-06     evaluation reward: 6.38\n",
      "episode: 2496   score: 8.0   memory length: 611373   epsilon: 0.009998020008555413    steps: 427    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2497   score: 5.0   memory length: 611723   epsilon: 0.009998020008555413    steps: 350    lr: 1.0240000000000005e-06     evaluation reward: 6.34\n",
      "episode: 2498   score: 6.0   memory length: 612101   epsilon: 0.009998020008555413    steps: 378    lr: 1.0240000000000005e-06     evaluation reward: 6.36\n",
      "episode: 2499   score: 5.0   memory length: 612450   epsilon: 0.009998020008555413    steps: 349    lr: 1.0240000000000005e-06     evaluation reward: 6.32\n",
      "episode: 2500   score: 8.0   memory length: 612882   epsilon: 0.009998020008555413    steps: 432    lr: 1.0240000000000005e-06     evaluation reward: 6.32\n",
      "episode: 2501   score: 4.0   memory length: 613158   epsilon: 0.009998020008555413    steps: 276    lr: 1.0240000000000005e-06     evaluation reward: 6.3\n",
      "episode: 2502   score: 11.0   memory length: 613716   epsilon: 0.009998020008555413    steps: 558    lr: 1.0240000000000005e-06     evaluation reward: 6.3\n",
      "episode: 2503   score: 10.0   memory length: 614094   epsilon: 0.009998020008555413    steps: 378    lr: 1.0240000000000005e-06     evaluation reward: 6.35\n",
      "episode: 2504   score: 7.0   memory length: 614485   epsilon: 0.009998020008555413    steps: 391    lr: 1.0240000000000005e-06     evaluation reward: 6.37\n",
      "episode: 2505   score: 12.0   memory length: 615030   epsilon: 0.009998020008555413    steps: 545    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2506   score: 3.0   memory length: 615262   epsilon: 0.009998020008555413    steps: 232    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2507   score: 5.0   memory length: 615542   epsilon: 0.009998020008555413    steps: 280    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2508   score: 6.0   memory length: 615898   epsilon: 0.009998020008555413    steps: 356    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2509   score: 6.0   memory length: 616257   epsilon: 0.009998020008555413    steps: 359    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2510   score: 4.0   memory length: 616540   epsilon: 0.009998020008555413    steps: 283    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2511   score: 3.0   memory length: 616772   epsilon: 0.009998020008555413    steps: 232    lr: 1.0240000000000005e-06     evaluation reward: 6.33\n",
      "episode: 2512   score: 6.0   memory length: 617151   epsilon: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     evaluation reward: 6.31\n",
      "episode: 2513   score: 4.0   memory length: 617428   epsilon: 0.009998020008555413    steps: 277    lr: 1.0240000000000005e-06     evaluation reward: 6.32\n",
      "episode: 2514   score: 11.0   memory length: 617853   epsilon: 0.009998020008555413    steps: 425    lr: 1.0240000000000005e-06     evaluation reward: 6.37\n",
      "episode: 2515   score: 5.0   memory length: 618157   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 6.36\n",
      "episode: 2516   score: 10.0   memory length: 618612   epsilon: 0.009998020008555413    steps: 455    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2517   score: 16.0   memory length: 619102   epsilon: 0.009998020008555413    steps: 490    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2518   score: 8.0   memory length: 619400   epsilon: 0.009998020008555413    steps: 298    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2519   score: 4.0   memory length: 619678   epsilon: 0.009998020008555413    steps: 278    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2520   score: 5.0   memory length: 620005   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2521   score: 15.0   memory length: 620465   epsilon: 0.009998020008555413    steps: 460    lr: 1.0240000000000005e-06     evaluation reward: 6.59\n",
      "episode: 2522   score: 8.0   memory length: 620873   epsilon: 0.009998020008555413    steps: 408    lr: 1.0240000000000005e-06     evaluation reward: 6.61\n",
      "episode: 2523   score: 5.0   memory length: 621181   epsilon: 0.009998020008555413    steps: 308    lr: 1.0240000000000005e-06     evaluation reward: 6.63\n",
      "episode: 2524   score: 7.0   memory length: 621578   epsilon: 0.009998020008555413    steps: 397    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2525   score: 9.0   memory length: 622019   epsilon: 0.009998020008555413    steps: 441    lr: 1.0240000000000005e-06     evaluation reward: 6.63\n",
      "episode: 2526   score: 6.0   memory length: 622342   epsilon: 0.009998020008555413    steps: 323    lr: 1.0240000000000005e-06     evaluation reward: 6.61\n",
      "episode: 2527   score: 6.0   memory length: 622714   epsilon: 0.009998020008555413    steps: 372    lr: 1.0240000000000005e-06     evaluation reward: 6.63\n",
      "episode: 2528   score: 4.0   memory length: 622990   epsilon: 0.009998020008555413    steps: 276    lr: 1.0240000000000005e-06     evaluation reward: 6.63\n",
      "episode: 2529   score: 11.0   memory length: 623403   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 6.68\n",
      "episode: 2530   score: 9.0   memory length: 623729   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 6.69\n",
      "episode: 2531   score: 8.0   memory length: 624133   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 6.7\n",
      "episode: 2532   score: 8.0   memory length: 624570   epsilon: 0.009998020008555413    steps: 437    lr: 1.0240000000000005e-06     evaluation reward: 6.75\n",
      "episode: 2533   score: 6.0   memory length: 624924   epsilon: 0.009998020008555413    steps: 354    lr: 1.0240000000000005e-06     evaluation reward: 6.73\n",
      "episode: 2534   score: 8.0   memory length: 625203   epsilon: 0.009998020008555413    steps: 279    lr: 1.0240000000000005e-06     evaluation reward: 6.76\n",
      "episode: 2535   score: 5.0   memory length: 625490   epsilon: 0.009998020008555413    steps: 287    lr: 1.0240000000000005e-06     evaluation reward: 6.75\n",
      "episode: 2536   score: 4.0   memory length: 625786   epsilon: 0.009998020008555413    steps: 296    lr: 1.0240000000000005e-06     evaluation reward: 6.74\n",
      "episode: 2537   score: 7.0   memory length: 626054   epsilon: 0.009998020008555413    steps: 268    lr: 1.0240000000000005e-06     evaluation reward: 6.75\n",
      "episode: 2538   score: 6.0   memory length: 626413   epsilon: 0.009998020008555413    steps: 359    lr: 1.0240000000000005e-06     evaluation reward: 6.75\n",
      "episode: 2539   score: 9.0   memory length: 626835   epsilon: 0.009998020008555413    steps: 422    lr: 1.0240000000000005e-06     evaluation reward: 6.8\n",
      "episode: 2540   score: 8.0   memory length: 627222   epsilon: 0.009998020008555413    steps: 387    lr: 1.0240000000000005e-06     evaluation reward: 6.83\n",
      "episode: 2541   score: 13.0   memory length: 627694   epsilon: 0.009998020008555413    steps: 472    lr: 1.0240000000000005e-06     evaluation reward: 6.91\n",
      "episode: 2542   score: 7.0   memory length: 628118   epsilon: 0.009998020008555413    steps: 424    lr: 1.0240000000000005e-06     evaluation reward: 6.89\n",
      "episode: 2543   score: 8.0   memory length: 628592   epsilon: 0.009998020008555413    steps: 474    lr: 1.0240000000000005e-06     evaluation reward: 6.9\n",
      "episode: 2544   score: 7.0   memory length: 628996   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 6.86\n",
      "episode: 2545   score: 4.0   memory length: 629274   epsilon: 0.009998020008555413    steps: 278    lr: 1.0240000000000005e-06     evaluation reward: 6.84\n",
      "episode: 2546   score: 10.0   memory length: 629603   epsilon: 0.009998020008555413    steps: 329    lr: 1.0240000000000005e-06     evaluation reward: 6.91\n",
      "episode: 2547   score: 6.0   memory length: 629946   epsilon: 0.009998020008555413    steps: 343    lr: 1.0240000000000005e-06     evaluation reward: 6.91\n",
      "episode: 2548   score: 7.0   memory length: 630322   epsilon: 0.009998020008555413    steps: 376    lr: 1.0240000000000005e-06     evaluation reward: 6.85\n",
      "episode: 2549   score: 11.0   memory length: 630733   epsilon: 0.009998020008555413    steps: 411    lr: 1.0240000000000005e-06     evaluation reward: 6.9\n",
      "episode: 2550   score: 6.0   memory length: 631110   epsilon: 0.009998020008555413    steps: 377    lr: 1.0240000000000005e-06     evaluation reward: 6.9\n",
      "episode: 2551   score: 8.0   memory length: 631567   epsilon: 0.009998020008555413    steps: 457    lr: 1.0240000000000005e-06     evaluation reward: 6.89\n",
      "episode: 2552   score: 4.0   memory length: 631825   epsilon: 0.009998020008555413    steps: 258    lr: 1.0240000000000005e-06     evaluation reward: 6.88\n",
      "episode: 2553   score: 8.0   memory length: 632264   epsilon: 0.009998020008555413    steps: 439    lr: 1.0240000000000005e-06     evaluation reward: 6.89\n",
      "episode: 2554   score: 6.0   memory length: 632642   epsilon: 0.009998020008555413    steps: 378    lr: 1.0240000000000005e-06     evaluation reward: 6.9\n",
      "episode: 2555   score: 6.0   memory length: 632971   epsilon: 0.009998020008555413    steps: 329    lr: 1.0240000000000005e-06     evaluation reward: 6.9\n",
      "episode: 2556   score: 10.0   memory length: 633349   epsilon: 0.009998020008555413    steps: 378    lr: 1.0240000000000005e-06     evaluation reward: 6.96\n",
      "episode: 2557   score: 8.0   memory length: 633802   epsilon: 0.009998020008555413    steps: 453    lr: 1.0240000000000005e-06     evaluation reward: 6.98\n",
      "episode: 2558   score: 4.0   memory length: 634064   epsilon: 0.009998020008555413    steps: 262    lr: 1.0240000000000005e-06     evaluation reward: 6.93\n",
      "episode: 2559   score: 6.0   memory length: 634438   epsilon: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     evaluation reward: 6.86\n",
      "episode: 2560   score: 7.0   memory length: 634849   epsilon: 0.009998020008555413    steps: 411    lr: 1.0240000000000005e-06     evaluation reward: 6.84\n",
      "episode: 2561   score: 6.0   memory length: 635207   epsilon: 0.009998020008555413    steps: 358    lr: 1.0240000000000005e-06     evaluation reward: 6.85\n",
      "episode: 2562   score: 5.0   memory length: 635545   epsilon: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     evaluation reward: 6.84\n",
      "episode: 2563   score: 7.0   memory length: 635958   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 6.83\n",
      "episode: 2564   score: 4.0   memory length: 636218   epsilon: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     evaluation reward: 6.82\n",
      "episode: 2565   score: 3.0   memory length: 636447   epsilon: 0.009998020008555413    steps: 229    lr: 1.0240000000000005e-06     evaluation reward: 6.8\n",
      "episode: 2566   score: 7.0   memory length: 636836   epsilon: 0.009998020008555413    steps: 389    lr: 1.0240000000000005e-06     evaluation reward: 6.78\n",
      "episode: 2567   score: 6.0   memory length: 637193   epsilon: 0.009998020008555413    steps: 357    lr: 1.0240000000000005e-06     evaluation reward: 6.77\n",
      "episode: 2568   score: 6.0   memory length: 637522   epsilon: 0.009998020008555413    steps: 329    lr: 1.0240000000000005e-06     evaluation reward: 6.73\n",
      "episode: 2569   score: 18.0   memory length: 637901   epsilon: 0.009998020008555413    steps: 379    lr: 1.0240000000000005e-06     evaluation reward: 6.86\n",
      "episode: 2570   score: 4.0   memory length: 638162   epsilon: 0.009998020008555413    steps: 261    lr: 1.0240000000000005e-06     evaluation reward: 6.82\n",
      "episode: 2571   score: 9.0   memory length: 638492   epsilon: 0.009998020008555413    steps: 330    lr: 1.0240000000000005e-06     evaluation reward: 6.84\n",
      "episode: 2572   score: 6.0   memory length: 638849   epsilon: 0.009998020008555413    steps: 357    lr: 1.0240000000000005e-06     evaluation reward: 6.82\n",
      "episode: 2573   score: 5.0   memory length: 639135   epsilon: 0.009998020008555413    steps: 286    lr: 1.0240000000000005e-06     evaluation reward: 6.83\n",
      "episode: 2574   score: 6.0   memory length: 639492   epsilon: 0.009998020008555413    steps: 357    lr: 1.0240000000000005e-06     evaluation reward: 6.83\n",
      "episode: 2575   score: 7.0   memory length: 639923   epsilon: 0.009998020008555413    steps: 431    lr: 1.0240000000000005e-06     evaluation reward: 6.84\n",
      "episode: 2576   score: 8.0   memory length: 640202   epsilon: 0.009998020008555413    steps: 279    lr: 1.0240000000000005e-06     evaluation reward: 6.86\n",
      "episode: 2577   score: 7.0   memory length: 640550   epsilon: 0.009998020008555413    steps: 348    lr: 1.0240000000000005e-06     evaluation reward: 6.86\n",
      "episode: 2578   score: 5.0   memory length: 640861   epsilon: 0.009998020008555413    steps: 311    lr: 1.0240000000000005e-06     evaluation reward: 6.84\n",
      "episode: 2579   score: 5.0   memory length: 641156   epsilon: 0.009998020008555413    steps: 295    lr: 1.0240000000000005e-06     evaluation reward: 6.84\n",
      "episode: 2580   score: 4.0   memory length: 641400   epsilon: 0.009998020008555413    steps: 244    lr: 1.0240000000000005e-06     evaluation reward: 6.79\n",
      "episode: 2581   score: 5.0   memory length: 641687   epsilon: 0.009998020008555413    steps: 287    lr: 1.0240000000000005e-06     evaluation reward: 6.8\n",
      "episode: 2582   score: 5.0   memory length: 642001   epsilon: 0.009998020008555413    steps: 314    lr: 1.0240000000000005e-06     evaluation reward: 6.81\n",
      "episode: 2583   score: 3.0   memory length: 642229   epsilon: 0.009998020008555413    steps: 228    lr: 1.0240000000000005e-06     evaluation reward: 6.75\n",
      "episode: 2584   score: 10.0   memory length: 642723   epsilon: 0.009998020008555413    steps: 494    lr: 1.0240000000000005e-06     evaluation reward: 6.76\n",
      "episode: 2585   score: 7.0   memory length: 643149   epsilon: 0.009998020008555413    steps: 426    lr: 1.0240000000000005e-06     evaluation reward: 6.79\n",
      "episode: 2586   score: 3.0   memory length: 643377   epsilon: 0.009998020008555413    steps: 228    lr: 1.0240000000000005e-06     evaluation reward: 6.76\n",
      "episode: 2587   score: 6.0   memory length: 643713   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 6.77\n",
      "episode: 2588   score: 6.0   memory length: 644090   epsilon: 0.009998020008555413    steps: 377    lr: 1.0240000000000005e-06     evaluation reward: 6.75\n",
      "episode: 2589   score: 9.0   memory length: 644544   epsilon: 0.009998020008555413    steps: 454    lr: 1.0240000000000005e-06     evaluation reward: 6.79\n",
      "episode: 2590   score: 8.0   memory length: 644861   epsilon: 0.009998020008555413    steps: 317    lr: 1.0240000000000005e-06     evaluation reward: 6.81\n",
      "episode: 2591   score: 4.0   memory length: 645137   epsilon: 0.009998020008555413    steps: 276    lr: 1.0240000000000005e-06     evaluation reward: 6.81\n",
      "episode: 2592   score: 10.0   memory length: 645622   epsilon: 0.009998020008555413    steps: 485    lr: 1.0240000000000005e-06     evaluation reward: 6.87\n",
      "episode: 2593   score: 7.0   memory length: 646035   epsilon: 0.009998020008555413    steps: 413    lr: 1.0240000000000005e-06     evaluation reward: 6.89\n",
      "episode: 2594   score: 7.0   memory length: 646443   epsilon: 0.009998020008555413    steps: 408    lr: 1.0240000000000005e-06     evaluation reward: 6.9\n",
      "episode: 2595   score: 6.0   memory length: 646793   epsilon: 0.009998020008555413    steps: 350    lr: 1.0240000000000005e-06     evaluation reward: 6.91\n",
      "episode: 2596   score: 6.0   memory length: 647151   epsilon: 0.009998020008555413    steps: 358    lr: 1.0240000000000005e-06     evaluation reward: 6.89\n",
      "episode: 2597   score: 7.0   memory length: 647522   epsilon: 0.009998020008555413    steps: 371    lr: 1.0240000000000005e-06     evaluation reward: 6.91\n",
      "episode: 2598   score: 6.0   memory length: 647897   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 6.91\n",
      "episode: 2599   score: 6.0   memory length: 648273   epsilon: 0.009998020008555413    steps: 376    lr: 1.0240000000000005e-06     evaluation reward: 6.92\n",
      "episode: 2600   score: 3.0   memory length: 648487   epsilon: 0.009998020008555413    steps: 214    lr: 1.0240000000000005e-06     evaluation reward: 6.87\n",
      "episode: 2601   score: 5.0   memory length: 648815   epsilon: 0.009998020008555413    steps: 328    lr: 1.0240000000000005e-06     evaluation reward: 6.88\n",
      "episode: 2602   score: 5.0   memory length: 649124   epsilon: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     evaluation reward: 6.82\n",
      "episode: 2603   score: 6.0   memory length: 649477   epsilon: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     evaluation reward: 6.78\n",
      "episode: 2604   score: 6.0   memory length: 649839   epsilon: 0.009998020008555413    steps: 362    lr: 1.0240000000000005e-06     evaluation reward: 6.77\n",
      "episode: 2605   score: 10.0   memory length: 650380   epsilon: 0.009998020008555413    steps: 541    lr: 1.0240000000000005e-06     evaluation reward: 6.75\n",
      "episode: 2606   score: 4.0   memory length: 650659   epsilon: 0.009998020008555413    steps: 279    lr: 1.0240000000000005e-06     evaluation reward: 6.76\n",
      "episode: 2607   score: 7.0   memory length: 651098   epsilon: 0.009998020008555413    steps: 439    lr: 1.0240000000000005e-06     evaluation reward: 6.78\n",
      "episode: 2608   score: 15.0   memory length: 651701   epsilon: 0.009998020008555413    steps: 603    lr: 1.0240000000000005e-06     evaluation reward: 6.87\n",
      "episode: 2609   score: 7.0   memory length: 652074   epsilon: 0.009998020008555413    steps: 373    lr: 1.0240000000000005e-06     evaluation reward: 6.88\n",
      "episode: 2610   score: 7.0   memory length: 652449   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 6.91\n",
      "episode: 2611   score: 5.0   memory length: 652775   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 6.93\n",
      "episode: 2612   score: 6.0   memory length: 653114   epsilon: 0.009998020008555413    steps: 339    lr: 1.0240000000000005e-06     evaluation reward: 6.93\n",
      "episode: 2613   score: 9.0   memory length: 653509   epsilon: 0.009998020008555413    steps: 395    lr: 1.0240000000000005e-06     evaluation reward: 6.98\n",
      "episode: 2614   score: 10.0   memory length: 654060   epsilon: 0.009998020008555413    steps: 551    lr: 1.0240000000000005e-06     evaluation reward: 6.97\n",
      "episode: 2615   score: 4.0   memory length: 654338   epsilon: 0.009998020008555413    steps: 278    lr: 1.0240000000000005e-06     evaluation reward: 6.96\n",
      "episode: 2616   score: 4.0   memory length: 654614   epsilon: 0.009998020008555413    steps: 276    lr: 1.0240000000000005e-06     evaluation reward: 6.9\n",
      "episode: 2617   score: 6.0   memory length: 654986   epsilon: 0.009998020008555413    steps: 372    lr: 1.0240000000000005e-06     evaluation reward: 6.8\n",
      "episode: 2618   score: 6.0   memory length: 655329   epsilon: 0.009998020008555413    steps: 343    lr: 1.0240000000000005e-06     evaluation reward: 6.78\n",
      "episode: 2619   score: 6.0   memory length: 655650   epsilon: 0.009998020008555413    steps: 321    lr: 1.0240000000000005e-06     evaluation reward: 6.8\n",
      "episode: 2620   score: 7.0   memory length: 655976   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 6.82\n",
      "episode: 2621   score: 7.0   memory length: 656377   epsilon: 0.009998020008555413    steps: 401    lr: 1.0240000000000005e-06     evaluation reward: 6.74\n",
      "episode: 2622   score: 7.0   memory length: 656760   epsilon: 0.009998020008555413    steps: 383    lr: 1.0240000000000005e-06     evaluation reward: 6.73\n",
      "episode: 2623   score: 9.0   memory length: 657268   epsilon: 0.009998020008555413    steps: 508    lr: 1.0240000000000005e-06     evaluation reward: 6.77\n",
      "episode: 2624   score: 4.0   memory length: 657545   epsilon: 0.009998020008555413    steps: 277    lr: 1.0240000000000005e-06     evaluation reward: 6.74\n",
      "episode: 2625   score: 5.0   memory length: 657871   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 6.7\n",
      "episode: 2626   score: 6.0   memory length: 658228   epsilon: 0.009998020008555413    steps: 357    lr: 1.0240000000000005e-06     evaluation reward: 6.7\n",
      "episode: 2627   score: 8.0   memory length: 658681   epsilon: 0.009998020008555413    steps: 453    lr: 1.0240000000000005e-06     evaluation reward: 6.72\n",
      "episode: 2628   score: 4.0   memory length: 658942   epsilon: 0.009998020008555413    steps: 261    lr: 1.0240000000000005e-06     evaluation reward: 6.72\n",
      "episode: 2629   score: 6.0   memory length: 659272   epsilon: 0.009998020008555413    steps: 330    lr: 1.0240000000000005e-06     evaluation reward: 6.67\n",
      "episode: 2630   score: 5.0   memory length: 659584   epsilon: 0.009998020008555413    steps: 312    lr: 1.0240000000000005e-06     evaluation reward: 6.63\n",
      "episode: 2631   score: 6.0   memory length: 659941   epsilon: 0.009998020008555413    steps: 357    lr: 1.0240000000000005e-06     evaluation reward: 6.61\n",
      "episode: 2632   score: 5.0   memory length: 660251   epsilon: 0.009998020008555413    steps: 310    lr: 1.0240000000000005e-06     evaluation reward: 6.58\n",
      "episode: 2633   score: 11.0   memory length: 660650   epsilon: 0.009998020008555413    steps: 399    lr: 1.0240000000000005e-06     evaluation reward: 6.63\n",
      "episode: 2634   score: 10.0   memory length: 661209   epsilon: 0.009998020008555413    steps: 559    lr: 1.0240000000000005e-06     evaluation reward: 6.65\n",
      "episode: 2635   score: 5.0   memory length: 661521   epsilon: 0.009998020008555413    steps: 312    lr: 1.0240000000000005e-06     evaluation reward: 6.65\n",
      "episode: 2636   score: 7.0   memory length: 661929   epsilon: 0.009998020008555413    steps: 408    lr: 1.0240000000000005e-06     evaluation reward: 6.68\n",
      "episode: 2637   score: 5.0   memory length: 662261   epsilon: 0.009998020008555413    steps: 332    lr: 1.0240000000000005e-06     evaluation reward: 6.66\n",
      "episode: 2638   score: 5.0   memory length: 662584   epsilon: 0.009998020008555413    steps: 323    lr: 1.0240000000000005e-06     evaluation reward: 6.65\n",
      "episode: 2639   score: 5.0   memory length: 662907   epsilon: 0.009998020008555413    steps: 323    lr: 1.0240000000000005e-06     evaluation reward: 6.61\n",
      "episode: 2640   score: 4.0   memory length: 663183   epsilon: 0.009998020008555413    steps: 276    lr: 1.0240000000000005e-06     evaluation reward: 6.57\n",
      "episode: 2641   score: 8.0   memory length: 663462   epsilon: 0.009998020008555413    steps: 279    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2642   score: 5.0   memory length: 663792   epsilon: 0.009998020008555413    steps: 330    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2643   score: 7.0   memory length: 664200   epsilon: 0.009998020008555413    steps: 408    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2644   score: 5.0   memory length: 664489   epsilon: 0.009998020008555413    steps: 289    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2645   score: 6.0   memory length: 664818   epsilon: 0.009998020008555413    steps: 329    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2646   score: 10.0   memory length: 665310   epsilon: 0.009998020008555413    steps: 492    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2647   score: 6.0   memory length: 665649   epsilon: 0.009998020008555413    steps: 339    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2648   score: 6.0   memory length: 666014   epsilon: 0.009998020008555413    steps: 365    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2649   score: 8.0   memory length: 666293   epsilon: 0.009998020008555413    steps: 279    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2650   score: 5.0   memory length: 666641   epsilon: 0.009998020008555413    steps: 348    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2651   score: 5.0   memory length: 666948   epsilon: 0.009998020008555413    steps: 307    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2652   score: 4.0   memory length: 667206   epsilon: 0.009998020008555413    steps: 258    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2653   score: 6.0   memory length: 667545   epsilon: 0.009998020008555413    steps: 339    lr: 1.0240000000000005e-06     evaluation reward: 6.39\n",
      "episode: 2654   score: 4.0   memory length: 667805   epsilon: 0.009998020008555413    steps: 260    lr: 1.0240000000000005e-06     evaluation reward: 6.37\n",
      "episode: 2655   score: 7.0   memory length: 668224   epsilon: 0.009998020008555413    steps: 419    lr: 1.0240000000000005e-06     evaluation reward: 6.38\n",
      "episode: 2656   score: 3.0   memory length: 668469   epsilon: 0.009998020008555413    steps: 245    lr: 1.0240000000000005e-06     evaluation reward: 6.31\n",
      "episode: 2657   score: 5.0   memory length: 668774   epsilon: 0.009998020008555413    steps: 305    lr: 1.0240000000000005e-06     evaluation reward: 6.28\n",
      "episode: 2658   score: 7.0   memory length: 669150   epsilon: 0.009998020008555413    steps: 376    lr: 1.0240000000000005e-06     evaluation reward: 6.31\n",
      "episode: 2659   score: 7.0   memory length: 669576   epsilon: 0.009998020008555413    steps: 426    lr: 1.0240000000000005e-06     evaluation reward: 6.32\n",
      "episode: 2660   score: 4.0   memory length: 669852   epsilon: 0.009998020008555413    steps: 276    lr: 1.0240000000000005e-06     evaluation reward: 6.29\n",
      "episode: 2661   score: 4.0   memory length: 670146   epsilon: 0.009998020008555413    steps: 294    lr: 1.0240000000000005e-06     evaluation reward: 6.27\n",
      "episode: 2662   score: 5.0   memory length: 670473   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.27\n",
      "episode: 2663   score: 5.0   memory length: 670800   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.25\n",
      "episode: 2664   score: 6.0   memory length: 671142   epsilon: 0.009998020008555413    steps: 342    lr: 1.0240000000000005e-06     evaluation reward: 6.27\n",
      "episode: 2665   score: 5.0   memory length: 671450   epsilon: 0.009998020008555413    steps: 308    lr: 1.0240000000000005e-06     evaluation reward: 6.29\n",
      "episode: 2666   score: 6.0   memory length: 671803   epsilon: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     evaluation reward: 6.28\n",
      "episode: 2667   score: 11.0   memory length: 672225   epsilon: 0.009998020008555413    steps: 422    lr: 1.0240000000000005e-06     evaluation reward: 6.33\n",
      "episode: 2668   score: 10.0   memory length: 672615   epsilon: 0.009998020008555413    steps: 390    lr: 1.0240000000000005e-06     evaluation reward: 6.37\n",
      "episode: 2669   score: 5.0   memory length: 672940   epsilon: 0.009998020008555413    steps: 325    lr: 1.0240000000000005e-06     evaluation reward: 6.24\n",
      "episode: 2670   score: 7.0   memory length: 673344   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 6.27\n",
      "episode: 2671   score: 5.0   memory length: 673672   epsilon: 0.009998020008555413    steps: 328    lr: 1.0240000000000005e-06     evaluation reward: 6.23\n",
      "episode: 2672   score: 5.0   memory length: 673997   epsilon: 0.009998020008555413    steps: 325    lr: 1.0240000000000005e-06     evaluation reward: 6.22\n",
      "episode: 2673   score: 11.0   memory length: 674391   epsilon: 0.009998020008555413    steps: 394    lr: 1.0240000000000005e-06     evaluation reward: 6.28\n",
      "episode: 2674   score: 6.0   memory length: 674710   epsilon: 0.009998020008555413    steps: 319    lr: 1.0240000000000005e-06     evaluation reward: 6.28\n",
      "episode: 2675   score: 6.0   memory length: 675068   epsilon: 0.009998020008555413    steps: 358    lr: 1.0240000000000005e-06     evaluation reward: 6.27\n",
      "episode: 2676   score: 10.0   memory length: 675539   epsilon: 0.009998020008555413    steps: 471    lr: 1.0240000000000005e-06     evaluation reward: 6.29\n",
      "episode: 2677   score: 9.0   memory length: 676007   epsilon: 0.009998020008555413    steps: 468    lr: 1.0240000000000005e-06     evaluation reward: 6.31\n",
      "episode: 2678   score: 6.0   memory length: 676363   epsilon: 0.009998020008555413    steps: 356    lr: 1.0240000000000005e-06     evaluation reward: 6.32\n",
      "episode: 2679   score: 6.0   memory length: 676737   epsilon: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     evaluation reward: 6.33\n",
      "episode: 2680   score: 6.0   memory length: 677097   epsilon: 0.009998020008555413    steps: 360    lr: 1.0240000000000005e-06     evaluation reward: 6.35\n",
      "episode: 2681   score: 13.0   memory length: 677644   epsilon: 0.009998020008555413    steps: 547    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2682   score: 5.0   memory length: 677970   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2683   score: 10.0   memory length: 678345   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2684   score: 5.0   memory length: 678649   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2685   score: 6.0   memory length: 679025   epsilon: 0.009998020008555413    steps: 376    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2686   score: 5.0   memory length: 679326   epsilon: 0.009998020008555413    steps: 301    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2687   score: 9.0   memory length: 679762   epsilon: 0.009998020008555413    steps: 436    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2688   score: 17.0   memory length: 680421   epsilon: 0.009998020008555413    steps: 659    lr: 1.0240000000000005e-06     evaluation reward: 6.6\n",
      "episode: 2689   score: 5.0   memory length: 680731   epsilon: 0.009998020008555413    steps: 310    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2690   score: 7.0   memory length: 681101   epsilon: 0.009998020008555413    steps: 370    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2691   score: 4.0   memory length: 681380   epsilon: 0.009998020008555413    steps: 279    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2692   score: 7.0   memory length: 681755   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2693   score: 7.0   memory length: 682140   epsilon: 0.009998020008555413    steps: 385    lr: 1.0240000000000005e-06     evaluation reward: 6.52\n",
      "episode: 2694   score: 5.0   memory length: 682449   epsilon: 0.009998020008555413    steps: 309    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2695   score: 5.0   memory length: 682776   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2696   score: 4.0   memory length: 683052   epsilon: 0.009998020008555413    steps: 276    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2697   score: 5.0   memory length: 683381   epsilon: 0.009998020008555413    steps: 329    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2698   score: 4.0   memory length: 683676   epsilon: 0.009998020008555413    steps: 295    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2699   score: 5.0   memory length: 683989   epsilon: 0.009998020008555413    steps: 313    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2700   score: 5.0   memory length: 684297   epsilon: 0.009998020008555413    steps: 308    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2701   score: 6.0   memory length: 684623   epsilon: 0.009998020008555413    steps: 326    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2702   score: 7.0   memory length: 684998   epsilon: 0.009998020008555413    steps: 375    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2703   score: 6.0   memory length: 685358   epsilon: 0.009998020008555413    steps: 360    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2704   score: 4.0   memory length: 685634   epsilon: 0.009998020008555413    steps: 276    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2705   score: 11.0   memory length: 686190   epsilon: 0.009998020008555413    steps: 556    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2706   score: 5.0   memory length: 686495   epsilon: 0.009998020008555413    steps: 305    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2707   score: 6.0   memory length: 686848   epsilon: 0.009998020008555413    steps: 353    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2708   score: 8.0   memory length: 687240   epsilon: 0.009998020008555413    steps: 392    lr: 1.0240000000000005e-06     evaluation reward: 6.39\n",
      "episode: 2709   score: 8.0   memory length: 687680   epsilon: 0.009998020008555413    steps: 440    lr: 1.0240000000000005e-06     evaluation reward: 6.4\n",
      "episode: 2710   score: 7.0   memory length: 688076   epsilon: 0.009998020008555413    steps: 396    lr: 1.0240000000000005e-06     evaluation reward: 6.4\n",
      "episode: 2711   score: 11.0   memory length: 688582   epsilon: 0.009998020008555413    steps: 506    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2712   score: 5.0   memory length: 688888   epsilon: 0.009998020008555413    steps: 306    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2713   score: 9.0   memory length: 689355   epsilon: 0.009998020008555413    steps: 467    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2714   score: 7.0   memory length: 689727   epsilon: 0.009998020008555413    steps: 372    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2715   score: 6.0   memory length: 690101   epsilon: 0.009998020008555413    steps: 374    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2716   score: 5.0   memory length: 690428   epsilon: 0.009998020008555413    steps: 327    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2717   score: 4.0   memory length: 690707   epsilon: 0.009998020008555413    steps: 279    lr: 1.0240000000000005e-06     evaluation reward: 6.43\n",
      "episode: 2718   score: 9.0   memory length: 691151   epsilon: 0.009998020008555413    steps: 444    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2719   score: 8.0   memory length: 691571   epsilon: 0.009998020008555413    steps: 420    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2720   score: 6.0   memory length: 691909   epsilon: 0.009998020008555413    steps: 338    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2721   score: 5.0   memory length: 692238   epsilon: 0.009998020008555413    steps: 329    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2722   score: 8.0   memory length: 692653   epsilon: 0.009998020008555413    steps: 415    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2723   score: 5.0   memory length: 692975   epsilon: 0.009998020008555413    steps: 322    lr: 1.0240000000000005e-06     evaluation reward: 6.42\n",
      "episode: 2724   score: 8.0   memory length: 693383   epsilon: 0.009998020008555413    steps: 408    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2725   score: 6.0   memory length: 693719   epsilon: 0.009998020008555413    steps: 336    lr: 1.0240000000000005e-06     evaluation reward: 6.47\n",
      "episode: 2726   score: 3.0   memory length: 693948   epsilon: 0.009998020008555413    steps: 229    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2727   score: 5.0   memory length: 694246   epsilon: 0.009998020008555413    steps: 298    lr: 1.0240000000000005e-06     evaluation reward: 6.41\n",
      "episode: 2728   score: 7.0   memory length: 694655   epsilon: 0.009998020008555413    steps: 409    lr: 1.0240000000000005e-06     evaluation reward: 6.44\n",
      "episode: 2729   score: 7.0   memory length: 695059   epsilon: 0.009998020008555413    steps: 404    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2730   score: 6.0   memory length: 695414   epsilon: 0.009998020008555413    steps: 355    lr: 1.0240000000000005e-06     evaluation reward: 6.46\n",
      "episode: 2731   score: 5.0   memory length: 695718   epsilon: 0.009998020008555413    steps: 304    lr: 1.0240000000000005e-06     evaluation reward: 6.45\n",
      "episode: 2732   score: 8.0   memory length: 696125   epsilon: 0.009998020008555413    steps: 407    lr: 1.0240000000000005e-06     evaluation reward: 6.48\n",
      "episode: 2733   score: 12.0   memory length: 696597   epsilon: 0.009998020008555413    steps: 472    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2734   score: 10.0   memory length: 697139   epsilon: 0.009998020008555413    steps: 542    lr: 1.0240000000000005e-06     evaluation reward: 6.49\n",
      "episode: 2735   score: 6.0   memory length: 697479   epsilon: 0.009998020008555413    steps: 340    lr: 1.0240000000000005e-06     evaluation reward: 6.5\n",
      "episode: 2736   score: 8.0   memory length: 697899   epsilon: 0.009998020008555413    steps: 420    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2737   score: 5.0   memory length: 698240   epsilon: 0.009998020008555413    steps: 341    lr: 1.0240000000000005e-06     evaluation reward: 6.51\n",
      "episode: 2738   score: 9.0   memory length: 698747   epsilon: 0.009998020008555413    steps: 507    lr: 1.0240000000000005e-06     evaluation reward: 6.55\n",
      "episode: 2739   score: 6.0   memory length: 699109   epsilon: 0.009998020008555413    steps: 362    lr: 1.0240000000000005e-06     evaluation reward: 6.56\n",
      "episode: 2740   score: 6.0   memory length: 699468   epsilon: 0.009998020008555413    steps: 359    lr: 1.0240000000000005e-06     evaluation reward: 6.58\n",
      "episode: 2741   score: 15.0   memory length: 699880   epsilon: 0.009998020008555413    steps: 412    lr: 1.0240000000000005e-06     evaluation reward: 6.65\n",
      "episode: 2742   score: 2.0   memory length: 700081   epsilon: 0.009998020008555413    steps: 201    lr: 4.0960000000000023e-07     evaluation reward: 6.62\n",
      "episode: 2743   score: 7.0   memory length: 700494   epsilon: 0.009998020008555413    steps: 413    lr: 4.0960000000000023e-07     evaluation reward: 6.62\n",
      "episode: 2744   score: 5.0   memory length: 700794   epsilon: 0.009998020008555413    steps: 300    lr: 4.0960000000000023e-07     evaluation reward: 6.62\n",
      "episode: 2745   score: 7.0   memory length: 701177   epsilon: 0.009998020008555413    steps: 383    lr: 4.0960000000000023e-07     evaluation reward: 6.63\n",
      "episode: 2746   score: 5.0   memory length: 701505   epsilon: 0.009998020008555413    steps: 328    lr: 4.0960000000000023e-07     evaluation reward: 6.58\n",
      "episode: 2747   score: 9.0   memory length: 702027   epsilon: 0.009998020008555413    steps: 522    lr: 4.0960000000000023e-07     evaluation reward: 6.61\n",
      "episode: 2748   score: 4.0   memory length: 702288   epsilon: 0.009998020008555413    steps: 261    lr: 4.0960000000000023e-07     evaluation reward: 6.59\n",
      "episode: 2749   score: 6.0   memory length: 702623   epsilon: 0.009998020008555413    steps: 335    lr: 4.0960000000000023e-07     evaluation reward: 6.57\n",
      "episode: 2750   score: 8.0   memory length: 703015   epsilon: 0.009998020008555413    steps: 392    lr: 4.0960000000000023e-07     evaluation reward: 6.6\n",
      "episode: 2751   score: 6.0   memory length: 703319   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.61\n",
      "episode: 2752   score: 9.0   memory length: 703775   epsilon: 0.009998020008555413    steps: 456    lr: 4.0960000000000023e-07     evaluation reward: 6.66\n",
      "episode: 2753   score: 5.0   memory length: 704080   epsilon: 0.009998020008555413    steps: 305    lr: 4.0960000000000023e-07     evaluation reward: 6.65\n",
      "episode: 2754   score: 6.0   memory length: 704438   epsilon: 0.009998020008555413    steps: 358    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2755   score: 6.0   memory length: 704748   epsilon: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     evaluation reward: 6.66\n",
      "episode: 2756   score: 5.0   memory length: 705043   epsilon: 0.009998020008555413    steps: 295    lr: 4.0960000000000023e-07     evaluation reward: 6.68\n",
      "episode: 2757   score: 9.0   memory length: 705369   epsilon: 0.009998020008555413    steps: 326    lr: 4.0960000000000023e-07     evaluation reward: 6.72\n",
      "episode: 2758   score: 3.0   memory length: 705597   epsilon: 0.009998020008555413    steps: 228    lr: 4.0960000000000023e-07     evaluation reward: 6.68\n",
      "episode: 2759   score: 5.0   memory length: 705889   epsilon: 0.009998020008555413    steps: 292    lr: 4.0960000000000023e-07     evaluation reward: 6.66\n",
      "episode: 2760   score: 6.0   memory length: 706244   epsilon: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     evaluation reward: 6.68\n",
      "episode: 2761   score: 4.0   memory length: 706509   epsilon: 0.009998020008555413    steps: 265    lr: 4.0960000000000023e-07     evaluation reward: 6.68\n",
      "episode: 2762   score: 8.0   memory length: 706942   epsilon: 0.009998020008555413    steps: 433    lr: 4.0960000000000023e-07     evaluation reward: 6.71\n",
      "episode: 2763   score: 14.0   memory length: 707583   epsilon: 0.009998020008555413    steps: 641    lr: 4.0960000000000023e-07     evaluation reward: 6.8\n",
      "episode: 2764   score: 5.0   memory length: 707889   epsilon: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     evaluation reward: 6.79\n",
      "episode: 2765   score: 9.0   memory length: 708215   epsilon: 0.009998020008555413    steps: 326    lr: 4.0960000000000023e-07     evaluation reward: 6.83\n",
      "episode: 2766   score: 13.0   memory length: 708741   epsilon: 0.009998020008555413    steps: 526    lr: 4.0960000000000023e-07     evaluation reward: 6.9\n",
      "episode: 2767   score: 9.0   memory length: 709068   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 6.88\n",
      "episode: 2768   score: 5.0   memory length: 709375   epsilon: 0.009998020008555413    steps: 307    lr: 4.0960000000000023e-07     evaluation reward: 6.83\n",
      "episode: 2769   score: 5.0   memory length: 709673   epsilon: 0.009998020008555413    steps: 298    lr: 4.0960000000000023e-07     evaluation reward: 6.83\n",
      "episode: 2770   score: 5.0   memory length: 710021   epsilon: 0.009998020008555413    steps: 348    lr: 4.0960000000000023e-07     evaluation reward: 6.81\n",
      "episode: 2771   score: 9.0   memory length: 710544   epsilon: 0.009998020008555413    steps: 523    lr: 4.0960000000000023e-07     evaluation reward: 6.85\n",
      "episode: 2772   score: 8.0   memory length: 711004   epsilon: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     evaluation reward: 6.88\n",
      "episode: 2773   score: 11.0   memory length: 711464   epsilon: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     evaluation reward: 6.88\n",
      "episode: 2774   score: 4.0   memory length: 711742   epsilon: 0.009998020008555413    steps: 278    lr: 4.0960000000000023e-07     evaluation reward: 6.86\n",
      "episode: 2775   score: 3.0   memory length: 711971   epsilon: 0.009998020008555413    steps: 229    lr: 4.0960000000000023e-07     evaluation reward: 6.83\n",
      "episode: 2776   score: 7.0   memory length: 712398   epsilon: 0.009998020008555413    steps: 427    lr: 4.0960000000000023e-07     evaluation reward: 6.8\n",
      "episode: 2777   score: 6.0   memory length: 712758   epsilon: 0.009998020008555413    steps: 360    lr: 4.0960000000000023e-07     evaluation reward: 6.77\n",
      "episode: 2778   score: 7.0   memory length: 713150   epsilon: 0.009998020008555413    steps: 392    lr: 4.0960000000000023e-07     evaluation reward: 6.78\n",
      "episode: 2779   score: 5.0   memory length: 713432   epsilon: 0.009998020008555413    steps: 282    lr: 4.0960000000000023e-07     evaluation reward: 6.77\n",
      "episode: 2780   score: 5.0   memory length: 713721   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 6.76\n",
      "episode: 2781   score: 5.0   memory length: 714002   epsilon: 0.009998020008555413    steps: 281    lr: 4.0960000000000023e-07     evaluation reward: 6.68\n",
      "episode: 2782   score: 4.0   memory length: 714260   epsilon: 0.009998020008555413    steps: 258    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2783   score: 10.0   memory length: 714698   epsilon: 0.009998020008555413    steps: 438    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2784   score: 7.0   memory length: 715063   epsilon: 0.009998020008555413    steps: 365    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2785   score: 7.0   memory length: 715472   epsilon: 0.009998020008555413    steps: 409    lr: 4.0960000000000023e-07     evaluation reward: 6.7\n",
      "episode: 2786   score: 11.0   memory length: 715986   epsilon: 0.009998020008555413    steps: 514    lr: 4.0960000000000023e-07     evaluation reward: 6.76\n",
      "episode: 2787   score: 8.0   memory length: 716421   epsilon: 0.009998020008555413    steps: 435    lr: 4.0960000000000023e-07     evaluation reward: 6.75\n",
      "episode: 2788   score: 5.0   memory length: 716765   epsilon: 0.009998020008555413    steps: 344    lr: 4.0960000000000023e-07     evaluation reward: 6.63\n",
      "episode: 2789   score: 4.0   memory length: 717026   epsilon: 0.009998020008555413    steps: 261    lr: 4.0960000000000023e-07     evaluation reward: 6.62\n",
      "episode: 2790   score: 4.0   memory length: 717307   epsilon: 0.009998020008555413    steps: 281    lr: 4.0960000000000023e-07     evaluation reward: 6.59\n",
      "episode: 2791   score: 5.0   memory length: 717620   epsilon: 0.009998020008555413    steps: 313    lr: 4.0960000000000023e-07     evaluation reward: 6.6\n",
      "episode: 2792   score: 5.0   memory length: 717926   epsilon: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     evaluation reward: 6.58\n",
      "episode: 2793   score: 8.0   memory length: 718329   epsilon: 0.009998020008555413    steps: 403    lr: 4.0960000000000023e-07     evaluation reward: 6.59\n",
      "episode: 2794   score: 9.0   memory length: 718780   epsilon: 0.009998020008555413    steps: 451    lr: 4.0960000000000023e-07     evaluation reward: 6.63\n",
      "episode: 2795   score: 4.0   memory length: 719039   epsilon: 0.009998020008555413    steps: 259    lr: 4.0960000000000023e-07     evaluation reward: 6.62\n",
      "episode: 2796   score: 3.0   memory length: 719284   epsilon: 0.009998020008555413    steps: 245    lr: 4.0960000000000023e-07     evaluation reward: 6.61\n",
      "episode: 2797   score: 6.0   memory length: 719679   epsilon: 0.009998020008555413    steps: 395    lr: 4.0960000000000023e-07     evaluation reward: 6.62\n",
      "episode: 2798   score: 5.0   memory length: 720003   epsilon: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     evaluation reward: 6.63\n",
      "episode: 2799   score: 5.0   memory length: 720350   epsilon: 0.009998020008555413    steps: 347    lr: 4.0960000000000023e-07     evaluation reward: 6.63\n",
      "episode: 2800   score: 4.0   memory length: 720612   epsilon: 0.009998020008555413    steps: 262    lr: 4.0960000000000023e-07     evaluation reward: 6.62\n",
      "episode: 2801   score: 3.0   memory length: 720826   epsilon: 0.009998020008555413    steps: 214    lr: 4.0960000000000023e-07     evaluation reward: 6.59\n",
      "episode: 2802   score: 11.0   memory length: 721370   epsilon: 0.009998020008555413    steps: 544    lr: 4.0960000000000023e-07     evaluation reward: 6.63\n",
      "episode: 2803   score: 17.0   memory length: 721872   epsilon: 0.009998020008555413    steps: 502    lr: 4.0960000000000023e-07     evaluation reward: 6.74\n",
      "episode: 2804   score: 4.0   memory length: 722132   epsilon: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     evaluation reward: 6.74\n",
      "episode: 2805   score: 10.0   memory length: 722651   epsilon: 0.009998020008555413    steps: 519    lr: 4.0960000000000023e-07     evaluation reward: 6.73\n",
      "episode: 2806   score: 4.0   memory length: 722945   epsilon: 0.009998020008555413    steps: 294    lr: 4.0960000000000023e-07     evaluation reward: 6.72\n",
      "episode: 2807   score: 7.0   memory length: 723395   epsilon: 0.009998020008555413    steps: 450    lr: 4.0960000000000023e-07     evaluation reward: 6.73\n",
      "episode: 2808   score: 11.0   memory length: 723857   epsilon: 0.009998020008555413    steps: 462    lr: 4.0960000000000023e-07     evaluation reward: 6.76\n",
      "episode: 2809   score: 9.0   memory length: 724240   epsilon: 0.009998020008555413    steps: 383    lr: 4.0960000000000023e-07     evaluation reward: 6.77\n",
      "episode: 2810   score: 7.0   memory length: 724630   epsilon: 0.009998020008555413    steps: 390    lr: 4.0960000000000023e-07     evaluation reward: 6.77\n",
      "episode: 2811   score: 3.0   memory length: 724859   epsilon: 0.009998020008555413    steps: 229    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2812   score: 12.0   memory length: 725374   epsilon: 0.009998020008555413    steps: 515    lr: 4.0960000000000023e-07     evaluation reward: 6.76\n",
      "episode: 2813   score: 4.0   memory length: 725652   epsilon: 0.009998020008555413    steps: 278    lr: 4.0960000000000023e-07     evaluation reward: 6.71\n",
      "episode: 2814   score: 5.0   memory length: 725975   epsilon: 0.009998020008555413    steps: 323    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2815   score: 5.0   memory length: 726273   epsilon: 0.009998020008555413    steps: 298    lr: 4.0960000000000023e-07     evaluation reward: 6.68\n",
      "episode: 2816   score: 9.0   memory length: 726600   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 6.72\n",
      "episode: 2817   score: 5.0   memory length: 726904   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.73\n",
      "episode: 2818   score: 5.0   memory length: 727229   epsilon: 0.009998020008555413    steps: 325    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2819   score: 6.0   memory length: 727621   epsilon: 0.009998020008555413    steps: 392    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2820   score: 6.0   memory length: 728015   epsilon: 0.009998020008555413    steps: 394    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2821   score: 5.0   memory length: 728342   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2822   score: 6.0   memory length: 728635   epsilon: 0.009998020008555413    steps: 293    lr: 4.0960000000000023e-07     evaluation reward: 6.65\n",
      "episode: 2823   score: 3.0   memory length: 728864   epsilon: 0.009998020008555413    steps: 229    lr: 4.0960000000000023e-07     evaluation reward: 6.63\n",
      "episode: 2824   score: 5.0   memory length: 729188   epsilon: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     evaluation reward: 6.6\n",
      "episode: 2825   score: 8.0   memory length: 729617   epsilon: 0.009998020008555413    steps: 429    lr: 4.0960000000000023e-07     evaluation reward: 6.62\n",
      "episode: 2826   score: 5.0   memory length: 729921   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.64\n",
      "episode: 2827   score: 9.0   memory length: 730365   epsilon: 0.009998020008555413    steps: 444    lr: 4.0960000000000023e-07     evaluation reward: 6.68\n",
      "episode: 2828   score: 4.0   memory length: 730643   epsilon: 0.009998020008555413    steps: 278    lr: 4.0960000000000023e-07     evaluation reward: 6.65\n",
      "episode: 2829   score: 8.0   memory length: 731101   epsilon: 0.009998020008555413    steps: 458    lr: 4.0960000000000023e-07     evaluation reward: 6.66\n",
      "episode: 2830   score: 8.0   memory length: 731538   epsilon: 0.009998020008555413    steps: 437    lr: 4.0960000000000023e-07     evaluation reward: 6.68\n",
      "episode: 2831   score: 11.0   memory length: 732031   epsilon: 0.009998020008555413    steps: 493    lr: 4.0960000000000023e-07     evaluation reward: 6.74\n",
      "episode: 2832   score: 9.0   memory length: 732456   epsilon: 0.009998020008555413    steps: 425    lr: 4.0960000000000023e-07     evaluation reward: 6.75\n",
      "episode: 2833   score: 4.0   memory length: 732731   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2834   score: 12.0   memory length: 733105   epsilon: 0.009998020008555413    steps: 374    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2835   score: 4.0   memory length: 733381   epsilon: 0.009998020008555413    steps: 276    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2836   score: 8.0   memory length: 733864   epsilon: 0.009998020008555413    steps: 483    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2837   score: 2.0   memory length: 734063   epsilon: 0.009998020008555413    steps: 199    lr: 4.0960000000000023e-07     evaluation reward: 6.64\n",
      "episode: 2838   score: 6.0   memory length: 734423   epsilon: 0.009998020008555413    steps: 360    lr: 4.0960000000000023e-07     evaluation reward: 6.61\n",
      "episode: 2839   score: 6.0   memory length: 734716   epsilon: 0.009998020008555413    steps: 293    lr: 4.0960000000000023e-07     evaluation reward: 6.61\n",
      "episode: 2840   score: 6.0   memory length: 735066   epsilon: 0.009998020008555413    steps: 350    lr: 4.0960000000000023e-07     evaluation reward: 6.61\n",
      "episode: 2841   score: 6.0   memory length: 735423   epsilon: 0.009998020008555413    steps: 357    lr: 4.0960000000000023e-07     evaluation reward: 6.52\n",
      "episode: 2842   score: 4.0   memory length: 735722   epsilon: 0.009998020008555413    steps: 299    lr: 4.0960000000000023e-07     evaluation reward: 6.54\n",
      "episode: 2843   score: 6.0   memory length: 736083   epsilon: 0.009998020008555413    steps: 361    lr: 4.0960000000000023e-07     evaluation reward: 6.53\n",
      "episode: 2844   score: 6.0   memory length: 736465   epsilon: 0.009998020008555413    steps: 382    lr: 4.0960000000000023e-07     evaluation reward: 6.54\n",
      "episode: 2845   score: 10.0   memory length: 736827   epsilon: 0.009998020008555413    steps: 362    lr: 4.0960000000000023e-07     evaluation reward: 6.57\n",
      "episode: 2846   score: 6.0   memory length: 737184   epsilon: 0.009998020008555413    steps: 357    lr: 4.0960000000000023e-07     evaluation reward: 6.58\n",
      "episode: 2847   score: 4.0   memory length: 737429   epsilon: 0.009998020008555413    steps: 245    lr: 4.0960000000000023e-07     evaluation reward: 6.53\n",
      "episode: 2848   score: 8.0   memory length: 737848   epsilon: 0.009998020008555413    steps: 419    lr: 4.0960000000000023e-07     evaluation reward: 6.57\n",
      "episode: 2849   score: 8.0   memory length: 738257   epsilon: 0.009998020008555413    steps: 409    lr: 4.0960000000000023e-07     evaluation reward: 6.59\n",
      "episode: 2850   score: 10.0   memory length: 738776   epsilon: 0.009998020008555413    steps: 519    lr: 4.0960000000000023e-07     evaluation reward: 6.61\n",
      "episode: 2851   score: 9.0   memory length: 739243   epsilon: 0.009998020008555413    steps: 467    lr: 4.0960000000000023e-07     evaluation reward: 6.64\n",
      "episode: 2852   score: 5.0   memory length: 739549   epsilon: 0.009998020008555413    steps: 306    lr: 4.0960000000000023e-07     evaluation reward: 6.6\n",
      "episode: 2853   score: 8.0   memory length: 739913   epsilon: 0.009998020008555413    steps: 364    lr: 4.0960000000000023e-07     evaluation reward: 6.63\n",
      "episode: 2854   score: 5.0   memory length: 740239   epsilon: 0.009998020008555413    steps: 326    lr: 4.0960000000000023e-07     evaluation reward: 6.62\n",
      "episode: 2855   score: 6.0   memory length: 740613   epsilon: 0.009998020008555413    steps: 374    lr: 4.0960000000000023e-07     evaluation reward: 6.62\n",
      "episode: 2856   score: 4.0   memory length: 740869   epsilon: 0.009998020008555413    steps: 256    lr: 4.0960000000000023e-07     evaluation reward: 6.61\n",
      "episode: 2857   score: 10.0   memory length: 741376   epsilon: 0.009998020008555413    steps: 507    lr: 4.0960000000000023e-07     evaluation reward: 6.62\n",
      "episode: 2858   score: 4.0   memory length: 741651   epsilon: 0.009998020008555413    steps: 275    lr: 4.0960000000000023e-07     evaluation reward: 6.63\n",
      "episode: 2859   score: 6.0   memory length: 742006   epsilon: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     evaluation reward: 6.64\n",
      "episode: 2860   score: 6.0   memory length: 742347   epsilon: 0.009998020008555413    steps: 341    lr: 4.0960000000000023e-07     evaluation reward: 6.64\n",
      "episode: 2861   score: 9.0   memory length: 742674   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2862   score: 6.0   memory length: 743012   epsilon: 0.009998020008555413    steps: 338    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2863   score: 6.0   memory length: 743373   epsilon: 0.009998020008555413    steps: 361    lr: 4.0960000000000023e-07     evaluation reward: 6.59\n",
      "episode: 2864   score: 5.0   memory length: 743677   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 6.59\n",
      "episode: 2865   score: 7.0   memory length: 744086   epsilon: 0.009998020008555413    steps: 409    lr: 4.0960000000000023e-07     evaluation reward: 6.57\n",
      "episode: 2866   score: 4.0   memory length: 744349   epsilon: 0.009998020008555413    steps: 263    lr: 4.0960000000000023e-07     evaluation reward: 6.48\n",
      "episode: 2867   score: 6.0   memory length: 744745   epsilon: 0.009998020008555413    steps: 396    lr: 4.0960000000000023e-07     evaluation reward: 6.45\n",
      "episode: 2868   score: 10.0   memory length: 745285   epsilon: 0.009998020008555413    steps: 540    lr: 4.0960000000000023e-07     evaluation reward: 6.5\n",
      "episode: 2869   score: 10.0   memory length: 745803   epsilon: 0.009998020008555413    steps: 518    lr: 4.0960000000000023e-07     evaluation reward: 6.55\n",
      "episode: 2870   score: 5.0   memory length: 746096   epsilon: 0.009998020008555413    steps: 293    lr: 4.0960000000000023e-07     evaluation reward: 6.55\n",
      "episode: 2871   score: 5.0   memory length: 746391   epsilon: 0.009998020008555413    steps: 295    lr: 4.0960000000000023e-07     evaluation reward: 6.51\n",
      "episode: 2872   score: 7.0   memory length: 746780   epsilon: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     evaluation reward: 6.5\n",
      "episode: 2873   score: 5.0   memory length: 747125   epsilon: 0.009998020008555413    steps: 345    lr: 4.0960000000000023e-07     evaluation reward: 6.44\n",
      "episode: 2874   score: 9.0   memory length: 747600   epsilon: 0.009998020008555413    steps: 475    lr: 4.0960000000000023e-07     evaluation reward: 6.49\n",
      "episode: 2875   score: 3.0   memory length: 747846   epsilon: 0.009998020008555413    steps: 246    lr: 4.0960000000000023e-07     evaluation reward: 6.49\n",
      "episode: 2876   score: 5.0   memory length: 748146   epsilon: 0.009998020008555413    steps: 300    lr: 4.0960000000000023e-07     evaluation reward: 6.47\n",
      "episode: 2877   score: 4.0   memory length: 748406   epsilon: 0.009998020008555413    steps: 260    lr: 4.0960000000000023e-07     evaluation reward: 6.45\n",
      "episode: 2878   score: 9.0   memory length: 748727   epsilon: 0.009998020008555413    steps: 321    lr: 4.0960000000000023e-07     evaluation reward: 6.47\n",
      "episode: 2879   score: 6.0   memory length: 749099   epsilon: 0.009998020008555413    steps: 372    lr: 4.0960000000000023e-07     evaluation reward: 6.48\n",
      "episode: 2880   score: 9.0   memory length: 749547   epsilon: 0.009998020008555413    steps: 448    lr: 4.0960000000000023e-07     evaluation reward: 6.52\n",
      "episode: 2881   score: 3.0   memory length: 749776   epsilon: 0.009998020008555413    steps: 229    lr: 4.0960000000000023e-07     evaluation reward: 6.5\n",
      "episode: 2882   score: 7.0   memory length: 750182   epsilon: 0.009998020008555413    steps: 406    lr: 4.0960000000000023e-07     evaluation reward: 6.53\n",
      "episode: 2883   score: 5.0   memory length: 750528   epsilon: 0.009998020008555413    steps: 346    lr: 4.0960000000000023e-07     evaluation reward: 6.48\n",
      "episode: 2884   score: 6.0   memory length: 750840   epsilon: 0.009998020008555413    steps: 312    lr: 4.0960000000000023e-07     evaluation reward: 6.47\n",
      "episode: 2885   score: 5.0   memory length: 751169   epsilon: 0.009998020008555413    steps: 329    lr: 4.0960000000000023e-07     evaluation reward: 6.45\n",
      "episode: 2886   score: 7.0   memory length: 751526   epsilon: 0.009998020008555413    steps: 357    lr: 4.0960000000000023e-07     evaluation reward: 6.41\n",
      "episode: 2887   score: 7.0   memory length: 751881   epsilon: 0.009998020008555413    steps: 355    lr: 4.0960000000000023e-07     evaluation reward: 6.4\n",
      "episode: 2888   score: 4.0   memory length: 752158   epsilon: 0.009998020008555413    steps: 277    lr: 4.0960000000000023e-07     evaluation reward: 6.39\n",
      "episode: 2889   score: 7.0   memory length: 752579   epsilon: 0.009998020008555413    steps: 421    lr: 4.0960000000000023e-07     evaluation reward: 6.42\n",
      "episode: 2890   score: 4.0   memory length: 752842   epsilon: 0.009998020008555413    steps: 263    lr: 4.0960000000000023e-07     evaluation reward: 6.42\n",
      "episode: 2891   score: 7.0   memory length: 753206   epsilon: 0.009998020008555413    steps: 364    lr: 4.0960000000000023e-07     evaluation reward: 6.44\n",
      "episode: 2892   score: 9.0   memory length: 753516   epsilon: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     evaluation reward: 6.48\n",
      "episode: 2893   score: 7.0   memory length: 753868   epsilon: 0.009998020008555413    steps: 352    lr: 4.0960000000000023e-07     evaluation reward: 6.47\n",
      "episode: 2894   score: 4.0   memory length: 754147   epsilon: 0.009998020008555413    steps: 279    lr: 4.0960000000000023e-07     evaluation reward: 6.42\n",
      "episode: 2895   score: 6.0   memory length: 754462   epsilon: 0.009998020008555413    steps: 315    lr: 4.0960000000000023e-07     evaluation reward: 6.44\n",
      "episode: 2896   score: 8.0   memory length: 754871   epsilon: 0.009998020008555413    steps: 409    lr: 4.0960000000000023e-07     evaluation reward: 6.49\n",
      "episode: 2897   score: 6.0   memory length: 755242   epsilon: 0.009998020008555413    steps: 371    lr: 4.0960000000000023e-07     evaluation reward: 6.49\n",
      "episode: 2898   score: 7.0   memory length: 755617   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 6.51\n",
      "episode: 2899   score: 6.0   memory length: 755970   epsilon: 0.009998020008555413    steps: 353    lr: 4.0960000000000023e-07     evaluation reward: 6.52\n",
      "episode: 2900   score: 8.0   memory length: 756361   epsilon: 0.009998020008555413    steps: 391    lr: 4.0960000000000023e-07     evaluation reward: 6.56\n",
      "episode: 2901   score: 6.0   memory length: 756700   epsilon: 0.009998020008555413    steps: 339    lr: 4.0960000000000023e-07     evaluation reward: 6.59\n",
      "episode: 2902   score: 5.0   memory length: 757028   epsilon: 0.009998020008555413    steps: 328    lr: 4.0960000000000023e-07     evaluation reward: 6.53\n",
      "episode: 2903   score: 5.0   memory length: 757322   epsilon: 0.009998020008555413    steps: 294    lr: 4.0960000000000023e-07     evaluation reward: 6.41\n",
      "episode: 2904   score: 8.0   memory length: 757715   epsilon: 0.009998020008555413    steps: 393    lr: 4.0960000000000023e-07     evaluation reward: 6.45\n",
      "episode: 2905   score: 9.0   memory length: 758175   epsilon: 0.009998020008555413    steps: 460    lr: 4.0960000000000023e-07     evaluation reward: 6.44\n",
      "episode: 2906   score: 8.0   memory length: 758621   epsilon: 0.009998020008555413    steps: 446    lr: 4.0960000000000023e-07     evaluation reward: 6.48\n",
      "episode: 2907   score: 6.0   memory length: 758982   epsilon: 0.009998020008555413    steps: 361    lr: 4.0960000000000023e-07     evaluation reward: 6.47\n",
      "episode: 2908   score: 9.0   memory length: 759397   epsilon: 0.009998020008555413    steps: 415    lr: 4.0960000000000023e-07     evaluation reward: 6.45\n",
      "episode: 2909   score: 9.0   memory length: 759797   epsilon: 0.009998020008555413    steps: 400    lr: 4.0960000000000023e-07     evaluation reward: 6.45\n",
      "episode: 2910   score: 7.0   memory length: 760172   epsilon: 0.009998020008555413    steps: 375    lr: 4.0960000000000023e-07     evaluation reward: 6.45\n",
      "episode: 2911   score: 8.0   memory length: 760594   epsilon: 0.009998020008555413    steps: 422    lr: 4.0960000000000023e-07     evaluation reward: 6.5\n",
      "episode: 2912   score: 7.0   memory length: 761018   epsilon: 0.009998020008555413    steps: 424    lr: 4.0960000000000023e-07     evaluation reward: 6.45\n",
      "episode: 2913   score: 10.0   memory length: 761502   epsilon: 0.009998020008555413    steps: 484    lr: 4.0960000000000023e-07     evaluation reward: 6.51\n",
      "episode: 2914   score: 5.0   memory length: 761791   epsilon: 0.009998020008555413    steps: 289    lr: 4.0960000000000023e-07     evaluation reward: 6.51\n",
      "episode: 2915   score: 6.0   memory length: 762151   epsilon: 0.009998020008555413    steps: 360    lr: 4.0960000000000023e-07     evaluation reward: 6.52\n",
      "episode: 2916   score: 6.0   memory length: 762507   epsilon: 0.009998020008555413    steps: 356    lr: 4.0960000000000023e-07     evaluation reward: 6.49\n",
      "episode: 2917   score: 8.0   memory length: 762891   epsilon: 0.009998020008555413    steps: 384    lr: 4.0960000000000023e-07     evaluation reward: 6.52\n",
      "episode: 2918   score: 5.0   memory length: 763221   epsilon: 0.009998020008555413    steps: 330    lr: 4.0960000000000023e-07     evaluation reward: 6.52\n",
      "episode: 2919   score: 7.0   memory length: 763593   epsilon: 0.009998020008555413    steps: 372    lr: 4.0960000000000023e-07     evaluation reward: 6.53\n",
      "episode: 2920   score: 6.0   memory length: 763971   epsilon: 0.009998020008555413    steps: 378    lr: 4.0960000000000023e-07     evaluation reward: 6.53\n",
      "episode: 2921   score: 10.0   memory length: 764519   epsilon: 0.009998020008555413    steps: 548    lr: 4.0960000000000023e-07     evaluation reward: 6.58\n",
      "episode: 2922   score: 5.0   memory length: 764847   epsilon: 0.009998020008555413    steps: 328    lr: 4.0960000000000023e-07     evaluation reward: 6.57\n",
      "episode: 2923   score: 5.0   memory length: 765160   epsilon: 0.009998020008555413    steps: 313    lr: 4.0960000000000023e-07     evaluation reward: 6.59\n",
      "episode: 2924   score: 5.0   memory length: 765472   epsilon: 0.009998020008555413    steps: 312    lr: 4.0960000000000023e-07     evaluation reward: 6.59\n",
      "episode: 2925   score: 7.0   memory length: 765835   epsilon: 0.009998020008555413    steps: 363    lr: 4.0960000000000023e-07     evaluation reward: 6.58\n",
      "episode: 2926   score: 7.0   memory length: 766224   epsilon: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     evaluation reward: 6.6\n",
      "episode: 2927   score: 6.0   memory length: 766598   epsilon: 0.009998020008555413    steps: 374    lr: 4.0960000000000023e-07     evaluation reward: 6.57\n",
      "episode: 2928   score: 7.0   memory length: 766970   epsilon: 0.009998020008555413    steps: 372    lr: 4.0960000000000023e-07     evaluation reward: 6.6\n",
      "episode: 2929   score: 9.0   memory length: 767334   epsilon: 0.009998020008555413    steps: 364    lr: 4.0960000000000023e-07     evaluation reward: 6.61\n",
      "episode: 2930   score: 8.0   memory length: 767758   epsilon: 0.009998020008555413    steps: 424    lr: 4.0960000000000023e-07     evaluation reward: 6.61\n",
      "episode: 2931   score: 8.0   memory length: 768180   epsilon: 0.009998020008555413    steps: 422    lr: 4.0960000000000023e-07     evaluation reward: 6.58\n",
      "episode: 2932   score: 6.0   memory length: 768516   epsilon: 0.009998020008555413    steps: 336    lr: 4.0960000000000023e-07     evaluation reward: 6.55\n",
      "episode: 2933   score: 9.0   memory length: 768989   epsilon: 0.009998020008555413    steps: 473    lr: 4.0960000000000023e-07     evaluation reward: 6.6\n",
      "episode: 2934   score: 8.0   memory length: 769411   epsilon: 0.009998020008555413    steps: 422    lr: 4.0960000000000023e-07     evaluation reward: 6.56\n",
      "episode: 2935   score: 4.0   memory length: 769691   epsilon: 0.009998020008555413    steps: 280    lr: 4.0960000000000023e-07     evaluation reward: 6.56\n",
      "episode: 2936   score: 5.0   memory length: 769985   epsilon: 0.009998020008555413    steps: 294    lr: 4.0960000000000023e-07     evaluation reward: 6.53\n",
      "episode: 2937   score: 5.0   memory length: 770312   epsilon: 0.009998020008555413    steps: 327    lr: 4.0960000000000023e-07     evaluation reward: 6.56\n",
      "episode: 2938   score: 4.0   memory length: 770575   epsilon: 0.009998020008555413    steps: 263    lr: 4.0960000000000023e-07     evaluation reward: 6.54\n",
      "episode: 2939   score: 6.0   memory length: 770913   epsilon: 0.009998020008555413    steps: 338    lr: 4.0960000000000023e-07     evaluation reward: 6.54\n",
      "episode: 2940   score: 9.0   memory length: 771220   epsilon: 0.009998020008555413    steps: 307    lr: 4.0960000000000023e-07     evaluation reward: 6.57\n",
      "episode: 2941   score: 10.0   memory length: 771781   epsilon: 0.009998020008555413    steps: 561    lr: 4.0960000000000023e-07     evaluation reward: 6.61\n",
      "episode: 2942   score: 14.0   memory length: 772350   epsilon: 0.009998020008555413    steps: 569    lr: 4.0960000000000023e-07     evaluation reward: 6.71\n",
      "episode: 2943   score: 8.0   memory length: 772769   epsilon: 0.009998020008555413    steps: 419    lr: 4.0960000000000023e-07     evaluation reward: 6.73\n",
      "episode: 2944   score: 6.0   memory length: 773106   epsilon: 0.009998020008555413    steps: 337    lr: 4.0960000000000023e-07     evaluation reward: 6.73\n",
      "episode: 2945   score: 6.0   memory length: 773499   epsilon: 0.009998020008555413    steps: 393    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2946   score: 5.0   memory length: 773823   epsilon: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     evaluation reward: 6.68\n",
      "episode: 2947   score: 5.0   memory length: 774149   epsilon: 0.009998020008555413    steps: 326    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2948   score: 6.0   memory length: 774547   epsilon: 0.009998020008555413    steps: 398    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2949   score: 10.0   memory length: 775070   epsilon: 0.009998020008555413    steps: 523    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2950   score: 4.0   memory length: 775350   epsilon: 0.009998020008555413    steps: 280    lr: 4.0960000000000023e-07     evaluation reward: 6.63\n",
      "episode: 2951   score: 10.0   memory length: 775843   epsilon: 0.009998020008555413    steps: 493    lr: 4.0960000000000023e-07     evaluation reward: 6.64\n",
      "episode: 2952   score: 5.0   memory length: 776167   epsilon: 0.009998020008555413    steps: 324    lr: 4.0960000000000023e-07     evaluation reward: 6.64\n",
      "episode: 2953   score: 11.0   memory length: 776548   epsilon: 0.009998020008555413    steps: 381    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2954   score: 7.0   memory length: 776956   epsilon: 0.009998020008555413    steps: 408    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2955   score: 7.0   memory length: 777318   epsilon: 0.009998020008555413    steps: 362    lr: 4.0960000000000023e-07     evaluation reward: 6.7\n",
      "episode: 2956   score: 3.0   memory length: 777547   epsilon: 0.009998020008555413    steps: 229    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2957   score: 4.0   memory length: 777808   epsilon: 0.009998020008555413    steps: 261    lr: 4.0960000000000023e-07     evaluation reward: 6.63\n",
      "episode: 2958   score: 11.0   memory length: 778366   epsilon: 0.009998020008555413    steps: 558    lr: 4.0960000000000023e-07     evaluation reward: 6.7\n",
      "episode: 2959   score: 5.0   memory length: 778654   epsilon: 0.009998020008555413    steps: 288    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2960   score: 6.0   memory length: 778994   epsilon: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     evaluation reward: 6.69\n",
      "episode: 2961   score: 6.0   memory length: 779354   epsilon: 0.009998020008555413    steps: 360    lr: 4.0960000000000023e-07     evaluation reward: 6.66\n",
      "episode: 2962   score: 7.0   memory length: 779743   epsilon: 0.009998020008555413    steps: 389    lr: 4.0960000000000023e-07     evaluation reward: 6.67\n",
      "episode: 2963   score: 3.0   memory length: 779991   epsilon: 0.009998020008555413    steps: 248    lr: 4.0960000000000023e-07     evaluation reward: 6.64\n",
      "episode: 2964   score: 5.0   memory length: 780273   epsilon: 0.009998020008555413    steps: 282    lr: 4.0960000000000023e-07     evaluation reward: 6.64\n",
      "episode: 2965   score: 18.0   memory length: 780972   epsilon: 0.009998020008555413    steps: 699    lr: 4.0960000000000023e-07     evaluation reward: 6.75\n",
      "episode: 2966   score: 7.0   memory length: 781374   epsilon: 0.009998020008555413    steps: 402    lr: 4.0960000000000023e-07     evaluation reward: 6.78\n",
      "episode: 2967   score: 7.0   memory length: 781784   epsilon: 0.009998020008555413    steps: 410    lr: 4.0960000000000023e-07     evaluation reward: 6.79\n",
      "episode: 2968   score: 6.0   memory length: 782138   epsilon: 0.009998020008555413    steps: 354    lr: 4.0960000000000023e-07     evaluation reward: 6.75\n",
      "episode: 2969   score: 8.0   memory length: 782576   epsilon: 0.009998020008555413    steps: 438    lr: 4.0960000000000023e-07     evaluation reward: 6.73\n",
      "episode: 2970   score: 12.0   memory length: 783103   epsilon: 0.009998020008555413    steps: 527    lr: 4.0960000000000023e-07     evaluation reward: 6.8\n",
      "episode: 2971   score: 7.0   memory length: 783512   epsilon: 0.009998020008555413    steps: 409    lr: 4.0960000000000023e-07     evaluation reward: 6.82\n",
      "episode: 2972   score: 5.0   memory length: 783819   epsilon: 0.009998020008555413    steps: 307    lr: 4.0960000000000023e-07     evaluation reward: 6.8\n",
      "episode: 2973   score: 6.0   memory length: 784161   epsilon: 0.009998020008555413    steps: 342    lr: 4.0960000000000023e-07     evaluation reward: 6.81\n",
      "episode: 2974   score: 6.0   memory length: 784522   epsilon: 0.009998020008555413    steps: 361    lr: 4.0960000000000023e-07     evaluation reward: 6.78\n",
      "episode: 2975   score: 11.0   memory length: 785043   epsilon: 0.009998020008555413    steps: 521    lr: 4.0960000000000023e-07     evaluation reward: 6.86\n",
      "episode: 2976   score: 13.0   memory length: 785564   epsilon: 0.009998020008555413    steps: 521    lr: 4.0960000000000023e-07     evaluation reward: 6.94\n",
      "episode: 2977   score: 16.0   memory length: 786016   epsilon: 0.009998020008555413    steps: 452    lr: 4.0960000000000023e-07     evaluation reward: 7.06\n",
      "episode: 2978   score: 5.0   memory length: 786338   epsilon: 0.009998020008555413    steps: 322    lr: 4.0960000000000023e-07     evaluation reward: 7.02\n",
      "episode: 2979   score: 5.0   memory length: 786661   epsilon: 0.009998020008555413    steps: 323    lr: 4.0960000000000023e-07     evaluation reward: 7.01\n",
      "episode: 2980   score: 5.0   memory length: 786971   epsilon: 0.009998020008555413    steps: 310    lr: 4.0960000000000023e-07     evaluation reward: 6.97\n",
      "episode: 2981   score: 7.0   memory length: 787336   epsilon: 0.009998020008555413    steps: 365    lr: 4.0960000000000023e-07     evaluation reward: 7.01\n",
      "episode: 2982   score: 12.0   memory length: 787640   epsilon: 0.009998020008555413    steps: 304    lr: 4.0960000000000023e-07     evaluation reward: 7.06\n",
      "episode: 2983   score: 8.0   memory length: 788059   epsilon: 0.009998020008555413    steps: 419    lr: 4.0960000000000023e-07     evaluation reward: 7.09\n",
      "episode: 2984   score: 3.0   memory length: 788291   epsilon: 0.009998020008555413    steps: 232    lr: 4.0960000000000023e-07     evaluation reward: 7.06\n",
      "episode: 2985   score: 4.0   memory length: 788552   epsilon: 0.009998020008555413    steps: 261    lr: 4.0960000000000023e-07     evaluation reward: 7.05\n",
      "episode: 2986   score: 4.0   memory length: 788830   epsilon: 0.009998020008555413    steps: 278    lr: 4.0960000000000023e-07     evaluation reward: 7.02\n",
      "episode: 2987   score: 5.0   memory length: 789173   epsilon: 0.009998020008555413    steps: 343    lr: 4.0960000000000023e-07     evaluation reward: 7.0\n",
      "episode: 2988   score: 6.0   memory length: 789510   epsilon: 0.009998020008555413    steps: 337    lr: 4.0960000000000023e-07     evaluation reward: 7.02\n",
      "episode: 2989   score: 4.0   memory length: 789805   epsilon: 0.009998020008555413    steps: 295    lr: 4.0960000000000023e-07     evaluation reward: 6.99\n",
      "episode: 2990   score: 7.0   memory length: 790203   epsilon: 0.009998020008555413    steps: 398    lr: 4.0960000000000023e-07     evaluation reward: 7.02\n",
      "episode: 2991   score: 8.0   memory length: 790616   epsilon: 0.009998020008555413    steps: 413    lr: 4.0960000000000023e-07     evaluation reward: 7.03\n",
      "episode: 2992   score: 6.0   memory length: 790956   epsilon: 0.009998020008555413    steps: 340    lr: 4.0960000000000023e-07     evaluation reward: 7.0\n",
      "episode: 2993   score: 10.0   memory length: 791492   epsilon: 0.009998020008555413    steps: 536    lr: 4.0960000000000023e-07     evaluation reward: 7.03\n",
      "episode: 2994   score: 3.0   memory length: 791721   epsilon: 0.009998020008555413    steps: 229    lr: 4.0960000000000023e-07     evaluation reward: 7.02\n",
      "episode: 2995   score: 6.0   memory length: 792081   epsilon: 0.009998020008555413    steps: 360    lr: 4.0960000000000023e-07     evaluation reward: 7.02\n",
      "episode: 2996   score: 7.0   memory length: 792506   epsilon: 0.009998020008555413    steps: 425    lr: 4.0960000000000023e-07     evaluation reward: 7.01\n",
      "episode: 2997   score: 5.0   memory length: 792804   epsilon: 0.009998020008555413    steps: 298    lr: 4.0960000000000023e-07     evaluation reward: 7.0\n",
      "episode: 2998   score: 4.0   memory length: 793069   epsilon: 0.009998020008555413    steps: 265    lr: 4.0960000000000023e-07     evaluation reward: 6.97\n",
      "episode: 2999   score: 6.0   memory length: 793362   epsilon: 0.009998020008555413    steps: 293    lr: 4.0960000000000023e-07     evaluation reward: 6.97\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure the directories exist\n",
    "os.makedirs(\"save_graph\", exist_ok=True)\n",
    "os.makedirs(\"save_model\", exist_ok=True)\n",
    "\n",
    "rewards, episodes = [], []\n",
    "best_eval_reward = 0\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "    step = 0\n",
    "    d = False\n",
    "    state = env.reset()\n",
    "    next_state = state\n",
    "    life = number_lives\n",
    "\n",
    "    get_init_state(history, state)\n",
    "\n",
    "    while not done:\n",
    "        step += 1\n",
    "        frame += 1\n",
    "\n",
    "        # Perform a fire action if ball is no longer on screen to continue onto next life\n",
    "        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "            action = 0\n",
    "        else:\n",
    "            # Updated: Expand input dimensions for get_action\n",
    "            action = agent.get_action(np.expand_dims(np.float32(history[:4, :, :]), axis=0) / 255.)\n",
    "\n",
    "        state = next_state\n",
    "        next_state, reward, done, info = env.step(action + 1)\n",
    "\n",
    "        frame_next_state = get_frame(next_state)\n",
    "        history[4, :, :] = frame_next_state\n",
    "\n",
    "        # Updated to handle 'lives' key instead of 'ale.lives'\n",
    "        terminal_state = check_live(life, info.get('lives', life))\n",
    "        life = info.get('lives', life)\n",
    "\n",
    "        r = np.clip(reward, -1, 1)\n",
    "        r = reward\n",
    "\n",
    "        # Store the transition in memory\n",
    "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "\n",
    "        # Start training after random sample generation\n",
    "        if frame >= train_frame:\n",
    "            agent.train_policy_net(frame)\n",
    "            # Update the target network only for Double DQN\n",
    "            if double_dqn and (frame % update_target_network_frequency) == 0:\n",
    "                agent.update_target_net()\n",
    "\n",
    "        score += reward\n",
    "        history[:4, :, :] = history[1:, :, :]\n",
    "\n",
    "        if done:\n",
    "            evaluation_reward.append(score)\n",
    "            rewards.append(np.mean(evaluation_reward))\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, rewards, 'b')\n",
    "            pylab.xlabel('Episodes')\n",
    "            pylab.ylabel('Rewards')\n",
    "            pylab.title('Episodes vs Reward')\n",
    "            pylab.savefig(\"save_graph/breakout_dqn.png\")  # Save the graph in the correct directory\n",
    "\n",
    "            # every episode, plot the play time\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n",
    "                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n",
    "\n",
    "            # Save the model if evaluation reward exceeds a threshold\n",
    "            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n",
    "                torch.save(agent.policy_net, \"save_model/breakout_dqn.pth\")\n",
    "                best_eval_reward = np.mean(evaluation_reward)\n",
    "\n",
    "    # Early stopping condition\n",
    "    if np.mean(evaluation_reward) >= 8:\n",
    "        torch.save(agent.policy_net, \"save_model/breakout_dqn.pth\")\n",
    "        pylab.savefig(\"save_graph/breakout_dqn.png\")\n",
    "        best_eval_reward = np.mean(evaluation_reward)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.policy_net, \"./save_model/breakout_dqn_latest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers.record_video import RecordVideo\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "# Displaying the game live\n",
    "def show_state(env, step=0, info=\"\"):\n",
    "    plt.figure(3)\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n",
    "    plt.axis('off')\n",
    "\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    ipythondisplay.display(plt.gcf())\n",
    "    \n",
    "# Recording the game and replaying the game afterwards\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "    \n",
    "\n",
    "def wrap_env(env):\n",
    "    env=RecordVideo(env, './video', episode_trigger = lambda episode_number: True)\n",
    "\t  #env = Monitor(env, './video', force=True)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/wrappers/record_video.py:78: UserWarning: \u001b[33mWARN: Overwriting existing videos at /scratch/skamine3/CS747_Assignment5/CS747_Assigment5/video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/wrappers/monitoring/video_recorder.py:78: DeprecationWarning: \u001b[33mWARN: Recording ability for environment BreakoutDeterministic-v4 initialized with `render_mode=None` is marked as deprecated and will be removed in the future.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:297: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/core.py:49: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n",
      "/home/skamine3/.local/lib/python3.9/site-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" autoplay \n",
       "                loop controls style=\"height: 400px;\">\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f9d7d583070>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display = Display(visible=0, size=(300, 200))\n",
    "display.start()\n",
    "\n",
    "# Load agent\n",
    "# agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\n",
    "agent.epsilon = 0.0 # Set agent to only exploit the best action\n",
    "\n",
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "env = wrap_env(env)\n",
    "\n",
    "done = False\n",
    "score = 0\n",
    "step = 0\n",
    "state = env.reset()\n",
    "next_state = state\n",
    "life = number_lives\n",
    "history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
    "get_init_state(history, state)\n",
    "\n",
    "while not done:\n",
    "    \n",
    "    # Render breakout\n",
    "    env.render()\n",
    "#     show_state(env,step) # uncommenting this provides another way to visualize the game\n",
    "\n",
    "    step += 1\n",
    "    frame += 1\n",
    "\n",
    "    # Perform a fire action if ball is no longer on screen\n",
    "    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n",
    "        action = 0\n",
    "    else:\n",
    "        action = agent.get_action(np.expand_dims(np.float32(history[:4, :, :]),axis=0) / 255.)\n",
    "    state = next_state\n",
    "    \n",
    "    next_state, reward, done, info = env.step(action + 1)\n",
    "        \n",
    "    frame_next_state = get_frame(next_state)\n",
    "    history[4, :, :] = frame_next_state\n",
    "    terminal_state = check_live(life, info['lives'])\n",
    "        \n",
    "    life = info['lives']\n",
    "    r = np.clip(reward, -1, 1) \n",
    "    r = reward\n",
    "\n",
    "    # Store the transition in memory \n",
    "    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
    "    # Start training after random sample generation\n",
    "    score += reward\n",
    "    \n",
    "    history[:4, :, :] = history[1:, :, :]\n",
    "env.close()\n",
    "show_video()\n",
    "display.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
